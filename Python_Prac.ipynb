{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27c08711-98ed-45b0-a9b9-0c67fcd83430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as nd \n",
    "import datetime \n",
    "import requests\n",
    "import json\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "10a72a15-78c4-4ef0-b759-bd0e0747d091",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/4136278076.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmaxProfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0mbuy_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprofit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "def maxProfit(self, prices: List[int]) -> int:\n",
    "        buy_p = prices[0]\n",
    "        profit = 0\n",
    "        \n",
    "        for n in range(1, len(prices)):\n",
    "            if buy_p>prices[n]: buy_p = prices[n]\n",
    "            else: \n",
    "                if prices[n]-buy_p>profit: profit = prices[n]-buy_p\n",
    "        \n",
    "        return profit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7053c70b-f148-41e3-ab41-7ab6c674c9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Workable version of dynamic planning \n",
    "\n",
    "def maxProfit(prices, n):\n",
    "    buy = prices[0]\n",
    "    max_profit = 0\n",
    "    for i in range(1, n):\n",
    " \n",
    "        ## Checking for lower buy value\n",
    "        if (buy > prices[i]):\n",
    "            buy = prices[i]\n",
    " \n",
    "        ## Checking for higher profit\n",
    "        elif (prices[i] - buy > max_profit):\n",
    "            max_profit = prices[i] - buy;\n",
    "    return max_profit;\n",
    " \n",
    " \n",
    " ##  Driver code\n",
    "if __name__=='__main__':\n",
    " \n",
    "    prices = [ 7, 1, 5, 6, 4 ];\n",
    "    n = len(prices)\n",
    "    max_profit = maxProfit(prices, n);\n",
    "    print(max_profit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe65ae-c573-4cf9-afa2-eb2d695bbbba",
   "metadata": {},
   "source": [
    "This is an example of dynamic planning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e019bc5b-61a2-4456-a528-a45a15cf220b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3020529882.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/3020529882.py\"\u001b[0;36m, line \u001b[0;32m66\u001b[0m\n\u001b[0;31m    print \"Longest palindrome substring is: \", printSubStr(st, start,\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    " \n",
    "# A utility function to print a\n",
    "# substring str[low..high]\n",
    "def printSubStr(st, low, high) :\n",
    "    sys.stdout.write(st[low : high + 1])\n",
    "    sys.stdout.flush()\n",
    "    return ''\n",
    " \n",
    "# This function prints the longest palindrome\n",
    "# substring of st[]. It also returns the length\n",
    "# of the longest palindrome\n",
    "def longestPalSubstr(st) :\n",
    "    n = len(st) # get length of input string\n",
    " \n",
    "    # table[i][j] will be false if substring\n",
    "    # str[i..j] is not palindrome. Else\n",
    "    # table[i][j] will be true\n",
    "    table = [[0 for x in range(n)] for y\n",
    "                          in range(n)]\n",
    "     \n",
    "    # All substrings of length 1 are\n",
    "    # palindromes\n",
    "    maxLength = 1\n",
    "    i = 0\n",
    "    while (i < n) :\n",
    "        table[i][i] = True\n",
    "        i = i + 1\n",
    "     \n",
    "    # check for sub-string of length 2.\n",
    "    start = 0\n",
    "    i = 0\n",
    "    while i < n - 1 :\n",
    "        if (st[i] == st[i + 1]) :\n",
    "            table[i][i + 1] = True\n",
    "            start = i\n",
    "            maxLength = 2\n",
    "        i = i + 1\n",
    "     \n",
    "    # Check for lengths greater than 2.\n",
    "    # k is length of substring\n",
    "    k = 3\n",
    "    while k <= n :\n",
    "        # Fix the starting index\n",
    "        i = 0\n",
    "        while i < (n - k + 1) :\n",
    "             \n",
    "            # Get the ending index of\n",
    "            # substring from starting\n",
    "            # index i and length k\n",
    "            j = i + k - 1\n",
    "     \n",
    "            # checking for sub-string from\n",
    "            # ith index to jth index iff\n",
    "            # st[i + 1] to st[(j-1)] is a\n",
    "            # palindrome\n",
    "            if (table[i + 1][j - 1] and\n",
    "                      st[i] == st[j]) :\n",
    "                table[i][j] = True\n",
    "     \n",
    "                if (k > maxLength) :\n",
    "                    start = i\n",
    "                    maxLength = k\n",
    "            i = i + 1\n",
    "        k = k + 1\n",
    "    print\"Longest palindrome substring is: \", printSubStr(st, start,\n",
    "                                               start + maxLength - 1)\n",
    " \n",
    "    return maxLength # return length of LPS\n",
    " \n",
    " \n",
    " # Driver program to test above functions\n",
    "st = \"forgeeksskeegfor\"\n",
    "l = longestPalSubstr(st)\n",
    "print \"Length is\":, l\"\n",
    " \n",
    "# This code is contributed by Nikita Tiwari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "e48d25e6-d2bf-4880-be6e-5363938356e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest palindrome subString is: geeksskeeg\n",
      "Length is:  10\n"
     ]
    }
   ],
   "source": [
    "# A Python3 solution for longest palindrome\n",
    "\n",
    "# Function to pra subString str[low..high]\n",
    "def printSubStr(str, low, high):\n",
    "\t\n",
    "\tfor i in range(low, high + 1):\n",
    "\t\tprint(str[i], end = \"\")\n",
    "\n",
    "# This function prints the\n",
    "# longest palindrome subString\n",
    "# It also returns the length\n",
    "# of the longest palindrome\n",
    "def longestPalSubstr(str):\n",
    "\t\n",
    "\t# Get length of input String\n",
    "\tn = len(str)\n",
    "\t\n",
    "\t# All subStrings of length 1\n",
    "\t# are palindromes\n",
    "\tmaxLength = 1\n",
    "\tstart = 0\n",
    "\t\n",
    "\t# Nested loop to mark start\n",
    "\t# and end index\n",
    "\tfor i in range(n):\n",
    "\t\tfor j in range(i, n):\n",
    "\t\t\tflag = 1\n",
    "\t\t\t\n",
    "\t\t\t# Check palindrome\n",
    "\t\t\tfor k in range(0, ((j - i) // 2) + 1):\n",
    "\t\t\t\tif (str[i + k] != str[j - k]):\n",
    "\t\t\t\t\tflag = 0\n",
    "\n",
    "\t\t\t# Palindrome\n",
    "\t\t\tif (flag != 0 and (j - i + 1) > maxLength):\n",
    "\t\t\t\tstart = i\n",
    "\t\t\t\tmaxLength = j - i + 1\n",
    "\t\t\t\t\n",
    "\tprint(\"Longest palindrome subString is: \", end = \"\")\n",
    "\tprintSubStr(str, start, start + maxLength - 1)\n",
    "\n",
    "\t# Return length of LPS\n",
    "\treturn maxLength\n",
    "\n",
    "# Driver Code\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\tstr = \"forgeeksskeegfor\"\n",
    "\t\n",
    "\tprint(\"\\nLength is: \", longestPalSubstr(str))\n",
    "\n",
    "# This code is contributed by 29AjayKumar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b33ecf29-1b85-4cce-bd3d-f9f62add54ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/4080118024.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Dynamic planning .... .\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSolution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmaxProfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprofit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/4080118024.py\u001b[0m in \u001b[0;36mSolution\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSolution\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mmaxProfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprofit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9999\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not type"
     ]
    }
   ],
   "source": [
    "# Dynamic planning .... .\n",
    "\n",
    "class Solution:\n",
    "    def maxProfit(self, prices: List[int]) -> int:\n",
    "        profit=0\n",
    "        price=9999\n",
    "    for i in prices:\n",
    "        price=min(i,price)\n",
    "        profit=max(i-price,profit)\n",
    "return profit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9346915-0ffe-4da6-b5fe-ab66597ab97f",
   "metadata": {},
   "source": [
    "---- \n",
    "\n",
    "- ### Ask for two numbers. If the first one is larger than the second, display the second number first and then the first number, otherwise show the first number first and then the second.\n",
    "\n",
    "\n",
    "----- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cafdba24-059a-4c51-bf28-e1de999f88c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Number?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "None 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Number?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "None 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 5\n"
     ]
    }
   ],
   "source": [
    "num_1 = input(print('First Number?'))\n",
    "num_2 = input(print('Second Number?'))\n",
    "if num_1 > num_2:\n",
    "    print(num_2,num_1)\n",
    "else:\n",
    "    print(num_1,num_2)\n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0eaca45a-c611-4be0-875a-9c4c35f5e030",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1486225815.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/1486225815.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    self.breed = breed\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "class Dog:\n",
    "    family = \"Canine\"\n",
    "def __init__(self, name, breed): self.name = name\n",
    "self.breed = breed\n",
    "dog1 = Dog(\"Lassie\", \"Rough Collie\")\n",
    "print(dog1.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6fb99288-ffaa-44cf-8ece-243640a95dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up as a stock name and finding out where to pull the most current data from the desired stock \n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as nd \n",
    "import datetime \n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "STOCK_NAME = 'TSLA' # this is the stock name \n",
    "STOCK_ENDPOINT = 'https://www.alphavantage.co/query' # this is where we pull the information from \n",
    "\n",
    "API_KEY = 'J578B5KP1C3ZG1LE' \n",
    "# {} creating a dictionary !!! \n",
    "stock_params= { \n",
    "    'function':'TIME_SERIES_DAILY',\n",
    "    'symbol': STOCK_NAME,\n",
    "    'apikey': API_KEY,\n",
    "}\n",
    "\n",
    "response = requests.get(STOCK_ENDPOINT,params=stock_params)\n",
    "data = response.json()[\"Time Series (Daily)\"]\n",
    "# df  = print(response.json())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ac2c65c8-eeaf-4677-b93f-39deadf28d32",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/3466821532.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# data[\"date\"] = pd.to_datetime(data.index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"date\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   5449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5453\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "data  = pd.DataFrame(data=data)\n",
    "\n",
    "\n",
    "#df[\"date\"] = pd.to_datetime(df.date)\n",
    "\n",
    "\n",
    "\n",
    "#data\n",
    "\n",
    "\n",
    "# data[\"date\"] = pd.to_datetime(data.index)\n",
    "\n",
    "data.set_index( \"date\")   \n",
    "    \n",
    "data.head()\n",
    "\n",
    "df = data.drop( \"date\", axis = 1 ) \n",
    "\n",
    "\n",
    "\n",
    "# data.filter( \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1bff9cde-78a0-42f2-8a45-ab9e834423ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.DataFrame(data=data).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e01b10cd-078f-41d0-971f-1339eaf3bef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1. open</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2. high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3. low</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4. close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [1. open, 2. high, 3. low, 4. close, 5. volume]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.filter( \"2022-08-05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e7828277-eb7a-4dcc-b064-e0a1df840320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-05</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-04</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-03</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-02</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-01</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [2022-08-05, 2022-08-04, 2022-08-03, 2022-08-02, 2022-08-01, 2022-07-29, 2022-07-28, 2022-07-27, 2022-07-26, 2022-07-25, 2022-07-22, 2022-07-21, 2022-07-20, 2022-07-19, 2022-07-18, 2022-07-15, 2022-07-14, 2022-07-13, 2022-07-12, 2022-07-11, 2022-07-08, 2022-07-07, 2022-07-06, 2022-07-05, 2022-07-01, 2022-06-30, 2022-06-29, 2022-06-28, 2022-06-27, 2022-06-24, 2022-06-23, 2022-06-22, 2022-06-21, 2022-06-17, 2022-06-16, 2022-06-15, 2022-06-14, 2022-06-13, 2022-06-10, 2022-06-09, 2022-06-08, 2022-06-07, 2022-06-06, 2022-06-03, 2022-06-02, 2022-06-01, 2022-05-31, 2022-05-27, 2022-05-26, 2022-05-25, 2022-05-24, 2022-05-23, 2022-05-20, 2022-05-19, 2022-05-18, 2022-05-17, 2022-05-16, 2022-05-13, 2022-05-12, 2022-05-11, 2022-05-10, 2022-05-09, 2022-05-06, 2022-05-05, 2022-05-04, 2022-05-03, 2022-05-02, 2022-04-29, 2022-04-28, 2022-04-27, 2022-04-26, 2022-04-25, 2022-04-22, 2022-04-21, 2022-04-20, 2022-04-19, 2022-04-18, 2022-04-14, 2022-04-13, 2022-04-12, 2022-04-11, 2022-04-08, 2022-04-07, 2022-04-06, 2022-04-05, 2022-04-04, 2022-04-01, 2022-03-31, 2022-03-30, 2022-03-29, 2022-03-28, 2022-03-25, 2022-03-24, 2022-03-23, 2022-03-22, 2022-03-21, 2022-03-18, 2022-03-17, 2022-03-16, 2022-03-15]\n",
       "\n",
       "[100 rows x 0 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter( df.index ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "42fd016f-68ee-4717-aabb-1d212ce96388",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={ \"1. open\": \"Open\", \"2. high\": \"High\", \"3. low\": \"Low\" , \"4. close\": \"Close\", \"5. volume\": \"Volume\" } ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292b7b60-ef00-434a-824c-3a8491005264",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataD=dataD0[['Date','Close']]\n",
    "dataD.columns=['date','close']\n",
    "dataD['date']=pd.to_datetime(dataD['date'],format='%Y/%m/%d')\n",
    "dataD['daily gain']=(dataD['close']-dataD['close'].shift(1))*100/dataD['close'].shift(1)\n",
    "\n",
    "#######################\n",
    "\n",
    "# Plot creating rules \n",
    "fig=make_subplots(specs=[[{\"secondary_y\":True}]])\n",
    "fig.add_trace(go.Scatter(x=dataD['date'],y=dataD['close'],name=nameD),secondary_y=True,)\n",
    "fig.add_trace(go.Scatter(x=dataE['date'],y=dataE['close'],name=nameE),secondary_y=False,)\n",
    "fig.update_layout(autosize=False,width=800,height=500,title_text=nameD+' vs '+nameE+' Close')\n",
    "fig.update_xaxes(title_text=\"Date\")\n",
    "fig.update_yaxes(title_text=nameD+' USD',secondary_y=False)\n",
    "fig.update_yaxes(title_text=nameE+' USD',secondary_y=True)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "########################\n",
    "# Daily Gain \n",
    "\n",
    "fig=make_subplots(specs=[[{\"secondary_y\":False}]])\n",
    "fig.add_trace(go.Scatter(x=dataD['date'],y=dataD['daily gain'],name=nameD),secondary_y=False,)\n",
    "fig.add_trace(go.Scatter(x=dataE['date'],y=dataE['daily gain'],name=nameE),secondary_y=False,)\n",
    "fig.update_layout(autosize=False,width=800,height=500,title_text= nameD+' vs '+nameE + ' Daily Gain')\n",
    "fig.update_xaxes(title_text=\"Date\")\n",
    "fig.update_yaxes(title_text='Daily Gain %',secondary_y=False)\n",
    "fig.show()\n",
    "\n",
    "# Linear Regression of Daily Gain\n",
    "dataE2=dataE[['date','daily gain',]].reset_index(drop=True)\n",
    "dataD2=dataD[['date','daily gain',]].reset_index(drop=True)\n",
    "dataX=dataD2.merge(dataE2,on='date',how='left')\n",
    "display(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "60b10e3c-2929-412a-8c73-eea4ed992c70",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named 2009 for object type DataFrame",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 2009",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/214662706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2022\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, axis)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mnew_self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_self\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_axis_number\u001b[0;34m(cls, axis)\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_AXIS_TO_AXIS_NUMBER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No axis named {axis} for object type {cls.__name__}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No axis named 2009 for object type DataFrame"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Individual Stocks\n",
    "files = os.listdir('/kaggle/input/stock-market-data/stock_market_data/sp500/csv')\n",
    "Start auf Unternehmensebene:\n",
    "\n",
    "#Helping methods to sum up data\n",
    "\n",
    "def lowest_in_intervall_list(low_list, intervall):\n",
    "    return_list = []\n",
    "    i = 1\n",
    "    lowest_value = 0\n",
    "    float_values = list(map(float, low_list))\n",
    "    for value in float_values:\n",
    "        if(i == 1):\n",
    "            lowest_value = value\n",
    "            i+= 1\n",
    "        elif(i < intervall):\n",
    "            if(value < lowest_value):\n",
    "                lowest_value = value\n",
    "            i+=1\n",
    "        elif(i == intervall):\n",
    "            if(value < lowest_value):\n",
    "                lowest_value = value\n",
    "            return_list.append(lowest_value)\n",
    "            i = 1\n",
    "            lowest_value = 0\n",
    "    return return_list\n",
    "\n",
    "def highest_in_intervall_list(high_list, intervall):\n",
    "    return_list = []\n",
    "    i = 1\n",
    "    highest_value = 0\n",
    "    float_values = list(map(float, high_list))\n",
    "    for value in float_values:\n",
    "        if(i < intervall):\n",
    "            if(value > highest_value):\n",
    "                highest_value = value\n",
    "            i+=1\n",
    "        elif(i == intervall):\n",
    "            if(value > highest_value):\n",
    "                highest_value = value\n",
    "            return_list.append(highest_value)\n",
    "            i = 1\n",
    "            highest_value = 0\n",
    "    return return_list\n",
    "\n",
    "def average_in_intervall_list(value_list, intervall):\n",
    "    return_list = []\n",
    "    i = 1\n",
    "    sum = 0\n",
    "    float_values = list(map(float, value_list))\n",
    "    for value in float_values:\n",
    "        if(i < intervall):\n",
    "            sum += value\n",
    "            i +=1\n",
    "        elif(i == intervall):\n",
    "            sum += value\n",
    "            return_list.append(sum/intervall)\n",
    "            i = 1\n",
    "            sum = 0\n",
    "    return return_list\n",
    "\n",
    "def get_time_intervalls(day_list, intervall):\n",
    "    return_list = []\n",
    "    i = 1\n",
    "    day1 = \"\"\n",
    "    day_max = \"\"\n",
    "    for value in day_list:\n",
    "        if(i == 1):\n",
    "            day1 = value\n",
    "            i += 1\n",
    "        elif(i < intervall):\n",
    "            i+=1\n",
    "        elif(i == intervall):\n",
    "            day_max = value\n",
    "            return_list.append(str(day1) + \" - \"+ str(day_max))\n",
    "            i = 1\n",
    "    return return_list\n",
    "\n",
    "def sum_of_volume_in_intervall(volume_list, intervall):\n",
    "    return_list = []\n",
    "    i = 1\n",
    "    volume_sum = 0\n",
    "    float_values = list(map(float, volume_list))\n",
    "    for value in float_values:\n",
    "        if(i < intervall):\n",
    "            volume_sum += value\n",
    "            i += 1\n",
    "        elif(i == intervall):\n",
    "            volume_sum += value\n",
    "            return_list.append(volume_sum)\n",
    "            i = 1\n",
    "            volume_sum = 0\n",
    "    return return_list\n",
    "\n",
    "def clean_data(uncleaned_list):\n",
    "    return_list = []\n",
    "    float_values = list(map(float, uncleaned_list))\n",
    "    prev_value = float_values[0]\n",
    "    return_list.append(prev_value)\n",
    "    for i in range(len(float_values)-1):\n",
    "        if((float_values[i+1] >= (prev_value*2)) or float_values[i+1] <= (prev_value/2)):\n",
    "            float_values[i+1] = prev_value\n",
    "        prev_value = float_values[i+1]\n",
    "        return_list.append(prev_value)\n",
    "\n",
    "    return return_list\n",
    "\n",
    "def fix_tesla_dates(tesla_date_list):\n",
    "    return_list = []\n",
    "    for date in tesla_date_list:\n",
    "        new_date = date[8:10] + date[7:8] + date[5:7] + date[4:5] + date[:4]\n",
    "        return_list.append(new_date)\n",
    "        \n",
    "    return return_list\n",
    "\n",
    "def get_monthly_average_value(date_list, value_list):\n",
    "    sum = 0\n",
    "    values_per_month = 0\n",
    "    return_list = []\n",
    "    prev_month = date_list[0][3:5]\n",
    "    for i in range(len(date_list)-1):\n",
    "        if(date_list[i][3:5] != prev_month):\n",
    "            prev_month = date_list[i][3:5]\n",
    "            return_list.append(sum/values_per_month)\n",
    "            sum = 0\n",
    "            values_per_month = 0\n",
    "        sum += value_list[i]\n",
    "        values_per_month += 1    \n",
    "    return_list.append(sum/values_per_month)\n",
    "    return return_list\n",
    "\n",
    "def get_monthly_date_intervalls(date_list):\n",
    "    prev_month = \"\"\n",
    "    return_list = []\n",
    "    for value in date_list:\n",
    "        if(value[3:5] != prev_month):\n",
    "            prev_month = value[3:5]\n",
    "            month = get_month(value[3:5])\n",
    "            return_list.append(month + value[6:10])        \n",
    "    return return_list        \n",
    "          \n",
    "    \n",
    "def get_month(month_number):\n",
    "    if month_number == \"01\":\n",
    "        return \"Januar \"\n",
    "    elif month_number == \"02\":\n",
    "        return \"Februar \"\n",
    "    elif month_number == \"03\":\n",
    "        return \"März \"\n",
    "    elif month_number == \"04\":\n",
    "        return \"April \"\n",
    "    elif month_number == \"05\":\n",
    "        return \"Mai \"\n",
    "    elif month_number == \"06\":\n",
    "        return \"Juni \"\n",
    "    elif month_number == \"07\":\n",
    "        return \"Juli \"\n",
    "    elif month_number == \"08\":\n",
    "        return \"August \"\n",
    "    elif month_number == \"09\":\n",
    "        return \"September \"\n",
    "    elif month_number == \"10\":\n",
    "        return \"Oktober \"\n",
    "    elif month_number == \"11\":\n",
    "        return \"November \"\n",
    "    elif month_number == \"12\":\n",
    "        return \"Dezember \"\n",
    "    \n",
    "    else:\n",
    "        return \"invalid month\"\n",
    "    \n",
    "\n",
    "def get_yearly_date_intervalls(date_list):\n",
    "    return_list = []\n",
    "    return_list.append(date_list[0][6:10])\n",
    "    for value in date_list:\n",
    "        if(value[6:10] != return_list[len(return_list)-1]):\n",
    "            return_list.append(value[6:10])\n",
    "    return return_list\n",
    "\n",
    "def get_yearly_average_value(date_list, value_list):\n",
    "    sum = 0\n",
    "    values_per_year = 0\n",
    "    return_list = []\n",
    "    prev_year = date_list[0][6:10]\n",
    "    for i in range(len(date_list)-1):\n",
    "        if(date_list[i][6:10] != prev_year):\n",
    "            prev_year = date_list[i][6:10]\n",
    "            return_list.append(sum/values_per_year)\n",
    "            sum = 0\n",
    "            values_per_year = 0\n",
    "        sum += value_list[i]\n",
    "        values_per_year += 1    \n",
    "    return_list.append(sum/values_per_year)\n",
    "    return return_list\n",
    " \n",
    "Strukturierung von Daten: -Highs und Lows werden pro Woche und pro Monat eingeteilt -Hoch und Tiefpunkt vom Open Wert werden pro Woche und Monat ermittelt -Es werden Listen mit dem Volumen pro Woche und Monat erstellt -Entsprechend dazu werden Wochen und Monatsintervalle erstellt -Diese Strukturierung findet für die Unternehmen Apple, Amazon und Tesla statt\n",
    "\n",
    "#Getting some Apple Data\n",
    "\n",
    "apple_dates, apple_uncleaned_low, apple_uncleaned_high, apple_uncleaned_open, apple_volume = [], [], [], [], []\n",
    "apple_path = '/kaggle/input/stock-market-data/stock_market_data/sp500/csv/AAPL.csv'\n",
    "\n",
    "#Werte aus CSV holen  \n",
    "with open(apple_path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    header_row = next(reader)\n",
    "  \n",
    "    for row in reader:\n",
    "        apple_date = row[0]\n",
    "        apple_dates.append(apple_date)\n",
    "        \n",
    "        low_value = row[1]\n",
    "        apple_uncleaned_low.append(low_value)\n",
    "        \n",
    "        open_value = row[2]\n",
    "        apple_uncleaned_open.append(open_value)\n",
    "        \n",
    "        volume_value = row[3]\n",
    "        apple_volume.append(volume_value)\n",
    "        \n",
    "        high_value = row[4]\n",
    "        apple_uncleaned_high.append(high_value)\n",
    "        \n",
    "apple_low = clean_data(apple_uncleaned_low)\n",
    "apple_high = clean_data(apple_uncleaned_high)\n",
    "apple_open = clean_data(apple_uncleaned_open)\n",
    "\n",
    "#lowest low value for 7 days (5days) list of apple\n",
    "apple_weekly_low = lowest_in_intervall_list(apple_low, 5)\n",
    "\n",
    "#lowest opening value for 7 days (5days) list of apple\n",
    "apple_weekly_open_low = lowest_in_intervall_list(apple_open, 5)\n",
    "\n",
    "#average open value for 7 days (5days) list of apple\n",
    "apple_weekly_open_average = average_in_intervall_list(apple_open, 5)\n",
    "    \n",
    "#highest high value for 7 days (5days) list of apple\n",
    "apple_weekly_high = highest_in_intervall_list(apple_high, 5)\n",
    "  \n",
    "#highest opening value for 7 days (5days) list of apple\n",
    "apple_weekly_high = highest_in_intervall_list(apple_open, 5)\n",
    "\n",
    "#apple weekly volume\n",
    "apple_weekly_volume = sum_of_volume_in_intervall(apple_volume, 5)\n",
    "        \n",
    "#apple weekly time ranges\n",
    "apple_weekly_timeranges = get_time_intervalls(apple_dates, 5)\n",
    "\n",
    "#apple months\n",
    "apple_months = get_monthly_date_intervalls(apple_dates) \n",
    "\n",
    "#apple average monthly open value list\n",
    "apple_monthly_open = get_monthly_average_value(apple_dates, apple_open)\n",
    "\n",
    "#apple years\n",
    "apple_years = get_yearly_date_intervalls(apple_dates)\n",
    "\n",
    "#apple average yearly open value list\n",
    "apple_yearly_open = get_yearly_average_value(apple_dates, apple_open)\n",
    "#Getting some Amazon Data\n",
    "\n",
    "amazon_dates, amazon_uncleaned_low, amazon_uncleaned_high, amazon_uncleaned_open, amazon_volume = [], [], [], [], []\n",
    "amazon_path = '/kaggle/input/stock-market-data/stock_market_data/sp500/csv/AMZN.csv'\n",
    "\n",
    "#Werte aus CSV holen  \n",
    "with open(amazon_path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    header_row = next(reader)\n",
    "  \n",
    "    for row in reader:\n",
    "        amazon_date = row[0]\n",
    "        amazon_dates.append(amazon_date)\n",
    "        \n",
    "        low_value = row[1]\n",
    "        amazon_uncleaned_low.append(low_value)\n",
    "        \n",
    "        open_value = row[2]\n",
    "        amazon_uncleaned_open.append(open_value)\n",
    "        \n",
    "        volume_value = row[3]\n",
    "        amazon_volume.append(volume_value)\n",
    "        \n",
    "        high_value = row[4]\n",
    "        amazon_uncleaned_high.append(high_value)\n",
    "\n",
    "amazon_low = clean_data(amazon_uncleaned_low)\n",
    "amazon_high = clean_data(amazon_uncleaned_high)\n",
    "amazon_open = clean_data(amazon_uncleaned_open)\n",
    "\n",
    "#lowest value for 7 days (5days) list\n",
    "amazon_weekly_low = lowest_in_intervall_list(amazon_low, 5)\n",
    "\n",
    "#lowest opening value for 7 days (5days) list of amazon\n",
    "amazon_weekly_open_low = lowest_in_intervall_list(amazon_open, 5)\n",
    "\n",
    "#average open value for 7 days (5days) list of amazon\n",
    "amazon_weekly_open_average = average_in_intervall_list(amazon_open, 5)\n",
    "    \n",
    "#highest value for 7 days (5days) list\n",
    "amazon_weekly_high = highest_in_intervall_list(amazon_high, 5)\n",
    "  \n",
    "#highest opening value for 7 days (5days) list of amazon\n",
    "amazon_weekly_high = highest_in_intervall_list(amazon_open, 5)\n",
    "\n",
    "#amazon weekly volume\n",
    "amazon_weekly_volume = sum_of_volume_in_intervall(amazon_volume, 5)\n",
    "        \n",
    "#amazon weekly time ranges\n",
    "amazon_weekly_timeranges = get_time_intervalls(amazon_dates, 5)\n",
    "\n",
    "#amazon months\n",
    "amazon_months = get_monthly_date_intervalls(amazon_dates) \n",
    "\n",
    "#amazon average monthly open value list\n",
    "amazon_monthly_open = get_monthly_average_value(amazon_dates, amazon_open)\n",
    "\n",
    "#amazon years\n",
    "amazon_years = get_yearly_date_intervalls(amazon_dates)\n",
    "\n",
    "#amazon average yearly open value list\n",
    "amazon_yearly_open = get_yearly_average_value(amazon_dates, amazon_open)\n",
    "#Getting some Johnson & Johnson Data\n",
    "\n",
    "jnj_dates, jnj_uncleaned_low, jnj_uncleaned_high, jnj_uncleaned_open, jnj_volume = [], [], [], [], []\n",
    "jnj_path = '/kaggle/input/stock-market-data/stock_market_data/sp500/csv/JNJ.csv'\n",
    "\n",
    "#Werte aus CSV holen  \n",
    "with open(jnj_path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    header_row = next(reader)\n",
    "  \n",
    "    for row in reader:\n",
    "        jnj_date = row[0]\n",
    "        jnj_dates.append(jnj_date)\n",
    "        \n",
    "        low_value = row[1]\n",
    "        jnj_uncleaned_low.append(low_value)\n",
    "        \n",
    "        open_value = row[2]\n",
    "        jnj_uncleaned_open.append(open_value)\n",
    "        \n",
    "        volume_value = row[3]\n",
    "        jnj_volume.append(volume_value)\n",
    "        \n",
    "        high_value = row[4]\n",
    "        jnj_uncleaned_high.append(high_value)\n",
    "        \n",
    "jnj_low = clean_data(jnj_uncleaned_low)\n",
    "jnj_high = clean_data(jnj_uncleaned_high)\n",
    "jnj_open = clean_data(jnj_uncleaned_open)\n",
    "\n",
    "#lowest low value for 7 days (5days) list of johnson & johnson\n",
    "jnj_weekly_low = lowest_in_intervall_list(jnj_low, 5)\n",
    "\n",
    "#lowest opening value for 7 days (5days) list of johnson & johnson\n",
    "jnj_weekly_open_low = lowest_in_intervall_list(jnj_open, 5)\n",
    "\n",
    "#average open value for 7 days (5days) list of johnson & johnson\n",
    "jnj_weekly_open_average = average_in_intervall_list(jnj_open, 5)\n",
    "\n",
    "#highest high value for 7 days (5days) list of johnson & johnson\n",
    "jnj_weekly_high = highest_in_intervall_list(jnj_high, 5)\n",
    "\n",
    "#highest opening value for 7 days (5days) list of apple\n",
    "jnj_weekly_high = highest_in_intervall_list(jnj_open, 5)\n",
    "\n",
    "#johnson & johnson weekly volume\n",
    "jnj_weekly_volume = sum_of_volume_in_intervall(jnj_volume, 5)\n",
    "        \n",
    "#johnson & johnson weekly time ranges\n",
    "jnj_weekly_timeranges = get_time_intervalls(jnj_dates, 5)\n",
    "\n",
    "#johnson & johnson months\n",
    "jnj_months = get_monthly_date_intervalls(jnj_dates) \n",
    "\n",
    "#johnson & johnson average monthly open value list\n",
    "jnj_monthly_open = get_monthly_average_value(jnj_dates, jnj_open)\n",
    "\n",
    "#johnson & johnson years\n",
    "jnj_years = get_yearly_date_intervalls(jnj_dates)\n",
    "\n",
    "#johnson & johnson average yearly open value list\n",
    "jnj_yearly_open = get_yearly_average_value(jnj_dates, jnj_open)\n",
    "#Splitting some Tesla Data\n",
    "\n",
    "unfixed_tesla_dates, tesla_uncleaned_low, tesla_uncleaned_high, tesla_uncleaned_open, tesla_volume = [], [], [], [], []\n",
    "tesla_path = '/kaggle/input/tesla-stock-data-updated-till-28jun2021/TSLA.csv'\n",
    "\n",
    "#Werte aus CSV holen  \n",
    "with open(tesla_path) as f:\n",
    "    reader = csv.reader(f)\n",
    "    header_row = next(reader)\n",
    "  \n",
    "    for row in reader:\n",
    "        tesla_date = row[0]\n",
    "        unfixed_tesla_dates.append(tesla_date)\n",
    "        \n",
    "        low_value = row[3]\n",
    "        tesla_uncleaned_low.append(low_value)\n",
    "        \n",
    "        open_value = row[1]\n",
    "        tesla_uncleaned_open.append(open_value)\n",
    "        \n",
    "        volume_value = row[6]\n",
    "        tesla_volume.append(volume_value)\n",
    "        \n",
    "        high_value = row[2]\n",
    "        tesla_uncleaned_high.append(high_value)\n",
    "\n",
    "tesla_low = clean_data(tesla_uncleaned_low)\n",
    "tesla_high = clean_data(tesla_uncleaned_high)\n",
    "tesla_open = clean_data(tesla_uncleaned_open)\n",
    "tesla_dates = fix_tesla_dates(unfixed_tesla_dates)\n",
    "\n",
    "#lowest value for 7 days (5days) list\n",
    "tesla_weekly_low = lowest_in_intervall_list(tesla_low, 5)\n",
    "\n",
    "#lowest opening value for 7 days (5days) list of tesla\n",
    "tesla_weekly_open_low = lowest_in_intervall_list(tesla_open, 5)\n",
    "\n",
    "#average open value for 7 days (5days) list of tesla\n",
    "tesla_weekly_open_average = average_in_intervall_list(tesla_open, 5)\n",
    "    \n",
    "#highest value for 7 days (5days) list\n",
    "tesla_weekly_high = highest_in_intervall_list(tesla_high, 5)\n",
    "  \n",
    "#highest opening value for 7 days (5days) list of amazon\n",
    "tesla_weekly_high = highest_in_intervall_list(tesla_open, 5)\n",
    "\n",
    "#tesla weekly volume\n",
    "tesla_weekly_volume = sum_of_volume_in_intervall(tesla_volume, 5)\n",
    "        \n",
    "#tesla weekly time ranges\n",
    "tesla_weekly_timeranges = get_time_intervalls(tesla_dates, 5)\n",
    "\n",
    "#tesla months\n",
    "tesla_months = get_monthly_date_intervalls(tesla_dates) \n",
    "\n",
    "#tesla average monthly open value list\n",
    "tesla_monthly_open = get_monthly_average_value(tesla_dates, tesla_open)\n",
    "\n",
    "#tesla years\n",
    "tesla_years = get_yearly_date_intervalls(tesla_dates)\n",
    "\n",
    "#tesla average yearly open value list\n",
    "tesla_yearly_open = get_yearly_average_value(tesla_dates, tesla_open)\n",
    "#Hilfsmethoden für Extrem Punkte\n",
    "\n",
    "def get_highest_value_index_in_intervall(start_index, end_index, value_list):\n",
    "    highest_value_index = 0\n",
    "    for i in range(start_index, end_index):\n",
    "        if value_list[highest_value_index] < value_list[i]:\n",
    "            highest_value_index = i \n",
    "    return highest_value_index\n",
    "\n",
    "\n",
    "def get_back_to_value(highest_value_index, end_index, value_list):\n",
    "    counter = end_index +1\n",
    "\n",
    "    while counter < len(value_list):\n",
    "        if value_list[counter] > value_list[highest_value_index]:\n",
    "            return counter\n",
    "        counter += 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "def extreme_diff(values, amount_of_returned_indexes):\n",
    "    return_indexes = []\n",
    "    value_list = []\n",
    "    float_values = list(map(float, values))\n",
    "    if(len(values)<2):\n",
    "        return values\n",
    "    \n",
    "    for i in range(0, len(float_values)-1):\n",
    "        diff = abs(float_values[i]-float_values[i+1])\n",
    "        if(len(return_indexes)<amount_of_returned_indexes):\n",
    "            return_indexes.append(i)\n",
    "            value_list.append(diff)\n",
    "            \n",
    "        elif(min(value_list)<diff):\n",
    "            index = value_list.index(min(value_list))\n",
    "            value_list[index] = diff\n",
    "            return_indexes[index] = i\n",
    "            \n",
    "    return return_indexes\n",
    "\n",
    "def extreme_increase(values, amount_of_returned_indexes):\n",
    "    return_indexes = []\n",
    "    value_list = []\n",
    "    float_values = list(map(float, values))\n",
    "    if(len(values)<2):\n",
    "        return values\n",
    "    \n",
    "    for i in range(0, len(float_values)-1):\n",
    "        diff = float_values[i+1]-float_values[i]\n",
    "        if(len(return_indexes)<amount_of_returned_indexes):\n",
    "            return_indexes.append(i)\n",
    "            value_list.append(diff)\n",
    "            \n",
    "        elif(min(value_list)<diff):\n",
    "            index = value_list.index(min(value_list))\n",
    "            value_list[index] = diff\n",
    "            return_indexes[index] = i\n",
    "            \n",
    "    return return_indexes\n",
    "\n",
    "def extreme_decrease(values, amount_of_returned_indexes):\n",
    "    return_indexes = []\n",
    "    value_list = []\n",
    "    float_values = list(map(float, values))\n",
    "    if(len(values)<2):\n",
    "        return values\n",
    "    \n",
    "    for i in range(0, len(float_values)-1):\n",
    "        diff = float_values[i]-float_values[i+1]\n",
    "        if(len(return_indexes)<amount_of_returned_indexes):\n",
    "            return_indexes.append(i)\n",
    "            value_list.append(diff)\n",
    "            \n",
    "        elif(min(value_list)<diff):\n",
    "            index = value_list.index(min(value_list))\n",
    "            value_list[index] = diff\n",
    "            return_indexes[index] = i\n",
    "            \n",
    "    return return_indexes\n",
    "\n",
    "def extreme_percentage_increase(values, amount_of_returned_indexes):\n",
    "    return_indexes = []\n",
    "    value_list = []\n",
    "    float_values = list(map(float, values))\n",
    "    if(len(values)<2):\n",
    "        return values\n",
    "    \n",
    "    for i in range(0, len(float_values)-1):\n",
    "        #Prozentualer Unterschied\n",
    "        diff = float_values[i+1]/float_values[i]\n",
    "        if(len(return_indexes)<amount_of_returned_indexes):\n",
    "            return_indexes.append(i)\n",
    "            value_list.append(diff)\n",
    "            \n",
    "        elif(min(value_list)<diff):\n",
    "            index = value_list.index(min(value_list))\n",
    "            value_list[index] = diff\n",
    "            return_indexes[index] = i\n",
    "            \n",
    "    return return_indexes\n",
    "\n",
    "def extreme_percentage_decrease(values, amount_of_returned_indexes):\n",
    "    return_indexes = []\n",
    "    value_list = []\n",
    "    float_values = list(map(float, values))\n",
    "    if(len(values)<2):\n",
    "        return values\n",
    "    \n",
    "    for i in range(0, len(float_values)-1):\n",
    "        #Prozentualer Unterschied\n",
    "        diff = float_values[i]/float_values[i+1]\n",
    "        if(len(return_indexes)<amount_of_returned_indexes):\n",
    "            return_indexes.append(i)\n",
    "            value_list.append(diff)\n",
    "            \n",
    "        elif(min(value_list)<diff):\n",
    "            index = value_list.index(min(value_list))\n",
    "            value_list[index] = diff\n",
    "            return_indexes[index] = i\n",
    "            \n",
    "    return return_indexes\n",
    "\n",
    "def get_dates_by_index(date_list, index_list):\n",
    "    return_list = []\n",
    "    index_list.sort()\n",
    "    for value in index_list:\n",
    "        date = date_list[value]\n",
    "        return_string = f'Der Index {value} ist der {date}'\n",
    "        return_list.append(return_string)\n",
    "    return return_list\n",
    "\n",
    "def biggest_high_low_diff(high_list, low_list, amount_of_returned_indexes):\n",
    "    return_indexes = []\n",
    "    value_list = []\n",
    "    float_lows = list(map(float, low_list))\n",
    "    float_highs = list(map(float, high_list))\n",
    "    \n",
    "    if(len(high_list) != len(low_list)):\n",
    "        print(\"Fehler!\")\n",
    "        return []\n",
    "    \n",
    "    elif((len( float_lows) == 1) and (len(float_highs) == 1)):\n",
    "        return float_highs[0] - float_lows[0]\n",
    "    \n",
    "    elif((len(float_highs) < 1) or (len(float_lows) < 1)):\n",
    "        print(\"Fehler bei den Listen!\")\n",
    "        return []\n",
    "        \n",
    "    for i in range(0, len(float_highs)):\n",
    "        \n",
    "        diff = float_highs[i] / float_lows[i]\n",
    "        if(diff > 2):\n",
    "            diff = 0\n",
    "            \n",
    "        if(len(return_indexes)<amount_of_returned_indexes):\n",
    "            return_indexes.append(i)\n",
    "            value_list.append(diff)\n",
    "            \n",
    "        elif(min(value_list) < diff):\n",
    "            index_in_value_list = value_list.index(min(value_list))\n",
    "            value_list[index_in_value_list] = diff\n",
    "            return_indexes[index_in_value_list] = i\n",
    "    \n",
    "    for value in return_indexes:\n",
    "        diff = (float_highs[value] / float_lows[value])-1\n",
    "        print(f'Der Index {value} hat einen prozentualen Unterschied von {diff} zwischen dem High und dem Low Wert')\n",
    "    \n",
    "    return return_indexes\n",
    "\n",
    "def get_index_by_date(date_list, date):\n",
    "    for i in range(0, (len(date_list)-1)):\n",
    "        if(date_list[i] == date):\n",
    "            return i\n",
    "    print(f'Datum: {date} konnte nicht in der Liste gefunden werden')\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "\n",
    "def get_weekly_timerange_index_by_date(date, weekly_timerange_list):\n",
    "    return_value = 0\n",
    "    for i in range(0, (len(weekly_timerange_list)-1)):\n",
    "        week = weekly_timerange_list[i]\n",
    "        \n",
    "        if(week[3:10] == date[3:] ):\n",
    "            if(date[:2] >= week[:2]):\n",
    "                return_value = i\n",
    "            \n",
    "        if(week[16:23] == date[3:]):\n",
    "            if(date[:2] <= week[16:17]):\n",
    "                return_value = i\n",
    "            \n",
    "    return return_value\n",
    "\n",
    "\n",
    "def get_ca_index_by_date(date_list, date, is_start_index):\n",
    "    return_value = 0\n",
    "    for i in range(0, (len(date_list)-1)):\n",
    "        day = date_list[i]\n",
    "        if(day[3:] == date[3:]):\n",
    "            if(int(date[:2]) == int(day[:2])):\n",
    "                return i\n",
    "            elif(return_value == 0 or (not is_start_index)):\n",
    "                return_value = i\n",
    "                \n",
    "    return return_value\n",
    "\n",
    "\n",
    "def print_list(printed_list):\n",
    "    for value in printed_list:\n",
    "        print(value)\n",
    "        \n",
    "    \n",
    "def get_daily_diff_list(value_list):\n",
    "    return_list = []\n",
    "    return_list.append(0)\n",
    "    for i in range(len(value_list)-1):\n",
    "        diff = value_list[i+1]/value_list[i]\n",
    "        return_list.append((diff-1)*100)\n",
    "    return return_list\n",
    "\n",
    "\n",
    "def print_waggle_values(apple_waggle_list, apple_dates, min_percentage_diff):\n",
    "    print(f'Prozentuale Unterschiede mit mindestens {min_percentage_diff} zum Vortag:')\n",
    "    for i in range(len(apple_waggle_list)-1):\n",
    "        if(abs(apple_waggle_list[i])>min_percentage_diff):\n",
    "            print(f'Prozentualer Unterschied von {round(apple_waggle_list[i],2)} am {apple_dates[i]}')\n",
    "\n",
    "            \n",
    "            \n",
    "def print_average_diff_per_year(apple_waggle_list, apple_dates,start_year, end_year):\n",
    "    print()\n",
    "    print(f\"Entwicklung von {start_year} bis {end_year}\")\n",
    "    print()\n",
    "    \n",
    "    sum_of_increase = 0\n",
    "    sum_of_decrease = 0\n",
    "    values_of_increase = 0\n",
    "    values_of_decrease = 0\n",
    "    prev_year = apple_dates[0][6:10]\n",
    "    \n",
    "    start_index = 0\n",
    "    if(apple_dates[0][6:10] < start_year):\n",
    "        while(apple_dates[start_index][6:10] != start_year):\n",
    "            start_index += 1\n",
    "\n",
    "    \n",
    "    if(apple_dates[len(apple_dates)-1][6:10] > end_year):\n",
    "        end_index = start_index\n",
    "        while(apple_dates[end_index][6:10] != end_year):\n",
    "            end_index += 1\n",
    "    \n",
    "        while(apple_dates[end_index][6:10] == end_year):\n",
    "            end_index += 1\n",
    "    else:\n",
    "        end_index = len(apple_dates)-1\n",
    "        \n",
    "    prev_year = apple_dates[start_index][6:10]\n",
    "    for i in range(start_index,end_index):\n",
    "        if apple_dates[i][6:10] != prev_year:\n",
    "            print(f'Werte für das Jahr: {prev_year}')\n",
    "            print(f'Tage mit Anstieg: {values_of_increase}')\n",
    "            avg_increase_value = sum_of_increase/values_of_increase\n",
    "            print(f'Durchschnittlicher Anstieg pro Tag: {round(avg_increase_value,2)}')\n",
    "            print(f'Tage mit Abfall: {values_of_decrease}')\n",
    "            avg_decrease_value = sum_of_decrease/values_of_decrease\n",
    "            print(f'Durchschnittlicher Abfall pro Tag: {round(avg_decrease_value,2)}')\n",
    "\n",
    "            print()\n",
    "            sum_of_increase = 0\n",
    "            sum_of_decrease = 0\n",
    "            values_of_increase = 0\n",
    "            values_of_decrease = 0\n",
    "            prev_year = apple_dates[i][6:10]\n",
    "            \n",
    "        if apple_waggle_list[i]>= 0:\n",
    "            sum_of_increase += apple_waggle_list[i]\n",
    "            values_of_increase += 1\n",
    "            \n",
    "        elif apple_waggle_list[i]< 0:\n",
    "            sum_of_decrease -= apple_waggle_list[i]\n",
    "            values_of_decrease += 1\n",
    "            \n",
    "    print(f'Werte für das Jahr: {prev_year}')\n",
    "    print(f'Tage mit Anstieg: {values_of_increase}')\n",
    "    avg_increase_value = sum_of_increase/values_of_increase\n",
    "    print(f'Durchschnittlicher Anstieg pro Tag: {round(avg_increase_value,2)}')\n",
    "    print(f'Tage mit Abfall: {values_of_decrease}')\n",
    "    avg_decrease_value = sum_of_decrease/values_of_decrease\n",
    "    print(f'Durchschnittlicher Abfall pro Tag: {round(avg_decrease_value,2)}')\n",
    "    \n",
    "    \n",
    "def decrease_list_from_to(start_year,end_year, time_list, value_list):\n",
    "    prev_year = time_list[0][6:10]\n",
    "    \n",
    "    start_index = 0\n",
    "    if(time_list[0][6:10] < start_year):\n",
    "        while(time_list[start_index][6:10] != start_year):\n",
    "            start_index += 1\n",
    "  \n",
    "    if(time_list[len(time_list)-1][6:10] > end_year):\n",
    "        end_index = start_index\n",
    "        while(time_list[end_index][6:10] != end_year):\n",
    "            end_index += 1\n",
    "    \n",
    "        while(time_list[end_index][6:10] == end_year):\n",
    "            end_index += 1\n",
    "    else:\n",
    "        end_index = len(time_list)-1\n",
    "        \n",
    "    return_list = []\n",
    "    if(len(value_list) != len(time_list)):\n",
    "        value_list = time_list\n",
    "    for i in range(start_index,end_index):\n",
    "        return_list.append(value_list[i])\n",
    "        \n",
    "    return return_list    \n",
    "\n",
    "\n",
    "def get_highest_value_in_intervall(start_date, end_date, time_list, value_list):\n",
    "    \n",
    "    start_index = get_ca_index_by_date(time_list, start_date, True) if start_date[6:10] > time_list[0][6:10] else 0\n",
    "    end_index = get_ca_index_by_date(time_list, end_date, False) if int(end_date[6:10]) < int((time_list[len(time_list)-1][6:10])) else len(time_list)-1\n",
    "    \n",
    "    highest_value_index = get_highest_value_index_in_intervall(start_index, end_index, value_list)\n",
    "    \n",
    "    print (f'Der höchste Wert zwischen dem {start_date} und dem {end_date} ist {value_list[highest_value_index]} am {time_list[highest_value_index]}.')\n",
    "    \n",
    "    comeback_index = get_back_to_value(highest_value_index, end_index, value_list)\n",
    "\n",
    "    if(comeback_index == 0):\n",
    "        print (f'Danach wurde der Wert nie wieder erreicht!')\n",
    "    else:\n",
    "        print (f'Der Wert wurde am {time_list[comeback_index]} mit {value_list[comeback_index]} übertroffen.')\n",
    "        \n",
    "        \n",
    "def get_how_far_ago(time_list, value_list, multiplicator):\n",
    "    index = len(value_list)-1\n",
    "    float_values = list(map(float, value_list))\n",
    "    \n",
    "    while ((float_values[index]*multiplicator) > float_values[len(value_list)-1] or index < 0):\n",
    "           index -= 1\n",
    "    \n",
    "    if (float_values[index]*multiplicator) < float_values[len(value_list)-1]:\n",
    "\n",
    "        output_string = (f'Um den Wert seiner Aktie um den Faktor {multiplicator} zu erhöhen, müsste man die Aktie am {time_list[index]} zum Wert {value_list[index]} kaufen. Nun liegt der Wert am {time_list[len(value_list)-1]} beim Wert {value_list[len(value_list)-1]}')\n",
    "        print (output_string)\n",
    "        return\n",
    "    else:\n",
    "        print(\"Fehler\")\n",
    "        \n",
    "        \n",
    "def procentual_diff_from_to(start_date, end_date, time_list, value_list):\n",
    "    start_index = get_ca_index_by_date(time_list, start_date, True) if start_date[6:10] > time_list[0][6:10] else 0\n",
    "    end_index = get_ca_index_by_date(time_list, end_date, False) if int(end_date[6:10]) < int((time_list[len(time_list)-1][6:10])) else len(time_list)-1\n",
    "    diff = round((value_list[end_index]/value_list[start_index])*100)\n",
    "    \n",
    "        \n",
    "    print(f'Preis am {start_date}: {value_list[start_index]}')\n",
    "    print(f'Preis am {end_date}: {value_list[end_index]}')\n",
    "    print(f'Preisentwicklung von {diff}%.')\n",
    "            \n",
    "def show_lines(list_one, list_two, dates, value_amount, desc_x,desc_y, title, ticks):\n",
    "    \n",
    "    print()\n",
    "    list1 = list_one[(len(list_one)-value_amount):]\n",
    "    list_dates = dates[(len(dates)-value_amount):]\n",
    "    float_list_one = list(map(float, list1))\n",
    "    \n",
    "    plt.figure(figsize=(30,8))\n",
    "    \n",
    "    '''\n",
    "    if(len(list_two) == len(list_one)):\n",
    "        list2 = list_two[(len(list_two)-value_amount):]\n",
    "        float_list_two = list(map(float, list2))\n",
    "        plt.plot(list_dates,float_list_two, color = \"blue\")\n",
    "    '''\n",
    "    ax = plt.gca()  \n",
    "    if(ticks != 1):\n",
    "\n",
    "        tick_list = []\n",
    "        for i in range(len(dates)-1):\n",
    "            if(i%ticks == 0):\n",
    "                tick_list.append(i)\n",
    "        \n",
    "        ax.set_xticks(tick_list)\n",
    "        minor_ticks = np.arange(0, len(dates), (ticks/5))\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "        \n",
    "    plt.xticks(fontsize= 18)\n",
    "    plt.yticks(fontsize= 20)\n",
    "    \n",
    "    ax.set_xlabel(desc_x, fontsize=30)\n",
    "    ax.set_ylabel(desc_y, fontsize=30)\n",
    "    \n",
    "    plt.plot(list_dates,float_list_one, color = \"red\")\n",
    "    plt.title(title, fontsize = 35)\n",
    "\n",
    "    plt.show()\n",
    "     \n",
    "    \n",
    "def show_values_around_date(date_index, value_list, date_list, values_around_day, desc_x, desc_y, title, ticks):\n",
    "    craziest_one_day_diff = extreme_percentage_increase(apple_open, 1)\n",
    "    \n",
    "    values_after_day = values_around_day +1\n",
    "    if((len(date_list)-date_index-1) < values_after_day):\n",
    "        values_after_day = (len(date_list)-date_index-1)\n",
    "        \n",
    "    values_before_day = values_around_day -1\n",
    "    if(date_index< values_before_day):\n",
    "        values_before_day = date_index\n",
    "        \n",
    "    dates = date_list[(date_index - values_before_day) : (date_index + values_after_day)]\n",
    "    values = value_list[(date_index - values_before_day) : (date_index + values_after_day)]\n",
    "    floated_value_list = list(map(float, values))\n",
    "    \n",
    "    plt.figure(figsize=(14,6))\n",
    "    plt.plot(dates,floated_value_list, color = \"red\")\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    if(ticks != 1):\n",
    "        tick_list = []\n",
    "        for i in range(len(dates)-1):\n",
    "            if(i%ticks == 0):\n",
    "                tick_list.append(i)\n",
    "        \n",
    "        ax.set_xticks(tick_list)\n",
    "        minor_ticks = np.arange(0, len(dates), (ticks/5))\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "        \n",
    "    plt.xticks(fontsize= 12)\n",
    "    plt.yticks(fontsize= 14)\n",
    "    \n",
    "    ax.set_xlabel(desc_x, fontsize=20)\n",
    "    ax.set_ylabel(desc_y, fontsize=20)\n",
    " \n",
    "    plt.title(title)\n",
    "    plt.xlabel(desc_x)\n",
    "    plt.ylabel(desc_y)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def show_timerange(start_date, end_date, date_list, value_list, desc_x, desc_y, title, ticks):\n",
    "\n",
    "    start_index = get_ca_index_by_date(date_list, start_date, True)\n",
    "    end_index = get_ca_index_by_date(date_list, end_date, False)\n",
    "        \n",
    "    if(start_index == -1 or end_index == -1):\n",
    "        print(f'{title} konnte nicht angezeigen werden')\n",
    "        return \"\"\n",
    "    \n",
    "    plot_dates = []\n",
    "    plot_values = []\n",
    "    \n",
    "    for i in range(start_index, end_index):\n",
    "        plot_dates.append(date_list[i])\n",
    "        plot_values.append(value_list[i])\n",
    "        \n",
    "    show_lines(plot_values, [], plot_dates, len(plot_values), desc_x, desc_y, title, ticks)\n",
    "    \n",
    "    \n",
    "def overlapping_chart(date_list, list_one, list_two, list_three, list_four, desc_x, desc_y, title, ticks):\n",
    "\n",
    "    float_list_one = list(map(float, list_one))\n",
    "    float_list_two = list(map(float, list_two))\n",
    "    float_list_three = list(map(float, list_three))\n",
    "    float_list_four = list(map(float, list_four))\n",
    "    plt.figure(figsize=(30,8))\n",
    "    \n",
    "    ax = plt.gca()  \n",
    "    if(ticks != 1):\n",
    "\n",
    "        tick_list = []\n",
    "        for i in range(len(date_list)-1):\n",
    "            if(i%ticks == 0):\n",
    "                tick_list.append(i)\n",
    "        \n",
    "        ax.set_xticks(tick_list)\n",
    "        minor_ticks = np.arange(0, len(date_list), (ticks/5))\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "        \n",
    "    plt.xticks(fontsize= 18)\n",
    "    plt.yticks(fontsize= 20)\n",
    "    \n",
    "    ax.set_xlabel(desc_x, fontsize=30)\n",
    "    ax.set_ylabel(desc_y, fontsize=30)\n",
    "    \n",
    "    if len(date_list) == len(float_list_one):\n",
    "        plt.plot(date_list,float_list_one, color = \"red\", label = \"Apple\") \n",
    "    if len(date_list) == len(float_list_two):\n",
    "        plt.plot(date_list,float_list_two, color = \"blue\", label = \"Johnson & Johnson\")\n",
    "    if len(date_list) == len(float_list_three):\n",
    "        plt.plot(date_list,float_list_three, color = \"green\", label = \"Amazon\")\n",
    "    if len(date_list) == len(float_list_four):\n",
    "        plt.plot(date_list,float_list_four, color = \"yellow\", label = \"Tesla\")\n",
    "    ax.legend()\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.title(title, fontsize = 35)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "ticks = 10\n",
    "#Overall Apple Chart\n",
    "\n",
    "show_lines(apple_yearly_open, [], apple_years, len(apple_years), \"Time\",\"Value\", \"Overall Apple Stock Chart\", 2)\n",
    "\n",
    "show_lines(apple_monthly_open, [], apple_months, len(apple_months), \"Time\",\"Value\", \"Overall Apple Stock Chart\", 50)\n",
    "\n",
    "show_lines(apple_open, [], apple_dates, len(apple_open), \"Time\",\"Value\", \"Overall Detailed Apple Stock Chart\", (round(len(apple_open)/ticks)+1))\n",
    "\n",
    "#Overall Amazon Chart\n",
    "\n",
    "show_lines(amazon_yearly_open, [], amazon_years, len(amazon_years), \"Time\",\"Value\", \"Overall Amazon Stock Chart\", 2)\n",
    "\n",
    "show_lines(amazon_monthly_open, [], amazon_months, len(amazon_months), \"Time\",\"Value\", \"Overall Amazon Stock Chart\", 50)\n",
    "\n",
    "show_lines(amazon_open, [], amazon_dates, len(amazon_open), \"Time\",\"Value\", \"Overall Detailed Amazon Stock Chart\", (round(len(amazon_open)/ticks)+1))\n",
    "\n",
    "#Overall Tesla Chart\n",
    "\n",
    "show_lines(tesla_yearly_open, [], tesla_years, len(tesla_years), \"Time\",\"Value\", \"Overall Tesla Stock Chart\", 1)\n",
    "\n",
    "show_lines(tesla_monthly_open, [], tesla_months, len(tesla_months), \"Time\",\"Value\", \"Overall Tesla Stock Chart\", 30)\n",
    "\n",
    "show_lines(tesla_open, [], tesla_dates, len(tesla_open), \"Time\",\"Value\", \"Overall Detailed Tesla Stock Chart\", (round(len(tesla_open)/ticks)+1))\n",
    "\n",
    "#Overall Johnson & Johnson Chart\n",
    "\n",
    "\n",
    "show_lines(jnj_yearly_open, [], jnj_years, len(jnj_years), \"Time\",\"Value\", \"Overall Johnson & Johnson Stock Chart\", 2)\n",
    "\n",
    "show_lines(jnj_monthly_open, [], jnj_months, len(jnj_months), \"Time\",\"Value\", \"Overall Johnson & Johnson Stock Chart\", 80)\n",
    "\n",
    "show_lines(jnj_open, [], jnj_dates, len(jnj_open), \"Time\",\"Value\", \"Overall Detailed Johnson & Johnson Stock Chart\", (round(len(jnj_open)/ticks)+1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Combined Charts\n",
    "\n",
    "start_year = \"2011\"\n",
    "end_year = \"2021\"\n",
    "ticks = (int(end_year)-int(start_year))*30\n",
    "\n",
    "time_list = decrease_list_from_to(start_year,end_year, jnj_dates, [])\n",
    "apple_list = decrease_list_from_to(start_year,end_year, apple_dates, apple_open)\n",
    "jnj_list = decrease_list_from_to(start_year,end_year, jnj_dates, jnj_open)\n",
    "amazon_list = decrease_list_from_to(start_year,end_year, amazon_dates, amazon_open)\n",
    "tesla_list = decrease_list_from_to(start_year,end_year, tesla_dates, tesla_open)\n",
    "\n",
    "title = f'Chart from {start_year} to {end_year}'\n",
    "overlapping_chart(time_list, apple_list, jnj_list, amazon_list, tesla_list, \"Time\",\"Value\", title, ticks)\n",
    "\n",
    "#Highest increase in 1 day of apple\n",
    "\n",
    "craziest_one_day_diff = extreme_percentage_increase(apple_open, 1)\n",
    "biggest_daily_increase_index = craziest_one_day_diff[0]\n",
    "date = apple_dates[biggest_daily_increase_index]\n",
    "print(f'Die extremste Steigung einer Apple Aktie fand am {apple_dates[biggest_daily_increase_index]} statt')\n",
    "show_values_around_date(biggest_daily_increase_index, apple_open, apple_dates, 20, \"Time\", \"Value\", \"Biggest one day increase\", 4)\n",
    "\n",
    "\n",
    "#Check was bei Amazon passiert ist mit get index by date\n",
    "#Ganze Woche zeigen\n",
    "Die extremste Steigung einer Apple Aktie fand am 05-08-1997 statt\n",
    "\n",
    "#Highest increase in 1 week of apple\n",
    "\n",
    "craziest_one_week_diff = extreme_percentage_increase(apple_weekly_high, 1)\n",
    "biggest_increase_index = craziest_one_week_diff[0]\n",
    "show_values_around_date(biggest_increase_index, apple_weekly_high, apple_weekly_timeranges, 6, \"Time\", \"Value\", \"Biggest one week increase\", 3)\n",
    "\n",
    "week = apple_weekly_timeranges[biggest_increase_index]\n",
    "\n",
    "day_index = 1000\n",
    "day = apple_dates[day_index]\n",
    "print(f'Der Tag: {day}')\n",
    "week_index = get_weekly_timerange_index_by_date(day, apple_weekly_timeranges)\n",
    "print(week_index)\n",
    "print(apple_weekly_timeranges[week_index])\n",
    "\n",
    "Der Tag: 26-11-1984\n",
    "200\n",
    "26-11-1984 - 30-11-1984\n",
    "Extremfälle der einzelnen Unternehmen\n",
    "\n",
    "Betrachtet werden die x extremsten positiven und negativen Veränderungen eines Unternehmens in einem Tag, Woche(Monat, Jahr?)\n",
    "\n",
    "#Extremfälle Apple\n",
    "number_of_values_per_company = 5\n",
    "\n",
    "#apple daily increase \n",
    "biggest_daily_increases_apple = extreme_percentage_increase(apple_open, number_of_values_per_company)\n",
    "print(f'Highest daily apple increases:')\n",
    "print(get_dates_by_index(apple_dates, biggest_daily_increases_apple))\n",
    "\n",
    "#apple daily decrease \n",
    "biggest_daily_decreases_apple = extreme_percentage_decrease(apple_open, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest daily apple decreases:')\n",
    "print(get_dates_by_index(apple_dates, biggest_daily_decreases_apple))\n",
    "\n",
    "#apple weekly increase\n",
    "biggest_weekly_increases_apple = extreme_percentage_increase(apple_weekly_open_average, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest weekly apple increases:')\n",
    "print(get_dates_by_index(apple_weekly_timeranges, biggest_weekly_increases_apple))\n",
    "\n",
    "#apple weekly decrease\n",
    "biggest_weekly_decreases_apple = extreme_percentage_decrease(apple_weekly_open_average, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest weekly apple decreases:')\n",
    "print(get_dates_by_index(apple_weekly_timeranges, biggest_weekly_decreases_apple))\n",
    "Highest daily apple increases:\n",
    "['Der Index 3942 ist der 17-07-1996', 'Der Index 4208 ist der 05-08-1997', 'Der Index 4312 ist der 02-01-1998', 'Der Index 5069 ist der 03-01-2001', 'Der Index 7022 ist der 10-10-2008']\n",
    "\n",
    "\n",
    "Highest daily apple decreases:\n",
    "['Der Index 702 ist der 22-09-1983', 'Der Index 1731 ist der 19-10-1987', 'Der Index 2623 ist der 30-04-1991', 'Der Index 3182 ist der 15-07-1993', 'Der Index 5003 ist der 28-09-2000']\n",
    "\n",
    "\n",
    "Highest weekly apple increases:\n",
    "['Der Index 91 ist der 01-10-1982 - 07-10-1982', 'Der Index 840 ist der 24-07-1997 - 30-07-1997', 'Der Index 841 ist der 31-07-1997 - 06-08-1997', 'Der Index 862 ist der 30-12-1997 - 06-01-1998', 'Der Index 1130 ist der 01-05-2003 - 07-05-2003']\n",
    "\n",
    "\n",
    "Highest weekly apple decreases:\n",
    "['Der Index 140 ist der 20-09-1983 - 26-09-1983', 'Der Index 345 ist der 09-10-1987 - 15-10-1987', 'Der Index 346 ist der 16-10-1987 - 22-10-1987', 'Der Index 636 ist der 13-07-1993 - 19-07-1993', 'Der Index 1000 ist der 25-09-2000 - 29-09-2000']\n",
    "#Extremfälle Amazon\n",
    "\n",
    "#amazon daily increase \n",
    "biggest_daily_increases_amazon = extreme_percentage_increase(amazon_open, number_of_values_per_company)\n",
    "print(f'Highest daily amazon increases:')\n",
    "print(get_dates_by_index(amazon_dates, biggest_daily_increases_amazon))\n",
    "\n",
    "#amazon daily decrease \n",
    "biggest_daily_decreases_amazon = extreme_percentage_decrease(amazon_open, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest daily amazon decreases:')\n",
    "print(get_dates_by_index(amazon_dates, biggest_daily_decreases_amazon))\n",
    "\n",
    "#amazon weekly increase\n",
    "biggest_weekly_increases_amazon = extreme_percentage_increase(amazon_weekly_open_average, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest weekly amazon increases:')\n",
    "print(get_dates_by_index(amazon_weekly_timeranges, biggest_weekly_increases_amazon))\n",
    "\n",
    "#amazon weekly decrease\n",
    "biggest_weekly_decreases_amazon = extreme_percentage_decrease(amazon_weekly_open_average, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest weekly amazon decreases:')\n",
    "print(get_dates_by_index(amazon_weekly_timeranges, biggest_weekly_decreases_amazon))\n",
    "Highest daily amazon increases:\n",
    "['Der Index 115 ist der 28-10-1997', 'Der Index 415 ist der 07-01-1999', 'Der Index 865 ist der 18-10-2000', 'Der Index 982 ist der 06-04-2001', 'Der Index 1176 ist der 18-01-2002']\n",
    "\n",
    "\n",
    "Highest daily amazon decreases:\n",
    "['Der Index 287 ist der 07-07-1998', 'Der Index 326 ist der 31-08-1998', 'Der Index 418 ist der 12-01-1999', 'Der Index 423 ist der 20-01-1999', 'Der Index 783 ist der 22-06-2000']\n",
    "\n",
    "\n",
    "Highest weekly amazon increases:\n",
    "['Der Index 6 ist der 27-06-1997 - 03-07-1997', 'Der Index 53 ist der 04-06-1998 - 10-06-1998', 'Der Index 76 ist der 16-11-1998 - 20-11-1998', 'Der Index 82 ist der 30-12-1998 - 06-01-1999', 'Der Index 196 ist der 04-04-2001 - 10-04-2001']\n",
    "\n",
    "\n",
    "Highest weekly amazon decreases:\n",
    "['Der Index 0 ist der 15-05-1997 - 21-05-1997', 'Der Index 64 ist der 21-08-1998 - 27-08-1998', 'Der Index 98 ist der 27-04-1999 - 03-05-1999', 'Der Index 146 ist der 06-04-2000 - 12-04-2000', 'Der Index 181 ist der 14-12-2000 - 20-12-2000']\n",
    "#Extremfälle Tesla\n",
    "\n",
    "#tesla daily increase \n",
    "biggest_daily_increases_tesla = extreme_percentage_increase(tesla_open, number_of_values_per_company)\n",
    "print(f'Highest daily tesla increases:')\n",
    "print(get_dates_by_index(tesla_dates, biggest_daily_increases_tesla))\n",
    "\n",
    "#tesla daily decrease \n",
    "biggest_daily_decreases_tesla = extreme_percentage_decrease(tesla_open, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest daily tesla decreases:')\n",
    "print(get_dates_by_index(tesla_dates, biggest_daily_decreases_tesla))\n",
    "\n",
    "#tesla weekly increase\n",
    "biggest_weekly_increases_tesla = extreme_percentage_increase(tesla_weekly_open_average, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest weekly tesla increases:')\n",
    "print(get_dates_by_index(tesla_weekly_timeranges, biggest_weekly_increases_tesla))\n",
    "\n",
    "#tesla weekly decrease\n",
    "biggest_weekly_decreases_tesla = extreme_percentage_decrease(tesla_weekly_open_average, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest weekly tesla decreases:')\n",
    "print(get_dates_by_index(tesla_weekly_timeranges, biggest_weekly_decreases_tesla))\n",
    "Highest daily tesla increases:\n",
    "['Der Index 0 ist der 29-06-2010', 'Der Index 719 ist der 08-05-2013', 'Der Index 892 ist der 14-01-2014', 'Der Index 2415 ist der 03-02-2020', 'Der Index 2525 ist der 10-07-2020']\n",
    "\n",
    "\n",
    "Highest daily tesla decreases:\n",
    "['Der Index 4 ist der 06-07-2010', 'Der Index 766 ist der 16-07-2013', 'Der Index 2443 ist der 13-03-2020', 'Der Index 2534 ist der 23-07-2020', 'Der Index 2934 ist der 23-02-2022']\n",
    "\n",
    "\n",
    "Highest weekly tesla increases:\n",
    "['Der Index 143 ist der 02-05-2013 - 08-05-2013', 'Der Index 482 ist der 27-01-2020 - 31-01-2020', 'Der Index 489 ist der 17-03-2020 - 23-03-2020', 'Der Index 492 ist der 07-04-2020 - 14-04-2020', 'Der Index 503 ist der 25-06-2020 - 01-07-2020']\n",
    "\n",
    "\n",
    "Highest weekly tesla decreases:\n",
    "['Der Index 0 ist der 29-06-2010 - 06-07-2010', 'Der Index 485 ist der 18-02-2020 - 24-02-2020', 'Der Index 487 ist der 03-03-2020 - 09-03-2020', 'Der Index 488 ist der 10-03-2020 - 16-03-2020', 'Der Index 512 ist der 28-08-2020 - 03-09-2020']\n",
    "#Extremfälle Johnson & Johnson\n",
    "\n",
    "#jnj daily increase \n",
    "biggest_daily_increases_jnj = extreme_percentage_increase(jnj_open, number_of_values_per_company)\n",
    "print(f'Highest daily Johnson & Johnson increases:')\n",
    "print(get_dates_by_index(jnj_dates, biggest_daily_increases_jnj))\n",
    "\n",
    "#jnj daily decrease \n",
    "biggest_daily_decreases_jnj = extreme_percentage_decrease(jnj_open, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest daily Johnson & Johnson decreases:')\n",
    "print(get_dates_by_index(jnj_dates, biggest_daily_decreases_jnj))\n",
    "\n",
    "#jnj weekly increase\n",
    "biggest_weekly_increases_jnj = extreme_percentage_increase(jnj_weekly_open_average, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest weekly Johnson & Johnson increases:')\n",
    "print(get_dates_by_index(jnj_weekly_timeranges, biggest_weekly_increases_jnj))\n",
    "\n",
    "#jnj weekly decrease\n",
    "biggest_weekly_decreases_jnj = extreme_percentage_decrease(jnj_weekly_open_average, number_of_values_per_company)\n",
    "print(f'\\n\\nHighest weekly Johnson & Johnson decreases:')\n",
    "print(get_dates_by_index(jnj_weekly_timeranges, biggest_weekly_decreases_jnj))\n",
    "Highest daily Johnson & Johnson increases:\n",
    "['Der Index 1205 ist der 09-10-1974', 'Der Index 4109 ist der 08-04-1986', 'Der Index 4505 ist der 29-10-1987', 'Der Index 7632 ist der 15-03-2000', 'Der Index 9789 ist der 13-10-2008']\n",
    "\n",
    "\n",
    "Highest daily Johnson & Johnson decreases:\n",
    "['Der Index 4496 ist der 16-10-1987', 'Der Index 4499 ist der 21-10-1987', 'Der Index 8218 ist der 18-07-2002', 'Der Index 9787 ist der 09-10-2008', 'Der Index 12350 ist der 14-12-2018']\n",
    "\n",
    "\n",
    "Highest weekly Johnson & Johnson increases:\n",
    "['Der Index 20 ist der 26-05-1970 - 01-06-1970', 'Der Index 257 ist der 03-02-1975 - 07-02-1975', 'Der Index 821 ist der 02-04-1986 - 08-04-1986', 'Der Index 900 ist der 22-10-1987 - 28-10-1987', 'Der Index 1644 ist der 22-07-2002 - 26-07-2002']\n",
    "\n",
    "\n",
    "Highest weekly Johnson & Johnson decreases:\n",
    "['Der Index 643 ist der 23-09-1982 - 29-09-1982', 'Der Index 898 ist der 08-10-1987 - 14-10-1987', 'Der Index 899 ist der 15-10-1987 - 21-10-1987', 'Der Index 1527 ist der 20-03-2000 - 24-03-2000', 'Der Index 1956 ist der 30-09-2008 - 06-10-2008']\n",
    "Darstellung von einem Extrempunkt eines Unternehmens\n",
    "\n",
    "#Eigenschaft des Punktes\n",
    "\n",
    "#Tages Wert oder Wochen Wert?\n",
    "daily_value = True\n",
    "\n",
    "#biggest_daily/weekly_increase/decrease_apple/amazon/tesla/jnj\n",
    "to_be_shown_value_index = 0\n",
    "\n",
    "#bei tagen: apple/tesla/amazon/jnj_dates\n",
    "#bei wochen: apple/tesla/amazon/jnj_weekly_timeranges\n",
    "date = amazon_dates[to_be_shown_value_index]\n",
    "\n",
    "values_around_date = 100\n",
    "\n",
    "daily_ticks = 1\n",
    "if(values_around_date> 15):\n",
    "    daily_ticks = 8\n",
    "else:\n",
    "    daily_ticks = round(values_around_date/2)+1\n",
    "    \n",
    "weekly_ticks = 1\n",
    "if(values_around_date> 10):\n",
    "    weekly_ticks = 5\n",
    "else:\n",
    "    weekly_ticks = round(values_around_date/2)+1\n",
    "#show apple chart\n",
    "\n",
    "if(daily_value):\n",
    "    date_index = get_index_by_date(apple_dates, date)\n",
    "    show_values_around_date(date_index, apple_open, apple_dates, values_around_date, \"Time\", \"Value\", \"Apple: One day increase\", daily_ticks)\n",
    "    \n",
    "else:\n",
    "\n",
    "    date_index = get_weekly_timerange_index_by_date(date[:10], apple_weekly_timeranges)\n",
    "    show_values_around_date(date_index, apple_weekly_open_average, apple_weekly_timeranges, values_around_date, \"Time\", \"Value\", \"Apple: One week increase\", weekly_ticks)\n",
    "    \n",
    "#show tesla chart\n",
    "if(int(date[6:10]) > 2010):\n",
    "    if(daily_value):\n",
    "        date_index = get_index_by_date(tesla_dates, date)\n",
    "        if(date_index != 0):\n",
    "            show_values_around_date(date_index, tesla_open, tesla_dates, values_around_date, \"Time\", \"Value\", \"Tesla: One day increase\", daily_ticks)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        date_index = get_weekly_timerange_index_by_date(date[:10], tesla_weekly_timeranges)\n",
    "        show_values_around_date(date_index, tesla_weekly_open_average, tesla_weekly_timeranges, values_around_date, \"Time\", \"Value\", \"Tesla: One week increase\", weekly_ticks)\n",
    "else: \n",
    "    print(\"\\n\\n\\n\\nKeine Tesla Daten gefunden\\n\\n\\n\\n\")\n",
    "    \n",
    "    \n",
    "#show amazon chart\n",
    "if(daily_value):\n",
    "    date_index = get_index_by_date(amazon_dates, date)\n",
    "    show_values_around_date(date_index, amazon_open, amazon_dates, values_around_date, \"Time\", \"Value\", \"Amazon: One day increase\", daily_ticks)\n",
    "    \n",
    "else:\n",
    "\n",
    "    date_index = get_weekly_timerange_index_by_date(date[:10], amazon_weekly_timeranges)\n",
    "    show_values_around_date(date_index, amazon_weekly_open_average, amazon_weekly_timeranges, values_around_date, \"Time\", \"Value\", \"Amazon: One week increase\", weekly_ticks)\n",
    "    \n",
    "#show jnj chart\n",
    "if(daily_value):\n",
    "    date_index = get_index_by_date(jnj_dates, date)\n",
    "    show_values_around_date(date_index, jnj_open, jnj_dates, values_around_date, \"Time\", \"Value\", \"Johnson & Johnson: One day increase\", daily_ticks)\n",
    "    \n",
    "else:\n",
    "\n",
    "    date_index = get_weekly_timerange_index_by_date(date[:10], jnj_weekly_timeranges)\n",
    "    show_values_around_date(date_index, jnj_weekly_open_average, jnj_weekly_timeranges, values_around_date, \"Time\", \"Value\", \"Johnson & Johnson: One week increase\", weekly_ticks)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Keine Tesla Daten gefunden\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Datum: Tag, Monat, Jahr (xx-xx-xxxx)\n",
    "start_date = \"01-07-1999\"\n",
    "end_date = \"01-07-2013\"\n",
    "tick_distance = (int(end_date[6:10])-int(start_date[6:10]))*24\n",
    "\n",
    "\n",
    "title_apple = f'Apple chart from {start_date} to {end_date}'\n",
    "show_timerange(start_date, end_date, apple_dates, apple_open, \"Date\", \"Value\", title_apple, tick_distance)\n",
    "\n",
    "\n",
    "title_amazon = f'Amazon chart from {start_date} to {end_date}'\n",
    "show_timerange(start_date, end_date, amazon_dates, amazon_open, \"Date\", \"Value\", title_amazon, tick_distance)\n",
    "\n",
    "\n",
    "title_jnj = f'Johnson & Johnson chart from {start_date} to {end_date}'\n",
    "show_timerange(start_date, end_date, jnj_dates, jnj_open, \"Date\", \"Value\", title_jnj, tick_distance)\n",
    "\n",
    "\n",
    "title_tesla = f'Tesla chart from {start_date} to {end_date}'\n",
    "show_timerange(start_date, end_date, tesla_dates, tesla_open, \"Date\", \"Value\", title_tesla, tick_distance)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Charts of Apple\n",
    "\n",
    "apple_waggle_list = get_daily_diff_list(apple_open)\n",
    "title_apple = f'Apple daily difference chart from {apple_dates[0]} to {apple_dates[len(apple_dates)-1]}'\n",
    "show_timerange(apple_dates[0], apple_dates[len(apple_dates)-1], apple_dates, apple_waggle_list, \"Date\", \"Value\", title_apple, 1500)\n",
    "\n",
    "start_date = \"01-01-1995\"\n",
    "end_date = \"01-07-2022\"\n",
    "tick_distance = (int(end_date[6:10])-int(start_date[6:10]))*24\n",
    "\n",
    "title_apple = f'Apple daily difference chart from {start_date} to {end_date}'\n",
    "show_timerange(start_date, end_date, apple_dates, apple_waggle_list, \"Date\", \"Value\", title_apple, tick_distance)\n",
    "\n",
    "#daily\n",
    "min_percentage_diff = 5\n",
    "print_waggle_values(apple_waggle_list, apple_dates, min_percentage_diff)\n",
    "\n",
    "print_average_diff_per_year(apple_waggle_list, apple_dates, start_date[6:10], end_date[6:10])\n",
    "\n",
    "\n",
    "Prozentuale Unterschiede mit mindestens 5 zum Vortag:\n",
    "Prozentualer Unterschied von -7.31 am 16-12-1980\n",
    "Prozentualer Unterschied von 6.1 am 19-12-1980\n",
    "Prozentualer Unterschied von 5.26 am 24-12-1980\n",
    "Prozentualer Unterschied von 9.23 am 26-12-1980\n",
    "Prozentualer Unterschied von 5.62 am 19-01-1981\n",
    "Prozentualer Unterschied von -5.0 am 30-01-1981\n",
    "Prozentualer Unterschied von -6.14 am 02-02-1981\n",
    "Prozentualer Unterschied von -5.51 am 19-02-1981\n",
    "Prozentualer Unterschied von -5.34 am 20-02-1981\n",
    "Prozentualer Unterschied von 5.21 am 25-02-1981\n",
    "Prozentualer Unterschied von -8.21 am 09-03-1981\n",
    "Prozentualer Unterschied von 6.19 am 18-03-1981\n",
    "Prozentualer Unterschied von 8.21 am 02-04-1981\n",
    "Prozentualer Unterschied von -5.63 am 16-04-1981\n",
    "Prozentualer Unterschied von 6.8 am 21-04-1981\n",
    "Prozentualer Unterschied von 5.73 am 21-05-1981\n",
    "Prozentualer Unterschied von 5.18 am 27-05-1981\n",
    "Prozentualer Unterschied von -7.93 am 30-06-1981\n",
    "Prozentualer Unterschied von -7.18 am 09-07-1981\n",
    "Prozentualer Unterschied von -7.73 am 10-07-1981\n",
    "Prozentualer Unterschied von -6.28 am 20-07-1981\n",
    "Prozentualer Unterschied von -5.18 am 22-07-1981\n",
    "Prozentualer Unterschied von -5.78 am 21-08-1981\n",
    "Prozentualer Unterschied von -6.75 am 24-08-1981\n",
    "Prozentualer Unterschied von 5.23 am 28-08-1981\n",
    "Prozentualer Unterschied von 6.21 am 01-09-1981\n",
    "Prozentualer Unterschied von -12.12 am 25-09-1981\n",
    "Prozentualer Unterschied von 5.22 am 29-09-1981\n",
    "Prozentualer Unterschied von 8.2 am 02-10-1981\n",
    "Prozentualer Unterschied von 5.15 am 07-10-1981\n",
    "Prozentualer Unterschied von -5.2 am 14-10-1981\n",
    "Prozentualer Unterschied von 5.37 am 20-10-1981\n",
    "Prozentualer Unterschied von -7.1 am 05-11-1981\n",
    "Prozentualer Unterschied von -6.41 am 13-11-1981\n",
    "Prozentualer Unterschied von 8.33 am 17-12-1981\n",
    "Prozentualer Unterschied von 8.28 am 18-12-1981\n",
    "Prozentualer Unterschied von -7.23 am 07-01-1982\n",
    "Prozentualer Unterschied von -5.66 am 11-01-1982\n",
    "Prozentualer Unterschied von 6.67 am 15-01-1982\n",
    "Prozentualer Unterschied von -5.7 am 08-02-1982\n",
    "Prozentualer Unterschied von -7.59 am 05-03-1982\n",
    "Prozentualer Unterschied von -5.39 am 12-03-1982\n",
    "Prozentualer Unterschied von 7.02 am 18-03-1982\n",
    "Prozentualer Unterschied von 9.02 am 19-03-1982\n",
    "Prozentualer Unterschied von 7.52 am 22-03-1982\n",
    "Prozentualer Unterschied von -5.63 am 24-03-1982\n",
    "Prozentualer Unterschied von 5.18 am 01-04-1982\n",
    "Prozentualer Unterschied von -7.86 am 13-04-1982\n",
    "Prozentualer Unterschied von -5.22 am 20-04-1982\n",
    "Prozentualer Unterschied von 6.45 am 13-07-1982\n",
    "Prozentualer Unterschied von 6.54 am 20-07-1982\n",
    "Prozentualer Unterschied von -5.41 am 03-08-1982\n",
    "Prozentualer Unterschied von 6.06 am 10-08-1982\n",
    "Prozentualer Unterschied von 6.54 am 17-08-1982\n",
    "Prozentualer Unterschied von 6.98 am 25-08-1982\n",
    "Prozentualer Unterschied von 5.11 am 31-08-1982\n",
    "Prozentualer Unterschied von 7.95 am 07-10-1982\n",
    "Prozentualer Unterschied von 7.36 am 08-10-1982\n",
    "Prozentualer Unterschied von 7.43 am 11-10-1982\n",
    "Prozentualer Unterschied von 5.73 am 21-10-1982\n",
    "Prozentualer Unterschied von -5.8 am 26-10-1982\n",
    "Prozentualer Unterschied von 6.4 am 02-11-1982\n",
    "Prozentualer Unterschied von 6.02 am 03-11-1982\n",
    "Prozentualer Unterschied von 7.42 am 04-11-1982\n",
    "Prozentualer Unterschied von 6.45 am 12-11-1982\n",
    "Prozentualer Unterschied von -5.14 am 17-11-1982\n",
    "Prozentualer Unterschied von -7.69 am 23-11-1982\n",
    "Prozentualer Unterschied von 10.39 am 01-12-1982\n",
    "Prozentualer Unterschied von 5.51 am 07-12-1982\n",
    "Prozentualer Unterschied von -6.45 am 13-12-1982\n",
    "Prozentualer Unterschied von 5.7 am 05-01-1983\n",
    "Prozentualer Unterschied von -5.58 am 10-01-1983\n",
    "Prozentualer Unterschied von 6.88 am 17-01-1983\n",
    "Prozentualer Unterschied von 11.15 am 21-01-1983\n",
    "Prozentualer Unterschied von -5.69 am 25-01-1983\n",
    "Prozentualer Unterschied von 6.89 am 28-01-1983\n",
    "Prozentualer Unterschied von 7.4 am 11-02-1983\n",
    "Prozentualer Unterschied von 5.71 am 12-04-1983\n",
    "Prozentualer Unterschied von 10.22 am 21-04-1983\n",
    "Prozentualer Unterschied von 6.19 am 05-05-1983\n",
    "Prozentualer Unterschied von 6.55 am 06-05-1983\n",
    "Prozentualer Unterschied von 5.08 am 23-05-1983\n",
    "Prozentualer Unterschied von 5.22 am 25-05-1983\n",
    "Prozentualer Unterschied von -5.4 am 28-06-1983\n",
    "Prozentualer Unterschied von -6.95 am 29-06-1983\n",
    "Prozentualer Unterschied von -5.71 am 21-07-1983\n",
    "Prozentualer Unterschied von 5.15 am 22-07-1983\n",
    "Prozentualer Unterschied von -9.28 am 27-07-1983\n",
    "Prozentualer Unterschied von -7.35 am 28-07-1983\n",
    "Prozentualer Unterschied von -6.21 am 29-07-1983\n",
    "Prozentualer Unterschied von -5.58 am 24-08-1983\n",
    "Prozentualer Unterschied von 6.0 am 31-08-1983\n",
    "Prozentualer Unterschied von 12.45 am 01-09-1983\n",
    "Prozentualer Unterschied von 6.53 am 06-09-1983\n",
    "Prozentualer Unterschied von -11.78 am 08-09-1983\n",
    "Prozentualer Unterschied von -8.3 am 09-09-1983\n",
    "Prozentualer Unterschied von 8.94 am 20-09-1983\n",
    "Prozentualer Unterschied von -20.64 am 23-09-1983\n",
    "Prozentualer Unterschied von -5.53 am 28-09-1983\n",
    "Prozentualer Unterschied von -9.55 am 10-10-1983\n",
    "Prozentualer Unterschied von 12.26 am 13-10-1983\n",
    "Prozentualer Unterschied von 5.75 am 14-10-1983\n",
    "Prozentualer Unterschied von -8.79 am 18-10-1983\n",
    "Prozentualer Unterschied von -6.63 am 19-10-1983\n",
    "Prozentualer Unterschied von 10.97 am 20-10-1983\n",
    "Prozentualer Unterschied von -5.23 am 21-10-1983\n",
    "Prozentualer Unterschied von 6.29 am 25-10-1983\n",
    "Prozentualer Unterschied von -5.29 am 27-10-1983\n",
    "Prozentualer Unterschied von 7.1 am 01-11-1983\n",
    "Prozentualer Unterschied von -6.92 am 04-11-1983\n",
    "Prozentualer Unterschied von -7.69 am 08-11-1983\n",
    "Prozentualer Unterschied von -8.33 am 09-11-1983\n",
    "Prozentualer Unterschied von 7.69 am 10-11-1983\n",
    "Prozentualer Unterschied von -5.23 am 25-11-1983\n",
    "Prozentualer Unterschied von 5.64 am 04-01-1984\n",
    "Prozentualer Unterschied von 8.25 am 05-01-1984\n",
    "Prozentualer Unterschied von -5.41 am 10-01-1984\n",
    "Prozentualer Unterschied von 5.24 am 11-01-1984\n",
    "Prozentualer Unterschied von -5.63 am 25-01-1984\n",
    "Prozentualer Unterschied von -5.43 am 30-01-1984\n",
    "Prozentualer Unterschied von -5.26 am 31-01-1984\n",
    "Prozentualer Unterschied von -5.1 am 07-02-1984\n",
    "Prozentualer Unterschied von 5.67 am 15-02-1984\n",
    "Prozentualer Unterschied von 5.0 am 22-02-1984\n",
    "Prozentualer Unterschied von -5.56 am 29-02-1984\n",
    "Prozentualer Unterschied von 5.1 am 13-04-1984\n",
    "Prozentualer Unterschied von 7.21 am 27-04-1984\n",
    "Prozentualer Unterschied von 5.39 am 01-05-1984\n",
    "Prozentualer Unterschied von 5.2 am 09-05-1984\n",
    "Prozentualer Unterschied von 7.14 am 22-05-1984\n",
    "Prozentualer Unterschied von 6.47 am 25-07-1984\n",
    "Prozentualer Unterschied von -5.99 am 31-07-1984\n",
    "Prozentualer Unterschied von 13.47 am 06-08-1984\n",
    "Prozentualer Unterschied von 6.85 am 07-08-1984\n",
    "Prozentualer Unterschied von 5.26 am 14-08-1984\n",
    "Prozentualer Unterschied von 5.53 am 06-11-1984\n",
    "Prozentualer Unterschied von 5.08 am 28-11-1984\n",
    "Prozentualer Unterschied von 5.02 am 05-12-1984\n",
    "Prozentualer Unterschied von 6.02 am 18-12-1984\n",
    "Prozentualer Unterschied von -7.03 am 18-01-1985\n",
    "Prozentualer Unterschied von -6.08 am 28-02-1985\n",
    "Prozentualer Unterschied von -10.15 am 08-03-1985\n",
    "Prozentualer Unterschied von -5.44 am 14-03-1985\n",
    "Prozentualer Unterschied von 5.17 am 18-03-1985\n",
    "Prozentualer Unterschied von -5.99 am 09-04-1985\n",
    "Prozentualer Unterschied von 7.01 am 10-04-1985\n",
    "Prozentualer Unterschied von -6.67 am 03-05-1985\n",
    "Prozentualer Unterschied von 6.87 am 16-05-1985\n",
    "Prozentualer Unterschied von -9.49 am 28-05-1985\n",
    "Prozentualer Unterschied von -5.56 am 14-06-1985\n",
    "Prozentualer Unterschied von 6.98 am 24-06-1985\n",
    "Prozentualer Unterschied von 6.56 am 18-09-1985\n",
    "Prozentualer Unterschied von 5.88 am 16-10-1985\n",
    "Prozentualer Unterschied von 5.56 am 30-10-1985\n",
    "Prozentualer Unterschied von 5.62 am 30-01-1986\n",
    "Prozentualer Unterschied von 5.05 am 17-03-1986\n",
    "Prozentualer Unterschied von 5.91 am 25-04-1986\n",
    "Prozentualer Unterschied von 5.74 am 06-05-1986\n",
    "Prozentualer Unterschied von 8.99 am 13-05-1986\n",
    "Prozentualer Unterschied von -6.31 am 08-07-1986\n",
    "Prozentualer Unterschied von -5.72 am 15-07-1986\n",
    "Prozentualer Unterschied von -5.63 am 17-07-1986\n",
    "Prozentualer Unterschied von 5.11 am 14-08-1986\n",
    "Prozentualer Unterschied von -6.4 am 03-09-1986\n",
    "Prozentualer Unterschied von -6.14 am 12-09-1986\n",
    "Prozentualer Unterschied von 5.28 am 17-09-1986\n",
    "Prozentualer Unterschied von 5.22 am 23-09-1986\n",
    "Prozentualer Unterschied von 5.59 am 26-11-1986\n",
    "Prozentualer Unterschied von 8.12 am 15-01-1987\n",
    "Prozentualer Unterschied von 12.82 am 20-01-1987\n",
    "Prozentualer Unterschied von -7.5 am 21-01-1987\n",
    "Prozentualer Unterschied von 7.42 am 23-01-1987\n",
    "Prozentualer Unterschied von 6.0 am 28-01-1987\n",
    "Prozentualer Unterschied von 5.42 am 29-01-1987\n",
    "Prozentualer Unterschied von 7.55 am 12-02-1987\n",
    "Prozentualer Unterschied von 5.97 am 17-02-1987\n",
    "Prozentualer Unterschied von 7.24 am 18-02-1987\n",
    "Prozentualer Unterschied von 6.11 am 26-02-1987\n",
    "Prozentualer Unterschied von -5.58 am 30-03-1987\n",
    "Prozentualer Unterschied von 8.33 am 02-04-1987\n",
    "Prozentualer Unterschied von 9.07 am 22-04-1987\n",
    "Prozentualer Unterschied von 5.06 am 16-06-1987\n",
    "Prozentualer Unterschied von -5.1 am 09-07-1987\n",
    "Prozentualer Unterschied von 5.13 am 14-07-1987\n",
    "Prozentualer Unterschied von 6.94 am 07-08-1987\n",
    "Prozentualer Unterschied von -5.02 am 02-09-1987\n",
    "Prozentualer Unterschied von 5.97 am 10-09-1987\n",
    "Prozentualer Unterschied von 7.18 am 23-09-1987\n",
    "Prozentualer Unterschied von -6.72 am 07-10-1987\n",
    "Prozentualer Unterschied von -7.66 am 19-10-1987\n",
    "Prozentualer Unterschied von -20.21 am 20-10-1987\n",
    "Prozentualer Unterschied von -8.92 am 23-10-1987\n",
    "Prozentualer Unterschied von -14.49 am 27-10-1987\n",
    "Prozentualer Unterschied von 11.38 am 29-10-1987\n",
    "Prozentualer Unterschied von 16.79 am 30-10-1987\n",
    "Prozentualer Unterschied von -6.58 am 04-11-1987\n",
    "Prozentualer Unterschied von 5.52 am 06-11-1987\n",
    "Prozentualer Unterschied von -6.85 am 20-11-1987\n",
    "Prozentualer Unterschied von -6.9 am 30-11-1987\n",
    "Prozentualer Unterschied von -8.33 am 04-12-1987\n",
    "Prozentualer Unterschied von 8.06 am 08-12-1987\n",
    "Prozentualer Unterschied von 9.42 am 15-12-1987\n",
    "Prozentualer Unterschied von 7.28 am 17-12-1987\n",
    "Prozentualer Unterschied von 7.6 am 05-01-1988\n",
    "Prozentualer Unterschied von -10.11 am 11-01-1988\n",
    "Prozentualer Unterschied von 7.5 am 12-01-1988\n",
    "Prozentualer Unterschied von -5.81 am 21-01-1988\n",
    "Prozentualer Unterschied von -5.11 am 24-03-1988\n",
    "Prozentualer Unterschied von 5.7 am 07-04-1988\n",
    "Prozentualer Unterschied von -5.29 am 22-08-1988\n",
    "Prozentualer Unterschied von 5.81 am 12-09-1988\n",
    "Prozentualer Unterschied von -5.78 am 18-01-1989\n",
    "Prozentualer Unterschied von -6.13 am 27-01-1989\n",
    "Prozentualer Unterschied von 5.59 am 05-05-1989\n",
    "Prozentualer Unterschied von -9.6 am 16-06-1989\n",
    "Prozentualer Unterschied von -5.68 am 14-08-1989\n",
    "Prozentualer Unterschied von -8.21 am 16-10-1989\n",
    "Prozentualer Unterschied von -6.11 am 07-12-1989\n",
    "Prozentualer Unterschied von -8.28 am 13-12-1989\n",
    "Prozentualer Unterschied von 7.8 am 03-01-1990\n",
    "Prozentualer Unterschied von -5.52 am 12-01-1990\n",
    "Prozentualer Unterschied von -5.04 am 18-01-1990\n",
    "Prozentualer Unterschied von 5.38 am 25-01-1990\n",
    "Prozentualer Unterschied von -5.04 am 07-02-1990\n",
    "Prozentualer Unterschied von 9.59 am 16-03-1990\n",
    "Prozentualer Unterschied von -6.51 am 25-05-1990\n",
    "Prozentualer Unterschied von -8.43 am 19-07-1990\n",
    "Prozentualer Unterschied von 5.45 am 03-08-1990\n",
    "Prozentualer Unterschied von -10.34 am 06-08-1990\n",
    "Prozentualer Unterschied von 5.26 am 14-08-1990\n",
    "Prozentualer Unterschied von -5.19 am 20-08-1990\n",
    "Prozentualer Unterschied von -7.43 am 23-08-1990\n",
    "Prozentualer Unterschied von -5.0 am 28-09-1990\n",
    "Prozentualer Unterschied von 5.08 am 02-10-1990\n",
    "Prozentualer Unterschied von -10.08 am 04-10-1990\n",
    "Prozentualer Unterschied von 6.48 am 08-10-1990\n",
    "Prozentualer Unterschied von 5.61 am 12-10-1990\n",
    "Prozentualer Unterschied von -8.18 am 17-10-1990\n",
    "Prozentualer Unterschied von 17.92 am 19-10-1990\n",
    "Prozentualer Unterschied von 5.74 am 05-11-1990\n",
    "Prozentualer Unterschied von 6.06 am 09-11-1990\n",
    "Prozentualer Unterschied von 7.14 am 06-12-1990\n",
    "Prozentualer Unterschied von 5.13 am 18-12-1990\n",
    "Prozentualer Unterschied von 7.27 am 21-12-1990\n",
    "Prozentualer Unterschied von 11.7 am 17-01-1991\n",
    "Prozentualer Unterschied von -7.14 am 18-01-1991\n",
    "Prozentualer Unterschied von 8.47 am 06-03-1991\n",
    "Prozentualer Unterschied von 6.69 am 08-03-1991\n",
    "Prozentualer Unterschied von 6.37 am 14-03-1991\n",
    "Prozentualer Unterschied von -6.23 am 22-03-1991\n",
    "Prozentualer Unterschied von 8.11 am 27-03-1991\n",
    "Prozentualer Unterschied von 5.07 am 03-04-1991\n",
    "Prozentualer Unterschied von 5.54 am 12-04-1991\n",
    "Prozentualer Unterschied von -13.64 am 15-04-1991\n",
    "Prozentualer Unterschied von -16.88 am 01-05-1991\n",
    "Prozentualer Unterschied von 5.15 am 07-05-1991\n",
    "Prozentualer Unterschied von 5.32 am 04-06-1991\n",
    "Prozentualer Unterschied von 5.23 am 08-07-1991\n",
    "Prozentualer Unterschied von 8.15 am 02-08-1991\n",
    "Prozentualer Unterschied von 5.29 am 14-08-1991\n",
    "Prozentualer Unterschied von -6.16 am 19-08-1991\n",
    "Prozentualer Unterschied von 5.08 am 02-10-1991\n",
    "Prozentualer Unterschied von 5.67 am 08-11-1991\n",
    "Prozentualer Unterschied von -8.26 am 18-11-1991\n",
    "Prozentualer Unterschied von 7.62 am 03-01-1992\n",
    "Prozentualer Unterschied von 6.27 am 17-01-1992\n",
    "Prozentualer Unterschied von -6.56 am 08-04-1992\n",
    "Prozentualer Unterschied von 5.53 am 30-04-1992\n",
    "Prozentualer Unterschied von -5.31 am 17-06-1992\n",
    "Prozentualer Unterschied von -5.1 am 06-07-1992\n",
    "Prozentualer Unterschied von -5.76 am 17-07-1992\n",
    "Prozentualer Unterschied von -5.08 am 07-08-1992\n",
    "Prozentualer Unterschied von 5.38 am 03-09-1992\n",
    "Prozentualer Unterschied von 5.64 am 27-10-1992\n",
    "Prozentualer Unterschied von -5.23 am 24-02-1993\n",
    "Prozentualer Unterschied von -10.55 am 08-06-1993\n",
    "Prozentualer Unterschied von -7.69 am 09-06-1993\n",
    "Prozentualer Unterschied von -6.63 am 16-06-1993\n",
    "Prozentualer Unterschied von 5.44 am 13-07-1993\n",
    "Prozentualer Unterschied von -5.16 am 14-07-1993\n",
    "Prozentualer Unterschied von -23.49 am 16-07-1993\n",
    "Prozentualer Unterschied von -6.25 am 20-07-1993\n",
    "Prozentualer Unterschied von 5.13 am 05-08-1993\n",
    "Prozentualer Unterschied von -7.62 am 14-09-1993\n",
    "Prozentualer Unterschied von 5.15 am 23-09-1993\n",
    "Prozentualer Unterschied von -5.21 am 01-10-1993\n",
    "Prozentualer Unterschied von 5.49 am 12-10-1993\n",
    "Prozentualer Unterschied von 15.62 am 15-10-1993\n",
    "Prozentualer Unterschied von 10.91 am 22-10-1993\n",
    "Prozentualer Unterschied von 5.83 am 28-10-1993\n",
    "Prozentualer Unterschied von 5.6 am 03-11-1993\n",
    "Prozentualer Unterschied von 6.25 am 17-11-1993\n",
    "Prozentualer Unterschied von -6.61 am 13-12-1993\n",
    "Prozentualer Unterschied von 6.3 am 06-01-1994\n",
    "Prozentualer Unterschied von -5.19 am 07-01-1994\n",
    "Prozentualer Unterschied von -6.98 am 13-01-1994\n",
    "Prozentualer Unterschied von 12.71 am 21-01-1994\n",
    "Prozentualer Unterschied von 7.46 am 08-02-1994\n",
    "Prozentualer Unterschied von -5.04 am 28-03-1994\n",
    "Prozentualer Unterschied von -5.43 am 14-04-1994\n",
    "Prozentualer Unterschied von 9.65 am 22-04-1994\n",
    "Prozentualer Unterschied von 5.88 am 26-04-1994\n",
    "Prozentualer Unterschied von 7.26 am 05-05-1994\n",
    "Prozentualer Unterschied von -6.82 am 09-06-1994\n",
    "Prozentualer Unterschied von 5.85 am 10-06-1994\n",
    "Prozentualer Unterschied von -6.31 am 17-06-1994\n",
    "Prozentualer Unterschied von 5.56 am 13-07-1994\n",
    "Prozentualer Unterschied von 18.78 am 22-07-1994\n",
    "Prozentualer Unterschied von 5.49 am 01-08-1994\n",
    "Prozentualer Unterschied von 11.15 am 06-10-1994\n",
    "Prozentualer Unterschied von 11.45 am 11-10-1994\n",
    "Prozentualer Unterschied von 7.57 am 13-10-1994\n",
    "Prozentualer Unterschied von 5.23 am 09-11-1994\n",
    "Prozentualer Unterschied von -5.62 am 22-11-1994\n",
    "Prozentualer Unterschied von 5.03 am 20-12-1994\n",
    "Prozentualer Unterschied von 6.05 am 06-01-1995\n",
    "Prozentualer Unterschied von 6.06 am 11-01-1995\n",
    "Prozentualer Unterschied von 5.43 am 12-01-1995\n",
    "Prozentualer Unterschied von -10.9 am 23-01-1995\n",
    "Prozentualer Unterschied von -6.51 am 25-01-1995\n",
    "Prozentualer Unterschied von -7.19 am 15-03-1995\n",
    "Prozentualer Unterschied von -6.21 am 29-03-1995\n",
    "Prozentualer Unterschied von 9.16 am 06-04-1995\n",
    "Prozentualer Unterschied von 5.5 am 15-05-1995\n",
    "Prozentualer Unterschied von -6.52 am 21-07-1995\n",
    "Prozentualer Unterschied von -9.67 am 15-09-1995\n",
    "Prozentualer Unterschied von 5.3 am 08-11-1995\n",
    "Prozentualer Unterschied von 5.59 am 04-12-1995\n",
    "Prozentualer Unterschied von -8.68 am 15-12-1995\n",
    "Prozentualer Unterschied von -6.76 am 19-12-1995\n",
    "Prozentualer Unterschied von 9.09 am 08-01-1996\n",
    "Prozentualer Unterschied von -6.14 am 10-01-1996\n",
    "Prozentualer Unterschied von 6.51 am 12-01-1996\n",
    "Prozentualer Unterschied von -5.7 am 19-01-1996\n",
    "Prozentualer Unterschied von 13.45 am 23-01-1996\n",
    "Prozentualer Unterschied von -6.9 am 30-01-1996\n",
    "Prozentualer Unterschied von 5.0 am 02-02-1996\n",
    "Prozentualer Unterschied von -7.56 am 08-02-1996\n",
    "Prozentualer Unterschied von -5.88 am 26-03-1996\n",
    "Prozentualer Unterschied von 6.45 am 28-03-1996\n",
    "Prozentualer Unterschied von 5.03 am 10-04-1996\n",
    "Prozentualer Unterschied von 6.03 am 07-05-1996\n",
    "Prozentualer Unterschied von -5.24 am 30-05-1996\n",
    "Prozentualer Unterschied von -7.25 am 04-06-1996\n",
    "Prozentualer Unterschied von 5.73 am 05-06-1996\n",
    "Prozentualer Unterschied von -6.78 am 26-06-1996\n",
    "Prozentualer Unterschied von 23.74 am 18-07-1996\n",
    "Prozentualer Unterschied von 5.63 am 25-07-1996\n",
    "Prozentualer Unterschied von -6.08 am 31-07-1996\n",
    "Prozentualer Unterschied von 5.06 am 12-08-1996\n",
    "Prozentualer Unterschied von 6.7 am 20-08-1996\n",
    "Prozentualer Unterschied von 5.52 am 16-09-1996\n",
    "Prozentualer Unterschied von 6.4 am 17-09-1996\n",
    "Prozentualer Unterschied von 7.39 am 02-10-1996\n",
    "Prozentualer Unterschied von 5.1 am 15-10-1996\n",
    "Prozentualer Unterschied von 8.91 am 17-10-1996\n",
    "Prozentualer Unterschied von 6.67 am 23-12-1996\n",
    "Prozentualer Unterschied von -7.57 am 31-12-1996\n",
    "Prozentualer Unterschied von -16.57 am 06-01-1997\n",
    "Prozentualer Unterschied von -6.15 am 05-02-1997\n",
    "Prozentualer Unterschied von 8.2 am 07-02-1997\n",
    "Prozentualer Unterschied von 7.52 am 19-02-1997\n",
    "Prozentualer Unterschied von 9.38 am 21-03-1997\n",
    "Prozentualer Unterschied von -5.71 am 24-03-1997\n",
    "Prozentualer Unterschied von 6.87 am 27-03-1997\n",
    "Prozentualer Unterschied von 6.43 am 31-03-1997\n",
    "Prozentualer Unterschied von -5.37 am 01-04-1997\n",
    "Prozentualer Unterschied von -5.56 am 30-04-1997\n",
    "Prozentualer Unterschied von -5.51 am 01-07-1997\n",
    "Prozentualer Unterschied von 6.19 am 07-07-1997\n",
    "Prozentualer Unterschied von -6.79 am 10-07-1997\n",
    "Prozentualer Unterschied von 14.02 am 14-07-1997\n",
    "Prozentualer Unterschied von 7.51 am 17-07-1997\n",
    "Prozentualer Unterschied von 5.15 am 18-07-1997\n",
    "Prozentualer Unterschied von -6.76 am 22-07-1997\n",
    "Prozentualer Unterschied von 8.87 am 04-08-1997\n",
    "Prozentualer Unterschied von 26.65 am 06-08-1997\n",
    "Prozentualer Unterschied von 13.86 am 07-08-1997\n",
    "Prozentualer Unterschied von -5.39 am 11-08-1997\n",
    "Prozentualer Unterschied von -8.55 am 12-08-1997\n",
    "Prozentualer Unterschied von -7.53 am 13-08-1997\n",
    "Prozentualer Unterschied von 6.18 am 14-08-1997\n",
    "Prozentualer Unterschied von 5.17 am 11-09-1997\n",
    "Prozentualer Unterschied von 5.81 am 13-10-1997\n",
    "Prozentualer Unterschied von -6.21 am 21-10-1997\n",
    "Prozentualer Unterschied von -5.57 am 23-10-1997\n",
    "Prozentualer Unterschied von -7.59 am 27-10-1997\n",
    "Prozentualer Unterschied von 15.23 am 29-10-1997\n",
    "Prozentualer Unterschied von -7.46 am 30-10-1997\n",
    "Prozentualer Unterschied von 11.26 am 10-11-1997\n",
    "Prozentualer Unterschied von -9.52 am 11-11-1997\n",
    "Prozentualer Unterschied von -5.7 am 24-11-1997\n",
    "Prozentualer Unterschied von -7.55 am 03-12-1997\n",
    "Prozentualer Unterschied von -5.41 am 23-12-1997\n",
    "Prozentualer Unterschied von 21.1 am 05-01-1998\n",
    "Prozentualer Unterschied von 18.04 am 07-01-1998\n",
    "Prozentualer Unterschied von -7.31 am 08-01-1998\n",
    "Prozentualer Unterschied von 6.81 am 13-01-1998\n",
    "Prozentualer Unterschied von 6.71 am 14-01-1998\n",
    "Prozentualer Unterschied von 6.71 am 19-02-1998\n",
    "Prozentualer Unterschied von 5.9 am 24-02-1998\n",
    "Prozentualer Unterschied von -7.16 am 03-03-1998\n",
    "Prozentualer Unterschied von 9.24 am 11-03-1998\n",
    "Prozentualer Unterschied von 7.59 am 16-04-1998\n",
    "Prozentualer Unterschied von 5.2 am 21-04-1998\n",
    "Prozentualer Unterschied von 5.0 am 04-05-1998\n",
    "Prozentualer Unterschied von -8.46 am 27-05-1998\n",
    "Prozentualer Unterschied von 7.11 am 09-07-1998\n",
    "Prozentualer Unterschied von 6.26 am 14-07-1998\n",
    "Prozentualer Unterschied von 12.43 am 16-07-1998\n",
    "Prozentualer Unterschied von 6.11 am 30-07-1998\n",
    "Prozentualer Unterschied von -6.48 am 03-08-1998\n",
    "Prozentualer Unterschied von 6.06 am 07-08-1998\n",
    "Prozentualer Unterschied von 5.3 am 12-08-1998\n",
    "Prozentualer Unterschied von -5.75 am 20-08-1998\n",
    "Prozentualer Unterschied von 8.59 am 24-08-1998\n",
    "Prozentualer Unterschied von -5.9 am 26-08-1998\n",
    "Prozentualer Unterschied von -5.41 am 28-08-1998\n",
    "Prozentualer Unterschied von -6.4 am 31-08-1998\n",
    "Prozentualer Unterschied von -9.71 am 01-09-1998\n",
    "Prozentualer Unterschied von 13.15 am 02-09-1998\n",
    "Prozentualer Unterschied von 7.04 am 08-09-1998\n",
    "Prozentualer Unterschied von 6.21 am 11-09-1998\n",
    "Prozentualer Unterschied von 5.1 am 16-09-1998\n",
    "Prozentualer Unterschied von -6.63 am 17-09-1998\n",
    "Prozentualer Unterschied von -5.16 am 01-10-1998\n",
    "Prozentualer Unterschied von 18.11 am 12-10-1998\n",
    "Prozentualer Unterschied von -8.81 am 15-10-1998\n",
    "Prozentualer Unterschied von 5.37 am 27-10-1998\n",
    "Prozentualer Unterschied von -7.24 am 28-10-1998\n",
    "Prozentualer Unterschied von -7.34 am 12-11-1998\n",
    "Prozentualer Unterschied von 5.47 am 13-11-1998\n",
    "Prozentualer Unterschied von -7.41 am 01-12-1998\n",
    "Prozentualer Unterschied von 6.64 am 02-12-1998\n",
    "Prozentualer Unterschied von 6.41 am 03-12-1998\n",
    "Prozentualer Unterschied von -5.51 am 04-12-1998\n",
    "Prozentualer Unterschied von 5.99 am 21-12-1998\n",
    "Prozentualer Unterschied von 6.19 am 23-12-1998\n",
    "Prozentualer Unterschied von 5.45 am 29-12-1998\n",
    "Prozentualer Unterschied von 5.22 am 06-01-1999\n",
    "Prozentualer Unterschied von 10.21 am 08-01-1999\n",
    "Prozentualer Unterschied von -7.42 am 13-01-1999\n",
    "Prozentualer Unterschied von 6.12 am 14-01-1999\n",
    "Prozentualer Unterschied von -8.1 am 15-01-1999\n",
    "Prozentualer Unterschied von -6.8 am 22-01-1999\n",
    "Prozentualer Unterschied von 5.08 am 11-02-1999\n",
    "Prozentualer Unterschied von -5.67 am 11-03-1999\n",
    "Prozentualer Unterschied von 5.07 am 16-03-1999\n",
    "Prozentualer Unterschied von -5.39 am 22-03-1999\n",
    "Prozentualer Unterschied von -5.08 am 20-04-1999\n",
    "Prozentualer Unterschied von 8.97 am 26-04-1999\n",
    "Prozentualer Unterschied von 8.86 am 27-04-1999\n",
    "Prozentualer Unterschied von -5.36 am 21-05-1999\n",
    "Prozentualer Unterschied von 5.34 am 03-06-1999\n",
    "Prozentualer Unterschied von 6.95 am 30-06-1999\n",
    "Prozentualer Unterschied von 7.92 am 08-07-1999\n",
    "Prozentualer Unterschied von 6.6 am 09-07-1999\n",
    "Prozentualer Unterschied von 5.47 am 12-08-1999\n",
    "Prozentualer Unterschied von 7.04 am 01-09-1999\n",
    "Prozentualer Unterschied von 6.38 am 03-09-1999\n",
    "Prozentualer Unterschied von 5.56 am 15-09-1999\n",
    "Prozentualer Unterschied von -10.9 am 24-09-1999\n",
    "Prozentualer Unterschied von -7.34 am 28-09-1999\n",
    "Prozentualer Unterschied von 5.21 am 05-10-1999\n",
    "Prozentualer Unterschied von 5.71 am 06-10-1999\n",
    "Prozentualer Unterschied von 6.29 am 22-10-1999\n",
    "Prozentualer Unterschied von 7.55 am 09-11-1999\n",
    "Prozentualer Unterschied von -6.49 am 10-11-1999\n",
    "Prozentualer Unterschied von 8.79 am 03-12-1999\n",
    "Prozentualer Unterschied von -5.12 am 10-12-1999\n",
    "Prozentualer Unterschied von -5.21 am 15-12-1999\n",
    "Prozentualer Unterschied von 5.09 am 16-12-1999\n",
    "Prozentualer Unterschied von -5.03 am 28-12-1999\n",
    "Prozentualer Unterschied von 5.55 am 30-12-1999\n",
    "Prozentualer Unterschied von -9.07 am 07-01-2000\n",
    "Prozentualer Unterschied von 5.7 am 10-01-2000\n",
    "Prozentualer Unterschied von -5.94 am 11-01-2000\n",
    "Prozentualer Unterschied von 5.84 am 14-01-2000\n",
    "Prozentualer Unterschied von 9.35 am 20-01-2000\n",
    "Prozentualer Unterschied von -5.09 am 24-01-2000\n",
    "Prozentualer Unterschied von -6.64 am 31-01-2000\n",
    "Prozentualer Unterschied von 5.56 am 08-02-2000\n",
    "Prozentualer Unterschied von 5.43 am 15-02-2000\n",
    "Prozentualer Unterschied von 7.12 am 02-03-2000\n",
    "Prozentualer Unterschied von 8.34 am 22-03-2000\n",
    "Prozentualer Unterschied von 6.94 am 23-03-2000\n",
    "Prozentualer Unterschied von 6.33 am 03-04-2000\n",
    "Prozentualer Unterschied von -6.22 am 11-04-2000\n",
    "Prozentualer Unterschied von -6.3 am 13-04-2000\n",
    "Prozentualer Unterschied von 12.79 am 18-04-2000\n",
    "Prozentualer Unterschied von -7.02 am 24-04-2000\n",
    "Prozentualer Unterschied von 6.2 am 25-04-2000\n",
    "Prozentualer Unterschied von -7.45 am 27-04-2000\n",
    "Prozentualer Unterschied von 8.48 am 28-04-2000\n",
    "Prozentualer Unterschied von -5.67 am 10-05-2000\n",
    "Prozentualer Unterschied von -5.54 am 22-05-2000\n",
    "Prozentualer Unterschied von -5.9 am 01-06-2000\n",
    "Prozentualer Unterschied von 14.68 am 02-06-2000\n",
    "Prozentualer Unterschied von -5.38 am 13-06-2000\n",
    "Prozentualer Unterschied von 8.76 am 20-06-2000\n",
    "Prozentualer Unterschied von 10.4 am 22-06-2000\n",
    "Prozentualer Unterschied von 5.37 am 11-07-2000\n",
    "Prozentualer Unterschied von -5.66 am 19-07-2000\n",
    "Prozentualer Unterschied von -5.98 am 31-07-2000\n",
    "Prozentualer Unterschied von -7.02 am 03-08-2000\n",
    "Prozentualer Unterschied von 8.57 am 04-08-2000\n",
    "Prozentualer Unterschied von 6.2 am 18-08-2000\n",
    "Prozentualer Unterschied von 6.22 am 24-08-2000\n",
    "Prozentualer Unterschied von 8.14 am 19-09-2000\n",
    "Prozentualer Unterschied von -14.0 am 22-09-2000\n",
    "Prozentualer Unterschied von -42.84 am 29-09-2000\n",
    "Prozentualer Unterschied von -5.32 am 02-10-2000\n",
    "Prozentualer Unterschied von -6.56 am 03-10-2000\n",
    "Prozentualer Unterschied von -10.28 am 04-10-2000\n",
    "Prozentualer Unterschied von 5.03 am 05-10-2000\n",
    "Prozentualer Unterschied von -6.94 am 11-10-2000\n",
    "Prozentualer Unterschied von 10.19 am 16-10-2000\n",
    "Prozentualer Unterschied von -10.37 am 18-10-2000\n",
    "Prozentualer Unterschied von 6.31 am 23-10-2000\n",
    "Prozentualer Unterschied von -7.86 am 25-10-2000\n",
    "Prozentualer Unterschied von 8.68 am 02-11-2000\n",
    "Prozentualer Unterschied von 8.88 am 03-11-2000\n",
    "Prozentualer Unterschied von -7.02 am 09-11-2000\n",
    "Prozentualer Unterschied von 6.33 am 14-11-2000\n",
    "Prozentualer Unterschied von 5.39 am 27-11-2000\n",
    "Prozentualer Unterschied von -5.98 am 28-11-2000\n",
    "Prozentualer Unterschied von -7.77 am 30-11-2000\n",
    "Prozentualer Unterschied von -13.65 am 06-12-2000\n",
    "Prozentualer Unterschied von 5.31 am 26-12-2000\n",
    "Prozentualer Unterschied von 25.11 am 04-01-2001\n",
    "Prozentualer Unterschied von -6.63 am 05-01-2001\n",
    "Prozentualer Unterschied von 10.0 am 12-01-2001\n",
    "Prozentualer Unterschied von 9.12 am 19-01-2001\n",
    "Prozentualer Unterschied von 6.8 am 24-01-2001\n",
    "Prozentualer Unterschied von -5.17 am 26-01-2001\n",
    "Prozentualer Unterschied von 10.22 am 30-01-2001\n",
    "Prozentualer Unterschied von -7.01 am 12-02-2001\n",
    "Prozentualer Unterschied von -8.06 am 01-03-2001\n",
    "Prozentualer Unterschied von 5.8 am 05-03-2001\n",
    "Prozentualer Unterschied von 6.94 am 06-03-2001\n",
    "Prozentualer Unterschied von 12.84 am 15-03-2001\n",
    "Prozentualer Unterschied von -8.98 am 16-03-2001\n",
    "Prozentualer Unterschied von 8.28 am 23-03-2001\n",
    "Prozentualer Unterschied von -5.14 am 27-03-2001\n",
    "Prozentualer Unterschied von -7.49 am 04-04-2001\n",
    "Prozentualer Unterschied von 9.95 am 11-04-2001\n",
    "Prozentualer Unterschied von -6.79 am 12-04-2001\n",
    "Prozentualer Unterschied von 18.45 am 19-04-2001\n",
    "Prozentualer Unterschied von 5.95 am 30-04-2001\n",
    "Prozentualer Unterschied von -6.66 am 04-05-2001\n",
    "Prozentualer Unterschied von 5.69 am 07-05-2001\n",
    "Prozentualer Unterschied von -6.99 am 30-05-2001\n",
    "Prozentualer Unterschied von -6.08 am 12-06-2001\n",
    "Prozentualer Unterschied von 8.35 am 13-06-2001\n",
    "Prozentualer Unterschied von -6.44 am 14-06-2001\n",
    "Prozentualer Unterschied von 7.75 am 21-06-2001\n",
    "Prozentualer Unterschied von -8.37 am 11-07-2001\n",
    "Prozentualer Unterschied von 10.79 am 12-07-2001\n",
    "Prozentualer Unterschied von -9.17 am 18-07-2001\n",
    "Prozentualer Unterschied von -7.21 am 20-07-2001\n",
    "Prozentualer Unterschied von -5.88 am 17-09-2001\n",
    "Prozentualer Unterschied von 5.63 am 18-09-2001\n",
    "Prozentualer Unterschied von -9.15 am 21-09-2001\n",
    "Prozentualer Unterschied von 8.85 am 24-09-2001\n",
    "Prozentualer Unterschied von 5.09 am 11-10-2001\n",
    "Prozentualer Unterschied von -5.73 am 18-10-2001\n",
    "Prozentualer Unterschied von -5.54 am 24-10-2001\n",
    "Prozentualer Unterschied von -6.41 am 30-10-2001\n",
    "Prozentualer Unterschied von -5.25 am 09-11-2001\n",
    "Prozentualer Unterschied von 6.32 am 27-11-2001\n",
    "Prozentualer Unterschied von 6.22 am 05-12-2001\n",
    "Prozentualer Unterschied von 5.01 am 06-12-2001\n",
    "Prozentualer Unterschied von -6.93 am 10-01-2002\n",
    "Prozentualer Unterschied von 5.09 am 24-01-2002\n",
    "Prozentualer Unterschied von -5.5 am 22-02-2002\n",
    "Prozentualer Unterschied von 5.49 am 25-02-2002\n",
    "Prozentualer Unterschied von -7.48 am 28-02-2002\n",
    "Prozentualer Unterschied von 6.06 am 04-03-2002\n",
    "Prozentualer Unterschied von 5.41 am 05-04-2002\n",
    "Prozentualer Unterschied von -5.88 am 22-05-2002\n",
    "Prozentualer Unterschied von -5.2 am 28-05-2002\n",
    "Prozentualer Unterschied von -5.23 am 07-06-2002\n",
    "Prozentualer Unterschied von -5.68 am 12-06-2002\n",
    "Prozentualer Unterschied von 5.2 am 17-06-2002\n",
    "Prozentualer Unterschied von -14.94 am 19-06-2002\n",
    "Prozentualer Unterschied von 5.35 am 05-07-2002\n",
    "Prozentualer Unterschied von 7.47 am 12-07-2002\n",
    "Prozentualer Unterschied von -6.04 am 15-07-2002\n",
    "Prozentualer Unterschied von -11.13 am 17-07-2002\n",
    "Prozentualer Unterschied von -5.16 am 19-07-2002\n",
    "Prozentualer Unterschied von 6.19 am 07-08-2002\n",
    "Prozentualer Unterschied von -5.79 am 28-08-2002\n",
    "Prozentualer Unterschied von 5.85 am 28-10-2002\n",
    "Prozentualer Unterschied von -5.49 am 08-11-2002\n",
    "Prozentualer Unterschied von -5.27 am 31-01-2003\n",
    "Prozentualer Unterschied von 9.14 am 06-05-2003\n",
    "Prozentualer Unterschied von 7.51 am 07-05-2003\n",
    "Prozentualer Unterschied von 5.34 am 28-07-2003\n",
    "Prozentualer Unterschied von -6.04 am 06-08-2003\n",
    "Prozentualer Unterschied von 5.86 am 29-09-2003\n",
    "Prozentualer Unterschied von 5.44 am 08-10-2003\n",
    "Prozentualer Unterschied von -5.03 am 17-11-2003\n",
    "Prozentualer Unterschied von 5.28 am 12-12-2003\n",
    "Prozentualer Unterschied von -6.05 am 16-12-2003\n",
    "Prozentualer Unterschied von 6.24 am 13-01-2004\n",
    "Prozentualer Unterschied von -6.11 am 15-01-2004\n",
    "Prozentualer Unterschied von 6.69 am 08-03-2004\n",
    "Prozentualer Unterschied von 7.78 am 15-04-2004\n",
    "Prozentualer Unterschied von 6.2 am 17-06-2004\n",
    "Prozentualer Unterschied von -6.17 am 29-06-2004\n",
    "Prozentualer Unterschied von -5.05 am 02-07-2004\n",
    "Prozentualer Unterschied von 13.17 am 15-07-2004\n",
    "Prozentualer Unterschied von 11.11 am 14-10-2004\n",
    "Prozentualer Unterschied von 7.61 am 19-10-2004\n",
    "Prozentualer Unterschied von 11.37 am 22-11-2004\n",
    "Prozentualer Unterschied von 5.93 am 26-11-2004\n",
    "Prozentualer Unterschied von 5.51 am 29-11-2004\n",
    "Prozentualer Unterschied von 7.43 am 10-01-2005\n",
    "Prozentualer Unterschied von 12.62 am 13-01-2005\n",
    "Prozentualer Unterschied von -5.39 am 09-03-2005\n",
    "Prozentualer Unterschied von -9.64 am 14-04-2005\n",
    "Prozentualer Unterschied von -5.64 am 15-04-2005\n",
    "Prozentualer Unterschied von -5.76 am 27-06-2005\n",
    "Prozentualer Unterschied von 6.53 am 14-07-2005\n",
    "Prozentualer Unterschied von 6.95 am 15-08-2005\n",
    "Prozentualer Unterschied von 5.03 am 07-09-2005\n",
    "Prozentualer Unterschied von -5.04 am 12-10-2005\n",
    "Prozentualer Unterschied von 9.28 am 14-10-2005\n",
    "Prozentualer Unterschied von 9.95 am 11-01-2006\n",
    "Prozentualer Unterschied von 6.08 am 31-01-2006\n",
    "Prozentualer Unterschied von -5.21 am 07-02-2006\n",
    "Prozentualer Unterschied von -5.67 am 10-02-2006\n",
    "Prozentualer Unterschied von -5.23 am 21-03-2006\n",
    "Prozentualer Unterschied von 6.24 am 30-03-2006\n",
    "Prozentualer Unterschied von 5.55 am 06-04-2006\n",
    "Prozentualer Unterschied von 5.25 am 02-06-2006\n",
    "Prozentualer Unterschied von -5.69 am 13-07-2006\n",
    "Prozentualer Unterschied von 15.11 am 20-07-2006\n",
    "Prozentualer Unterschied von 6.03 am 19-10-2006\n",
    "Prozentualer Unterschied von 9.6 am 10-01-2007\n",
    "Prozentualer Unterschied von -5.6 am 18-01-2007\n",
    "Prozentualer Unterschied von 5.61 am 22-02-2007\n",
    "Prozentualer Unterschied von 7.8 am 26-04-2007\n",
    "Prozentualer Unterschied von 5.05 am 31-05-2007\n",
    "Prozentualer Unterschied von -5.28 am 12-06-2007\n",
    "Prozentualer Unterschied von 5.57 am 05-07-2007\n",
    "Prozentualer Unterschied von 6.23 am 26-07-2007\n",
    "Prozentualer Unterschied von -6.53 am 01-08-2007\n",
    "Prozentualer Unterschied von -6.09 am 10-08-2007\n",
    "Prozentualer Unterschied von 7.37 am 22-08-2007\n",
    "Prozentualer Unterschied von 5.14 am 31-08-2007\n",
    "Prozentualer Unterschied von -6.49 am 06-09-2007\n",
    "Prozentualer Unterschied von 5.2 am 26-09-2007\n",
    "Prozentualer Unterschied von 10.69 am 23-10-2007\n",
    "Prozentualer Unterschied von -8.31 am 09-11-2007\n",
    "Prozentualer Unterschied von 10.14 am 14-11-2007\n",
    "Prozentualer Unterschied von -6.08 am 15-11-2007\n",
    "Prozentualer Unterschied von -5.33 am 07-01-2008\n",
    "Prozentualer Unterschied von -7.03 am 16-01-2008\n",
    "Prozentualer Unterschied von -8.44 am 22-01-2008\n",
    "Prozentualer Unterschied von -8.02 am 23-01-2008\n",
    "Prozentualer Unterschied von -7.79 am 28-01-2008\n",
    "Prozentualer Unterschied von 5.25 am 01-02-2008\n",
    "Prozentualer Unterschied von -8.3 am 07-02-2008\n",
    "Prozentualer Unterschied von 7.59 am 28-02-2008\n",
    "Prozentualer Unterschied von -5.64 am 17-03-2008\n",
    "Prozentualer Unterschied von 5.41 am 18-03-2008\n",
    "Prozentualer Unterschied von -5.43 am 13-06-2008\n",
    "Prozentualer Unterschied von 6.68 am 02-07-2008\n",
    "Prozentualer Unterschied von -10.72 am 22-07-2008\n",
    "Prozentualer Unterschied von 10.73 am 23-07-2008\n",
    "Prozentualer Unterschied von -5.88 am 15-09-2008\n",
    "Prozentualer Unterschied von -5.75 am 16-09-2008\n",
    "Prozentualer Unterschied von -5.72 am 18-09-2008\n",
    "Prozentualer Unterschied von 9.21 am 19-09-2008\n",
    "Prozentualer Unterschied von -5.78 am 23-09-2008\n",
    "Prozentualer Unterschied von -9.51 am 30-09-2008\n",
    "Prozentualer Unterschied von -11.58 am 06-10-2008\n",
    "Prozentualer Unterschied von 9.26 am 07-10-2008\n",
    "Prozentualer Unterschied von -14.5 am 08-10-2008\n",
    "Prozentualer Unterschied von 8.66 am 09-10-2008\n",
    "Prozentualer Unterschied von -8.19 am 10-10-2008\n",
    "Prozentualer Unterschied von 22.0 am 13-10-2008\n",
    "Prozentualer Unterschied von 11.2 am 14-10-2008\n",
    "Prozentualer Unterschied von -10.68 am 15-10-2008\n",
    "Prozentualer Unterschied von -6.4 am 24-10-2008\n",
    "Prozentualer Unterschied von 5.25 am 27-10-2008\n",
    "Prozentualer Unterschied von 5.69 am 29-10-2008\n",
    "Prozentualer Unterschied von 7.31 am 30-10-2008\n",
    "Prozentualer Unterschied von -7.22 am 06-11-2008\n",
    "Prozentualer Unterschied von -5.35 am 11-11-2008\n",
    "Prozentualer Unterschied von -5.63 am 17-11-2008\n",
    "Prozentualer Unterschied von 11.06 am 25-11-2008\n",
    "Prozentualer Unterschied von 5.32 am 28-11-2008\n",
    "Prozentualer Unterschied von 5.63 am 04-12-2008\n",
    "Prozentualer Unterschied von 7.67 am 08-12-2008\n",
    "Prozentualer Unterschied von 8.49 am 05-01-2009\n",
    "Prozentualer Unterschied von -6.57 am 15-01-2009\n",
    "Prozentualer Unterschied von 10.9 am 22-01-2009\n",
    "Prozentualer Unterschied von 5.82 am 11-03-2009\n",
    "Prozentualer Unterschied von 5.81 am 02-04-2009\n",
    "Prozentualer Unterschied von 5.63 am 27-05-2009\n",
    "Prozentualer Unterschied von 6.79 am 20-10-2009\n",
    "Prozentualer Unterschied von 6.21 am 24-05-2010\n",
    "Prozentualer Unterschied von 9.14 am 21-07-2010\n",
    "Prozentualer Unterschied von 5.71 am 19-01-2011\n",
    "Prozentualer Unterschied von 6.9 am 25-01-2012\n",
    "Prozentualer Unterschied von -5.1 am 17-04-2012\n",
    "Prozentualer Unterschied von 6.01 am 18-04-2012\n",
    "Prozentualer Unterschied von 9.43 am 25-04-2012\n",
    "Prozentualer Unterschied von 6.56 am 22-05-2012\n",
    "Prozentualer Unterschied von -5.42 am 25-07-2012\n",
    "Prozentualer Unterschied von 5.77 am 20-11-2012\n",
    "Prozentualer Unterschied von -7.03 am 06-12-2012\n",
    "Prozentualer Unterschied von -5.13 am 10-12-2012\n",
    "Prozentualer Unterschied von 8.48 am 02-01-2013\n",
    "Prozentualer Unterschied von -9.59 am 24-01-2013\n",
    "Prozentualer Unterschied von 5.72 am 14-08-2013\n",
    "Prozentualer Unterschied von -7.74 am 11-09-2013\n",
    "Prozentualer Unterschied von -7.51 am 28-01-2014\n",
    "Prozentualer Unterschied von 7.4 am 24-04-2014\n",
    "Prozentualer Unterschied von -8.17 am 22-07-2015\n",
    "Prozentualer Unterschied von -14.09 am 24-08-2015\n",
    "Prozentualer Unterschied von 17.12 am 25-08-2015\n",
    "Prozentualer Unterschied von -7.61 am 27-04-2016\n",
    "Prozentualer Unterschied von 7.69 am 27-07-2016\n",
    "Prozentualer Unterschied von -6.09 am 12-06-2017\n",
    "Prozentualer Unterschied von 6.83 am 02-08-2017\n",
    "Prozentualer Unterschied von 5.33 am 07-02-2018\n",
    "Prozentualer Unterschied von 5.3 am 02-05-2018\n",
    "Prozentualer Unterschied von -6.12 am 20-11-2018\n",
    "Prozentualer Unterschied von -5.08 am 06-12-2018\n",
    "Prozentualer Unterschied von -5.55 am 24-12-2018\n",
    "Prozentualer Unterschied von 5.08 am 27-12-2018\n",
    "Prozentualer Unterschied von -7.04 am 03-01-2019\n",
    "Prozentualer Unterschied von 5.04 am 05-06-2019\n",
    "Prozentualer Unterschied von -5.18 am 03-02-2020\n",
    "Prozentualer Unterschied von -6.7 am 24-02-2020\n",
    "Prozentualer Unterschied von -8.48 am 28-02-2020\n",
    "Prozentualer Unterschied von 9.73 am 02-03-2020\n",
    "Prozentualer Unterschied von 7.58 am 03-03-2020\n",
    "Prozentualer Unterschied von -6.47 am 09-03-2020\n",
    "Prozentualer Unterschied von 5.08 am 10-03-2020\n",
    "Prozentualer Unterschied von -7.73 am 12-03-2020\n",
    "Prozentualer Unterschied von -8.66 am 16-03-2020\n",
    "Prozentualer Unterschied von -7.73 am 23-03-2020\n",
    "Prozentualer Unterschied von 6.09 am 25-03-2020\n",
    "Prozentualer Unterschied von 7.93 am 07-04-2020\n",
    "Prozentualer Unterschied von 5.46 am 16-06-2020\n",
    "Prozentualer Unterschied von -6.2 am 24-07-2020\n",
    "Prozentualer Unterschied von 9.23 am 31-07-2020\n",
    "Prozentualer Unterschied von 5.17 am 03-08-2020\n",
    "Prozentualer Unterschied von 7.91 am 24-08-2020\n",
    "Prozentualer Unterschied von -7.76 am 03-09-2020\n",
    "Prozentualer Unterschied von -5.39 am 04-09-2020\n",
    "Prozentualer Unterschied von -5.1 am 08-09-2020\n",
    "Prozentualer Unterschied von -5.31 am 21-09-2020\n",
    "Prozentualer Unterschied von 7.79 am 22-09-2020\n",
    "Prozentualer Unterschied von -5.78 am 24-09-2020\n",
    "Prozentualer Unterschied von 6.07 am 28-09-2020\n",
    "Prozentualer Unterschied von 5.27 am 22-12-2020\n",
    "Prozentualer Unterschied von -5.22 am 02-12-2021\n",
    "Prozentualer Unterschied von -5.22 am 17-12-2021\n",
    "Prozentualer Unterschied von -7.83 am 24-02-2022\n",
    "Prozentualer Unterschied von 7.38 am 25-02-2022\n",
    "Prozentualer Unterschied von -6.99 am 12-05-2022\n",
    "Prozentualer Unterschied von 5.82 am 27-05-2022\n",
    "Prozentualer Unterschied von -5.28 am 13-06-2022\n",
    "\n",
    "Entwicklung von 1995 bis 2022\n",
    "\n",
    "Werte für das Jahr: 1995\n",
    "Tage mit Anstieg: 137\n",
    "Durchschnittlicher Anstieg pro Tag: 1.73\n",
    "Tage mit Abfall: 115\n",
    "Durchschnittlicher Abfall pro Tag: 2.17\n",
    "\n",
    "Werte für das Jahr: 1996\n",
    "Tage mit Anstieg: 118\n",
    "Durchschnittlicher Anstieg pro Tag: 2.48\n",
    "Tage mit Abfall: 136\n",
    "Durchschnittlicher Abfall pro Tag: 2.35\n",
    "\n",
    "Werte für das Jahr: 1997\n",
    "Tage mit Anstieg: 123\n",
    "Durchschnittlicher Anstieg pro Tag: 2.64\n",
    "Tage mit Abfall: 130\n",
    "Durchschnittlicher Abfall pro Tag: 2.72\n",
    "\n",
    "Werte für das Jahr: 1998\n",
    "Tage mit Anstieg: 131\n",
    "Durchschnittlicher Anstieg pro Tag: 3.41\n",
    "Tage mit Abfall: 121\n",
    "Durchschnittlicher Abfall pro Tag: 2.58\n",
    "\n",
    "Werte für das Jahr: 1999\n",
    "Tage mit Anstieg: 142\n",
    "Durchschnittlicher Anstieg pro Tag: 2.88\n",
    "Tage mit Abfall: 110\n",
    "Durchschnittlicher Abfall pro Tag: 2.74\n",
    "\n",
    "Werte für das Jahr: 2000\n",
    "Tage mit Anstieg: 112\n",
    "Durchschnittlicher Anstieg pro Tag: 3.5\n",
    "Tage mit Abfall: 140\n",
    "Durchschnittlicher Abfall pro Tag: 3.42\n",
    "\n",
    "Werte für das Jahr: 2001\n",
    "Tage mit Anstieg: 127\n",
    "Durchschnittlicher Anstieg pro Tag: 3.32\n",
    "Tage mit Abfall: 121\n",
    "Durchschnittlicher Abfall pro Tag: 2.95\n",
    "\n",
    "Werte für das Jahr: 2002\n",
    "Tage mit Anstieg: 120\n",
    "Durchschnittlicher Anstieg pro Tag: 2.19\n",
    "Tage mit Abfall: 132\n",
    "Durchschnittlicher Abfall pro Tag: 2.27\n",
    "\n",
    "Werte für das Jahr: 2003\n",
    "Tage mit Anstieg: 132\n",
    "Durchschnittlicher Anstieg pro Tag: 1.91\n",
    "Tage mit Abfall: 120\n",
    "Durchschnittlicher Abfall pro Tag: 1.7\n",
    "\n",
    "Werte für das Jahr: 2004\n",
    "Tage mit Anstieg: 147\n",
    "Durchschnittlicher Anstieg pro Tag: 1.96\n",
    "Tage mit Abfall: 105\n",
    "Durchschnittlicher Abfall pro Tag: 1.6\n",
    "\n",
    "Werte für das Jahr: 2005\n",
    "Tage mit Anstieg: 151\n",
    "Durchschnittlicher Anstieg pro Tag: 1.77\n",
    "Tage mit Abfall: 101\n",
    "Durchschnittlicher Abfall pro Tag: 1.8\n",
    "\n",
    "Werte für das Jahr: 2006\n",
    "Tage mit Anstieg: 123\n",
    "Durchschnittlicher Anstieg pro Tag: 1.92\n",
    "Tage mit Abfall: 128\n",
    "Durchschnittlicher Abfall pro Tag: 1.65\n",
    "\n",
    "Werte für das Jahr: 2007\n",
    "Tage mit Anstieg: 155\n",
    "Durchschnittlicher Anstieg pro Tag: 1.79\n",
    "Tage mit Abfall: 96\n",
    "Durchschnittlicher Abfall pro Tag: 1.9\n",
    "\n",
    "Werte für das Jahr: 2008\n",
    "Tage mit Anstieg: 122\n",
    "Durchschnittlicher Anstieg pro Tag: 2.72\n",
    "Tage mit Abfall: 131\n",
    "Durchschnittlicher Abfall pro Tag: 3.02\n",
    "\n",
    "Werte für das Jahr: 2009\n",
    "Tage mit Anstieg: 147\n",
    "Durchschnittlicher Anstieg pro Tag: 1.79\n",
    "Tage mit Abfall: 105\n",
    "Durchschnittlicher Abfall pro Tag: 1.58\n",
    "\n",
    "Werte für das Jahr: 2010\n",
    "Tage mit Anstieg: 143\n",
    "Durchschnittlicher Anstieg pro Tag: 1.33\n",
    "Tage mit Abfall: 109\n",
    "Durchschnittlicher Abfall pro Tag: 1.33\n",
    "\n",
    "Werte für das Jahr: 2011\n",
    "Tage mit Anstieg: 137\n",
    "Durchschnittlicher Anstieg pro Tag: 1.33\n",
    "Tage mit Abfall: 115\n",
    "Durchschnittlicher Abfall pro Tag: 1.36\n",
    "\n",
    "Werte für das Jahr: 2012\n",
    "Tage mit Anstieg: 131\n",
    "Durchschnittlicher Anstieg pro Tag: 1.58\n",
    "Tage mit Abfall: 119\n",
    "Durchschnittlicher Abfall pro Tag: 1.49\n",
    "\n",
    "Werte für das Jahr: 2013\n",
    "Tage mit Anstieg: 132\n",
    "Durchschnittlicher Anstieg pro Tag: 1.36\n",
    "Tage mit Abfall: 120\n",
    "Durchschnittlicher Abfall pro Tag: 1.39\n",
    "\n",
    "Werte für das Jahr: 2014\n",
    "Tage mit Anstieg: 136\n",
    "Durchschnittlicher Anstieg pro Tag: 1.13\n",
    "Tage mit Abfall: 116\n",
    "Durchschnittlicher Abfall pro Tag: 0.99\n",
    "\n",
    "Werte für das Jahr: 2015\n",
    "Tage mit Anstieg: 121\n",
    "Durchschnittlicher Anstieg pro Tag: 1.43\n",
    "Tage mit Abfall: 131\n",
    "Durchschnittlicher Abfall pro Tag: 1.32\n",
    "\n",
    "Werte für das Jahr: 2016\n",
    "Tage mit Anstieg: 141\n",
    "Durchschnittlicher Anstieg pro Tag: 1.0\n",
    "Tage mit Abfall: 111\n",
    "Durchschnittlicher Abfall pro Tag: 1.17\n",
    "\n",
    "Werte für das Jahr: 2017\n",
    "Tage mit Anstieg: 145\n",
    "Durchschnittlicher Anstieg pro Tag: 0.82\n",
    "Tage mit Abfall: 106\n",
    "Durchschnittlicher Abfall pro Tag: 0.74\n",
    "\n",
    "Werte für das Jahr: 2018\n",
    "Tage mit Anstieg: 138\n",
    "Durchschnittlicher Anstieg pro Tag: 1.21\n",
    "Tage mit Abfall: 113\n",
    "Durchschnittlicher Abfall pro Tag: 1.51\n",
    "\n",
    "Werte für das Jahr: 2019\n",
    "Tage mit Anstieg: 147\n",
    "Durchschnittlicher Anstieg pro Tag: 1.14\n",
    "Tage mit Abfall: 105\n",
    "Durchschnittlicher Abfall pro Tag: 1.0\n",
    "\n",
    "Werte für das Jahr: 2020\n",
    "Tage mit Anstieg: 149\n",
    "Durchschnittlicher Anstieg pro Tag: 2.06\n",
    "Tage mit Abfall: 104\n",
    "Durchschnittlicher Abfall pro Tag: 2.26\n",
    "\n",
    "Werte für das Jahr: 2021\n",
    "Tage mit Anstieg: 133\n",
    "Durchschnittlicher Anstieg pro Tag: 1.24\n",
    "Tage mit Abfall: 119\n",
    "Durchschnittlicher Abfall pro Tag: 1.12\n",
    "\n",
    "Werte für das Jahr: 2022\n",
    "Tage mit Anstieg: 63\n",
    "Durchschnittlicher Anstieg pro Tag: 1.68\n",
    "Tage mit Abfall: 66\n",
    "Durchschnittlicher Abfall pro Tag: 1.86\n",
    "#Charts of Amazon\n",
    "\n",
    "amazon_waggle_list = get_daily_diff_list(amazon_open)\n",
    "title_amazon = f'Amazon daily difference chart from {amazon_dates[0]} to {amazon_dates[len(amazon_dates)-1]}'\n",
    "show_timerange(amazon_dates[0], amazon_dates[len(amazon_dates)-1], amazon_dates, amazon_waggle_list, \"Date\", \"Value\", title_amazon, 1500)\n",
    "\n",
    "start_date = \"01-01-1995\"\n",
    "end_date = \"01-07-2022\"\n",
    "tick_distance = (int(end_date[6:10])-int(start_date[6:10]))*24\n",
    "\n",
    "title_amazon = f'Amazon daily difference chart from {start_date} to {end_date}'\n",
    "show_timerange(start_date, end_date, amazon_dates, amazon_waggle_list, \"Date\", \"Value\", title_amazon, tick_distance)\n",
    "\n",
    "#daily\n",
    "min_percentage_diff = 5\n",
    "print_waggle_values(amazon_waggle_list, amazon_dates, min_percentage_diff)\n",
    "\n",
    "print_average_diff_per_year(amazon_waggle_list, amazon_dates, start_date[6:10], end_date[6:10])\n",
    "\n",
    "\n",
    "Prozentuale Unterschiede mit mindestens 5 zum Vortag:\n",
    "Prozentualer Unterschied von -19.23 am 16-05-1997\n",
    "Prozentualer Unterschied von -10.58 am 19-05-1997\n",
    "Prozentualer Unterschied von -5.42 am 21-05-1997\n",
    "Prozentualer Unterschied von -12.1 am 22-05-1997\n",
    "Prozentualer Unterschied von 7.41 am 27-05-1997\n",
    "Prozentualer Unterschied von 7.59 am 28-05-1997\n",
    "Prozentualer Unterschied von -5.13 am 29-05-1997\n",
    "Prozentualer Unterschied von 6.99 am 06-06-1997\n",
    "Prozentualer Unterschied von 9.28 am 09-06-1997\n",
    "Prozentualer Unterschied von -6.71 am 11-06-1997\n",
    "Prozentualer Unterschied von 5.5 am 03-07-1997\n",
    "Prozentualer Unterschied von 14.66 am 07-07-1997\n",
    "Prozentualer Unterschied von 11.36 am 08-07-1997\n",
    "Prozentualer Unterschied von 12.76 am 09-07-1997\n",
    "Prozentualer Unterschied von 8.04 am 11-07-1997\n",
    "Prozentualer Unterschied von -7.85 am 14-07-1997\n",
    "Prozentualer Unterschied von -8.07 am 15-07-1997\n",
    "Prozentualer Unterschied von 14.63 am 16-07-1997\n",
    "Prozentualer Unterschied von -6.67 am 18-07-1997\n",
    "Prozentualer Unterschied von 5.24 am 24-07-1997\n",
    "Prozentualer Unterschied von 6.07 am 29-07-1997\n",
    "Prozentualer Unterschied von 5.73 am 30-07-1997\n",
    "Prozentualer Unterschied von -5.36 am 06-08-1997\n",
    "Prozentualer Unterschied von 5.77 am 11-08-1997\n",
    "Prozentualer Unterschied von 6.44 am 26-08-1997\n",
    "Prozentualer Unterschied von 9.25 am 05-09-1997\n",
    "Prozentualer Unterschied von 24.07 am 09-09-1997\n",
    "Prozentualer Unterschied von 5.47 am 10-09-1997\n",
    "Prozentualer Unterschied von 15.03 am 15-09-1997\n",
    "Prozentualer Unterschied von -14.77 am 16-09-1997\n",
    "Prozentualer Unterschied von 10.67 am 17-09-1997\n",
    "Prozentualer Unterschied von 18.34 am 22-09-1997\n",
    "Prozentualer Unterschied von 12.24 am 23-09-1997\n",
    "Prozentualer Unterschied von -6.5 am 25-09-1997\n",
    "Prozentualer Unterschied von -6.24 am 26-09-1997\n",
    "Prozentualer Unterschied von 10.94 am 01-10-1997\n",
    "Prozentualer Unterschied von -8.92 am 02-10-1997\n",
    "Prozentualer Unterschied von -6.77 am 10-10-1997\n",
    "Prozentualer Unterschied von 5.31 am 13-10-1997\n",
    "Prozentualer Unterschied von -9.16 am 17-10-1997\n",
    "Prozentualer Unterschied von 7.65 am 21-10-1997\n",
    "Prozentualer Unterschied von 11.58 am 22-10-1997\n",
    "Prozentualer Unterschied von 12.32 am 24-10-1997\n",
    "Prozentualer Unterschied von -18.44 am 28-10-1997\n",
    "Prozentualer Unterschied von 31.38 am 29-10-1997\n",
    "Prozentualer Unterschied von -10.17 am 07-11-1997\n",
    "Prozentualer Unterschied von -5.67 am 11-11-1997\n",
    "Prozentualer Unterschied von -11.04 am 12-11-1997\n",
    "Prozentualer Unterschied von 7.41 am 17-11-1997\n",
    "Prozentualer Unterschied von 5.69 am 12-12-1997\n",
    "Prozentualer Unterschied von -5.83 am 17-12-1997\n",
    "Prozentualer Unterschied von 6.4 am 22-12-1997\n",
    "Prozentualer Unterschied von 5.45 am 30-12-1997\n",
    "Prozentualer Unterschied von -10.71 am 12-01-1998\n",
    "Prozentualer Unterschied von 7.19 am 14-01-1998\n",
    "Prozentualer Unterschied von 5.34 am 23-01-1998\n",
    "Prozentualer Unterschied von -6.82 am 26-01-1998\n",
    "Prozentualer Unterschied von 8.55 am 11-02-1998\n",
    "Prozentualer Unterschied von 10.2 am 27-02-1998\n",
    "Prozentualer Unterschied von 5.02 am 02-03-1998\n",
    "Prozentualer Unterschied von 5.4 am 06-03-1998\n",
    "Prozentualer Unterschied von 11.22 am 10-03-1998\n",
    "Prozentualer Unterschied von 7.73 am 19-03-1998\n",
    "Prozentualer Unterschied von 6.89 am 02-04-1998\n",
    "Prozentualer Unterschied von 5.62 am 03-04-1998\n",
    "Prozentualer Unterschied von -7.69 am 07-04-1998\n",
    "Prozentualer Unterschied von 6.95 am 09-04-1998\n",
    "Prozentualer Unterschied von -6.7 am 23-04-1998\n",
    "Prozentualer Unterschied von -5.75 am 24-04-1998\n",
    "Prozentualer Unterschied von 11.39 am 28-04-1998\n",
    "Prozentualer Unterschied von -5.58 am 12-05-1998\n",
    "Prozentualer Unterschied von -6.61 am 27-05-1998\n",
    "Prozentualer Unterschied von 8.55 am 28-05-1998\n",
    "Prozentualer Unterschied von 5.99 am 09-06-1998\n",
    "Prozentualer Unterschied von 11.17 am 10-06-1998\n",
    "Prozentualer Unterschied von 7.02 am 11-06-1998\n",
    "Prozentualer Unterschied von 14.93 am 12-06-1998\n",
    "Prozentualer Unterschied von -6.3 am 15-06-1998\n",
    "Prozentualer Unterschied von 12.18 am 16-06-1998\n",
    "Prozentualer Unterschied von 13.67 am 17-06-1998\n",
    "Prozentualer Unterschied von 6.75 am 18-06-1998\n",
    "Prozentualer Unterschied von -12.27 am 19-06-1998\n",
    "Prozentualer Unterschied von 5.19 am 22-06-1998\n",
    "Prozentualer Unterschied von 8.44 am 23-06-1998\n",
    "Prozentualer Unterschied von 17.19 am 24-06-1998\n",
    "Prozentualer Unterschied von 5.26 am 25-06-1998\n",
    "Prozentualer Unterschied von 13.69 am 02-07-1998\n",
    "Prozentualer Unterschied von 10.04 am 06-07-1998\n",
    "Prozentualer Unterschied von 12.27 am 07-07-1998\n",
    "Prozentualer Unterschied von -21.77 am 08-07-1998\n",
    "Prozentualer Unterschied von -6.89 am 10-07-1998\n",
    "Prozentualer Unterschied von -6.31 am 13-07-1998\n",
    "Prozentualer Unterschied von 12.44 am 14-07-1998\n",
    "Prozentualer Unterschied von 6.91 am 15-07-1998\n",
    "Prozentualer Unterschied von 7.79 am 20-07-1998\n",
    "Prozentualer Unterschied von 13.31 am 21-07-1998\n",
    "Prozentualer Unterschied von -7.83 am 27-07-1998\n",
    "Prozentualer Unterschied von -7.26 am 30-07-1998\n",
    "Prozentualer Unterschied von -7.48 am 06-08-1998\n",
    "Prozentualer Unterschied von 6.59 am 07-08-1998\n",
    "Prozentualer Unterschied von 5.17 am 10-08-1998\n",
    "Prozentualer Unterschied von 9.74 am 12-08-1998\n",
    "Prozentualer Unterschied von -7.6 am 17-08-1998\n",
    "Prozentualer Unterschied von 8.3 am 19-08-1998\n",
    "Prozentualer Unterschied von 5.52 am 25-08-1998\n",
    "Prozentualer Unterschied von -5.59 am 26-08-1998\n",
    "Prozentualer Unterschied von -11.95 am 31-08-1998\n",
    "Prozentualer Unterschied von -27.8 am 01-09-1998\n",
    "Prozentualer Unterschied von 9.2 am 02-09-1998\n",
    "Prozentualer Unterschied von 8.44 am 08-09-1998\n",
    "Prozentualer Unterschied von -11.31 am 10-09-1998\n",
    "Prozentualer Unterschied von -11.9 am 15-09-1998\n",
    "Prozentualer Unterschied von 8.33 am 17-09-1998\n",
    "Prozentualer Unterschied von 16.12 am 22-09-1998\n",
    "Prozentualer Unterschied von 17.96 am 24-09-1998\n",
    "Prozentualer Unterschied von -8.05 am 25-09-1998\n",
    "Prozentualer Unterschied von 18.15 am 28-09-1998\n",
    "Prozentualer Unterschied von -7.96 am 07-10-1998\n",
    "Prozentualer Unterschied von -19.24 am 08-10-1998\n",
    "Prozentualer Unterschied von 8.9 am 09-10-1998\n",
    "Prozentualer Unterschied von 7.62 am 12-10-1998\n",
    "Prozentualer Unterschied von -5.47 am 13-10-1998\n",
    "Prozentualer Unterschied von 9.85 am 20-10-1998\n",
    "Prozentualer Unterschied von 6.39 am 23-10-1998\n",
    "Prozentualer Unterschied von -5.79 am 28-10-1998\n",
    "Prozentualer Unterschied von 5.23 am 10-11-1998\n",
    "Prozentualer Unterschied von -6.08 am 12-11-1998\n",
    "Prozentualer Unterschied von 5.13 am 13-11-1998\n",
    "Prozentualer Unterschied von 17.2 am 18-11-1998\n",
    "Prozentualer Unterschied von 12.78 am 19-11-1998\n",
    "Prozentualer Unterschied von 9.07 am 23-11-1998\n",
    "Prozentualer Unterschied von 17.35 am 24-11-1998\n",
    "Prozentualer Unterschied von -15.54 am 01-12-1998\n",
    "Prozentualer Unterschied von 11.56 am 02-12-1998\n",
    "Prozentualer Unterschied von 8.31 am 09-12-1998\n",
    "Prozentualer Unterschied von 5.96 am 10-12-1998\n",
    "Prozentualer Unterschied von 5.27 am 14-12-1998\n",
    "Prozentualer Unterschied von 14.15 am 16-12-1998\n",
    "Prozentualer Unterschied von 7.2 am 18-12-1998\n",
    "Prozentualer Unterschied von 7.24 am 21-12-1998\n",
    "Prozentualer Unterschied von 7.72 am 22-12-1998\n",
    "Prozentualer Unterschied von 5.74 am 29-12-1998\n",
    "Prozentualer Unterschied von 24.47 am 06-01-1999\n",
    "Prozentualer Unterschied von 34.37 am 08-01-1999\n",
    "Prozentualer Unterschied von -30.75 am 13-01-1999\n",
    "Prozentualer Unterschied von 20.0 am 14-01-1999\n",
    "Prozentualer Unterschied von -6.67 am 15-01-1999\n",
    "Prozentualer Unterschied von 7.5 am 19-01-1999\n",
    "Prozentualer Unterschied von -10.26 am 20-01-1999\n",
    "Prozentualer Unterschied von -22.63 am 21-01-1999\n",
    "Prozentualer Unterschied von 22.11 am 25-01-1999\n",
    "Prozentualer Unterschied von -7.3 am 26-01-1999\n",
    "Prozentualer Unterschied von 19.09 am 27-01-1999\n",
    "Prozentualer Unterschied von -5.73 am 28-01-1999\n",
    "Prozentualer Unterschied von -6.34 am 03-02-1999\n",
    "Prozentualer Unterschied von 14.91 am 04-02-1999\n",
    "Prozentualer Unterschied von -6.59 am 05-02-1999\n",
    "Prozentualer Unterschied von -5.63 am 09-02-1999\n",
    "Prozentualer Unterschied von -8.98 am 10-02-1999\n",
    "Prozentualer Unterschied von 7.46 am 12-02-1999\n",
    "Prozentualer Unterschied von -7.89 am 17-02-1999\n",
    "Prozentualer Unterschied von 7.81 am 22-02-1999\n",
    "Prozentualer Unterschied von 8.23 am 23-02-1999\n",
    "Prozentualer Unterschied von 6.81 am 24-02-1999\n",
    "Prozentualer Unterschied von 8.68 am 26-02-1999\n",
    "Prozentualer Unterschied von 5.86 am 02-03-1999\n",
    "Prozentualer Unterschied von -7.95 am 03-03-1999\n",
    "Prozentualer Unterschied von 9.29 am 10-03-1999\n",
    "Prozentualer Unterschied von -5.53 am 17-03-1999\n",
    "Prozentualer Unterschied von 6.77 am 19-03-1999\n",
    "Prozentualer Unterschied von -6.12 am 22-03-1999\n",
    "Prozentualer Unterschied von -8.89 am 24-03-1999\n",
    "Prozentualer Unterschied von 10.03 am 25-03-1999\n",
    "Prozentualer Unterschied von 8.58 am 26-03-1999\n",
    "Prozentualer Unterschied von 7.14 am 29-03-1999\n",
    "Prozentualer Unterschied von 12.66 am 31-03-1999\n",
    "Prozentualer Unterschied von 6.88 am 06-04-1999\n",
    "Prozentualer Unterschied von -6.33 am 08-04-1999\n",
    "Prozentualer Unterschied von 6.03 am 13-04-1999\n",
    "Prozentualer Unterschied von -8.86 am 15-04-1999\n",
    "Prozentualer Unterschied von 10.85 am 16-04-1999\n",
    "Prozentualer Unterschied von -16.77 am 20-04-1999\n",
    "Prozentualer Unterschied von 9.57 am 21-04-1999\n",
    "Prozentualer Unterschied von 6.93 am 22-04-1999\n",
    "Prozentualer Unterschied von 8.36 am 26-04-1999\n",
    "Prozentualer Unterschied von -7.83 am 28-04-1999\n",
    "Prozentualer Unterschied von -13.78 am 29-04-1999\n",
    "Prozentualer Unterschied von -5.72 am 03-05-1999\n",
    "Prozentualer Unterschied von -8.54 am 04-05-1999\n",
    "Prozentualer Unterschied von -5.73 am 05-05-1999\n",
    "Prozentualer Unterschied von 10.29 am 11-05-1999\n",
    "Prozentualer Unterschied von -7.79 am 14-05-1999\n",
    "Prozentualer Unterschied von -8.84 am 25-05-1999\n",
    "Prozentualer Unterschied von 5.69 am 27-05-1999\n",
    "Prozentualer Unterschied von -6.05 am 02-06-1999\n",
    "Prozentualer Unterschied von 8.77 am 03-06-1999\n",
    "Prozentualer Unterschied von -7.3 am 04-06-1999\n",
    "Prozentualer Unterschied von 10.54 am 08-06-1999\n",
    "Prozentualer Unterschied von -5.05 am 09-06-1999\n",
    "Prozentualer Unterschied von -9.72 am 14-06-1999\n",
    "Prozentualer Unterschied von -11.24 am 15-06-1999\n",
    "Prozentualer Unterschied von 9.82 am 16-06-1999\n",
    "Prozentualer Unterschied von 10.18 am 17-06-1999\n",
    "Prozentualer Unterschied von 8.48 am 22-06-1999\n",
    "Prozentualer Unterschied von -6.19 am 23-06-1999\n",
    "Prozentualer Unterschied von 5.67 am 30-06-1999\n",
    "Prozentualer Unterschied von 7.51 am 01-07-1999\n",
    "Prozentualer Unterschied von -7.0 am 13-07-1999\n",
    "Prozentualer Unterschied von 9.57 am 14-07-1999\n",
    "Prozentualer Unterschied von 5.99 am 15-07-1999\n",
    "Prozentualer Unterschied von -5.06 am 20-07-1999\n",
    "Prozentualer Unterschied von -6.29 am 21-07-1999\n",
    "Prozentualer Unterschied von -5.69 am 23-07-1999\n",
    "Prozentualer Unterschied von -6.44 am 28-07-1999\n",
    "Prozentualer Unterschied von -6.6 am 05-08-1999\n",
    "Prozentualer Unterschied von 10.35 am 06-08-1999\n",
    "Prozentualer Unterschied von -5.3 am 09-08-1999\n",
    "Prozentualer Unterschied von -6.69 am 10-08-1999\n",
    "Prozentualer Unterschied von 8.2 am 11-08-1999\n",
    "Prozentualer Unterschied von 14.55 am 18-08-1999\n",
    "Prozentualer Unterschied von 9.12 am 23-08-1999\n",
    "Prozentualer Unterschied von 5.87 am 25-08-1999\n",
    "Prozentualer Unterschied von 8.3 am 26-08-1999\n",
    "Prozentualer Unterschied von -7.2 am 31-08-1999\n",
    "Prozentualer Unterschied von 7.29 am 01-09-1999\n",
    "Prozentualer Unterschied von -9.45 am 02-09-1999\n",
    "Prozentualer Unterschied von 10.65 am 03-09-1999\n",
    "Prozentualer Unterschied von 7.97 am 15-09-1999\n",
    "Prozentualer Unterschied von 6.56 am 23-09-1999\n",
    "Prozentualer Unterschied von -7.46 am 24-09-1999\n",
    "Prozentualer Unterschied von 6.75 am 27-09-1999\n",
    "Prozentualer Unterschied von -5.57 am 28-09-1999\n",
    "Prozentualer Unterschied von 6.4 am 29-09-1999\n",
    "Prozentualer Unterschied von 20.02 am 30-09-1999\n",
    "Prozentualer Unterschied von 7.62 am 07-10-1999\n",
    "Prozentualer Unterschied von -5.92 am 13-10-1999\n",
    "Prozentualer Unterschied von -5.75 am 15-10-1999\n",
    "Prozentualer Unterschied von 5.22 am 26-10-1999\n",
    "Prozentualer Unterschied von -12.44 am 28-10-1999\n",
    "Prozentualer Unterschied von -6.44 am 01-11-1999\n",
    "Prozentualer Unterschied von 26.52 am 09-11-1999\n",
    "Prozentualer Unterschied von -12.73 am 10-11-1999\n",
    "Prozentualer Unterschied von 8.09 am 26-11-1999\n",
    "Prozentualer Unterschied von -7.58 am 30-11-1999\n",
    "Prozentualer Unterschied von 7.56 am 03-12-1999\n",
    "Prozentualer Unterschied von -6.08 am 06-12-1999\n",
    "Prozentualer Unterschied von 10.01 am 09-12-1999\n",
    "Prozentualer Unterschied von 17.21 am 10-12-1999\n",
    "Prozentualer Unterschied von -10.48 am 15-12-1999\n",
    "Prozentualer Unterschied von 5.79 am 16-12-1999\n",
    "Prozentualer Unterschied von -10.46 am 27-12-1999\n",
    "Prozentualer Unterschied von -5.34 am 28-12-1999\n",
    "Prozentualer Unterschied von -6.28 am 31-12-1999\n",
    "Prozentualer Unterschied von -17.42 am 05-01-2000\n",
    "Prozentualer Unterschied von -6.05 am 07-01-2000\n",
    "Prozentualer Unterschied von 8.3 am 10-01-2000\n",
    "Prozentualer Unterschied von -7.84 am 11-01-2000\n",
    "Prozentualer Unterschied von -5.01 am 27-01-2000\n",
    "Prozentualer Unterschied von -7.12 am 31-01-2000\n",
    "Prozentualer Unterschied von 11.8 am 01-02-2000\n",
    "Prozentualer Unterschied von 19.41 am 03-02-2000\n",
    "Prozentualer Unterschied von -7.93 am 07-02-2000\n",
    "Prozentualer Unterschied von 8.85 am 09-02-2000\n",
    "Prozentualer Unterschied von -5.11 am 22-02-2000\n",
    "Prozentualer Unterschied von 8.77 am 24-02-2000\n",
    "Prozentualer Unterschied von 6.75 am 10-03-2000\n",
    "Prozentualer Unterschied von 6.12 am 17-03-2000\n",
    "Prozentualer Unterschied von 8.83 am 22-03-2000\n",
    "Prozentualer Unterschied von 7.37 am 24-03-2000\n",
    "Prozentualer Unterschied von -7.19 am 30-03-2000\n",
    "Prozentualer Unterschied von -7.06 am 11-04-2000\n",
    "Prozentualer Unterschied von -9.57 am 13-04-2000\n",
    "Prozentualer Unterschied von -17.28 am 14-04-2000\n",
    "Prozentualer Unterschied von -5.48 am 17-04-2000\n",
    "Prozentualer Unterschied von 5.25 am 18-04-2000\n",
    "Prozentualer Unterschied von 16.14 am 19-04-2000\n",
    "Prozentualer Unterschied von -7.49 am 24-04-2000\n",
    "Prozentualer Unterschied von -7.5 am 27-04-2000\n",
    "Prozentualer Unterschied von 9.51 am 28-04-2000\n",
    "Prozentualer Unterschied von 5.69 am 02-05-2000\n",
    "Prozentualer Unterschied von -6.65 am 03-05-2000\n",
    "Prozentualer Unterschied von 6.53 am 16-05-2000\n",
    "Prozentualer Unterschied von 5.57 am 18-05-2000\n",
    "Prozentualer Unterschied von -9.52 am 19-05-2000\n",
    "Prozentualer Unterschied von -8.04 am 24-05-2000\n",
    "Prozentualer Unterschied von 6.59 am 25-05-2000\n",
    "Prozentualer Unterschied von -6.57 am 26-05-2000\n",
    "Prozentualer Unterschied von 7.27 am 31-05-2000\n",
    "Prozentualer Unterschied von 7.16 am 02-06-2000\n",
    "Prozentualer Unterschied von 5.07 am 05-06-2000\n",
    "Prozentualer Unterschied von -7.66 am 13-06-2000\n",
    "Prozentualer Unterschied von -20.7 am 23-06-2000\n",
    "Prozentualer Unterschied von 9.26 am 28-06-2000\n",
    "Prozentualer Unterschied von 17.87 am 17-07-2000\n",
    "Prozentualer Unterschied von -6.41 am 18-07-2000\n",
    "Prozentualer Unterschied von -10.5 am 25-07-2000\n",
    "Prozentualer Unterschied von -10.34 am 27-07-2000\n",
    "Prozentualer Unterschied von 8.49 am 04-08-2000\n",
    "Prozentualer Unterschied von 9.84 am 14-08-2000\n",
    "Prozentualer Unterschied von 8.48 am 16-08-2000\n",
    "Prozentualer Unterschied von 8.76 am 24-08-2000\n",
    "Prozentualer Unterschied von 7.28 am 30-08-2000\n",
    "Prozentualer Unterschied von 15.42 am 06-09-2000\n",
    "Prozentualer Unterschied von -5.87 am 08-09-2000\n",
    "Prozentualer Unterschied von 6.96 am 14-09-2000\n",
    "Prozentualer Unterschied von -7.42 am 21-09-2000\n",
    "Prozentualer Unterschied von 7.41 am 25-09-2000\n",
    "Prozentualer Unterschied von -9.01 am 04-10-2000\n",
    "Prozentualer Unterschied von 5.23 am 05-10-2000\n",
    "Prozentualer Unterschied von -7.64 am 06-10-2000\n",
    "Prozentualer Unterschied von -6.92 am 09-10-2000\n",
    "Prozentualer Unterschied von -6.09 am 11-10-2000\n",
    "Prozentualer Unterschied von -14.54 am 13-10-2000\n",
    "Prozentualer Unterschied von 15.98 am 16-10-2000\n",
    "Prozentualer Unterschied von -11.56 am 17-10-2000\n",
    "Prozentualer Unterschied von -20.1 am 18-10-2000\n",
    "Prozentualer Unterschied von 33.65 am 19-10-2000\n",
    "Prozentualer Unterschied von 7.22 am 23-10-2000\n",
    "Prozentualer Unterschied von 13.81 am 25-10-2000\n",
    "Prozentualer Unterschied von -5.33 am 26-10-2000\n",
    "Prozentualer Unterschied von 5.44 am 27-10-2000\n",
    "Prozentualer Unterschied von 9.56 am 01-11-2000\n",
    "Prozentualer Unterschied von 6.28 am 02-11-2000\n",
    "Prozentualer Unterschied von -5.35 am 07-11-2000\n",
    "Prozentualer Unterschied von -9.2 am 09-11-2000\n",
    "Prozentualer Unterschied von -5.93 am 10-11-2000\n",
    "Prozentualer Unterschied von -6.3 am 13-11-2000\n",
    "Prozentualer Unterschied von -7.14 am 20-11-2000\n",
    "Prozentualer Unterschied von -10.33 am 22-11-2000\n",
    "Prozentualer Unterschied von 10.67 am 24-11-2000\n",
    "Prozentualer Unterschied von 12.6 am 27-11-2000\n",
    "Prozentualer Unterschied von -12.61 am 28-11-2000\n",
    "Prozentualer Unterschied von 7.69 am 05-12-2000\n",
    "Prozentualer Unterschied von -8.99 am 06-12-2000\n",
    "Prozentualer Unterschied von -6.58 am 07-12-2000\n",
    "Prozentualer Unterschied von 7.1 am 12-12-2000\n",
    "Prozentualer Unterschied von 8.42 am 13-12-2000\n",
    "Prozentualer Unterschied von -9.41 am 14-12-2000\n",
    "Prozentualer Unterschied von -7.53 am 15-12-2000\n",
    "Prozentualer Unterschied von -6.74 am 18-12-2000\n",
    "Prozentualer Unterschied von -20.31 am 20-12-2000\n",
    "Prozentualer Unterschied von -6.49 am 22-12-2000\n",
    "Prozentualer Unterschied von 6.53 am 26-12-2000\n",
    "Prozentualer Unterschied von -5.6 am 02-01-2001\n",
    "Prozentualer Unterschied von -13.83 am 03-01-2001\n",
    "Prozentualer Unterschied von 24.77 am 04-01-2001\n",
    "Prozentualer Unterschied von -8.82 am 05-01-2001\n",
    "Prozentualer Unterschied von -6.85 am 08-01-2001\n",
    "Prozentualer Unterschied von 8.8 am 10-01-2001\n",
    "Prozentualer Unterschied von 10.12 am 12-01-2001\n",
    "Prozentualer Unterschied von 5.59 am 16-01-2001\n",
    "Prozentualer Unterschied von 10.88 am 19-01-2001\n",
    "Prozentualer Unterschied von -5.77 am 23-01-2001\n",
    "Prozentualer Unterschied von 13.03 am 25-01-2001\n",
    "Prozentualer Unterschied von -12.68 am 26-01-2001\n",
    "Prozentualer Unterschied von 7.52 am 30-01-2001\n",
    "Prozentualer Unterschied von -7.9 am 31-01-2001\n",
    "Prozentualer Unterschied von -9.24 am 01-02-2001\n",
    "Prozentualer Unterschied von -6.18 am 02-02-2001\n",
    "Prozentualer Unterschied von -9.3 am 05-02-2001\n",
    "Prozentualer Unterschied von -5.56 am 06-02-2001\n",
    "Prozentualer Unterschied von 9.95 am 07-02-2001\n",
    "Prozentualer Unterschied von -6.53 am 09-02-2001\n",
    "Prozentualer Unterschied von 6.19 am 13-02-2001\n",
    "Prozentualer Unterschied von -5.83 am 14-02-2001\n",
    "Prozentualer Unterschied von -10.09 am 21-02-2001\n",
    "Prozentualer Unterschied von -12.22 am 01-03-2001\n",
    "Prozentualer Unterschied von 23.36 am 05-03-2001\n",
    "Prozentualer Unterschied von 5.68 am 06-03-2001\n",
    "Prozentualer Unterschied von -8.72 am 07-03-2001\n",
    "Prozentualer Unterschied von -5.2 am 14-03-2001\n",
    "Prozentualer Unterschied von 10.98 am 15-03-2001\n",
    "Prozentualer Unterschied von -6.59 am 16-03-2001\n",
    "Prozentualer Unterschied von 5.29 am 19-03-2001\n",
    "Prozentualer Unterschied von -5.59 am 20-03-2001\n",
    "Prozentualer Unterschied von -15.68 am 03-04-2001\n",
    "Prozentualer Unterschied von 5.25 am 05-04-2001\n",
    "Prozentualer Unterschied von 33.03 am 09-04-2001\n",
    "Prozentualer Unterschied von -5.07 am 10-04-2001\n",
    "Prozentualer Unterschied von 16.55 am 11-04-2001\n",
    "Prozentualer Unterschied von 11.11 am 16-04-2001\n",
    "Prozentualer Unterschied von 13.4 am 18-04-2001\n",
    "Prozentualer Unterschied von 7.92 am 19-04-2001\n",
    "Prozentualer Unterschied von -7.57 am 20-04-2001\n",
    "Prozentualer Unterschied von 7.8 am 02-05-2001\n",
    "Prozentualer Unterschied von 6.18 am 07-05-2001\n",
    "Prozentualer Unterschied von -6.22 am 08-05-2001\n",
    "Prozentualer Unterschied von -5.52 am 11-05-2001\n",
    "Prozentualer Unterschied von -8.12 am 15-05-2001\n",
    "Prozentualer Unterschied von 5.25 am 18-05-2001\n",
    "Prozentualer Unterschied von 12.31 am 22-05-2001\n",
    "Prozentualer Unterschied von 5.98 am 25-05-2001\n",
    "Prozentualer Unterschied von 8.71 am 01-06-2001\n",
    "Prozentualer Unterschied von -5.1 am 07-06-2001\n",
    "Prozentualer Unterschied von -5.81 am 12-06-2001\n",
    "Prozentualer Unterschied von -5.61 am 14-06-2001\n",
    "Prozentualer Unterschied von -7.86 am 15-06-2001\n",
    "Prozentualer Unterschied von -9.48 am 20-06-2001\n",
    "Prozentualer Unterschied von 12.51 am 21-06-2001\n",
    "Prozentualer Unterschied von 10.13 am 27-06-2001\n",
    "Prozentualer Unterschied von -6.49 am 17-07-2001\n",
    "Prozentualer Unterschied von -19.98 am 24-07-2001\n",
    "Prozentualer Unterschied von -9.77 am 25-07-2001\n",
    "Prozentualer Unterschied von -5.04 am 26-07-2001\n",
    "Prozentualer Unterschied von 5.66 am 27-07-2001\n",
    "Prozentualer Unterschied von -5.03 am 10-08-2001\n",
    "Prozentualer Unterschied von -5.65 am 17-08-2001\n",
    "Prozentualer Unterschied von 7.15 am 20-08-2001\n",
    "Prozentualer Unterschied von 5.0 am 21-08-2001\n",
    "Prozentualer Unterschied von -5.05 am 22-08-2001\n",
    "Prozentualer Unterschied von -9.76 am 30-08-2001\n",
    "Prozentualer Unterschied von -9.47 am 06-09-2001\n",
    "Prozentualer Unterschied von 5.53 am 10-09-2001\n",
    "Prozentualer Unterschied von -13.1 am 17-09-2001\n",
    "Prozentualer Unterschied von 10.79 am 24-09-2001\n",
    "Prozentualer Unterschied von -10.14 am 27-09-2001\n",
    "Prozentualer Unterschied von -5.44 am 01-10-2001\n",
    "Prozentualer Unterschied von 14.91 am 04-10-2001\n",
    "Prozentualer Unterschied von 9.28 am 11-10-2001\n",
    "Prozentualer Unterschied von 6.19 am 15-10-2001\n",
    "Prozentualer Unterschied von 12.01 am 16-10-2001\n",
    "Prozentualer Unterschied von 8.13 am 17-10-2001\n",
    "Prozentualer Unterschied von -10.72 am 18-10-2001\n",
    "Prozentualer Unterschied von 14.62 am 23-10-2001\n",
    "Prozentualer Unterschied von -12.97 am 24-10-2001\n",
    "Prozentualer Unterschied von -8.2 am 25-10-2001\n",
    "Prozentualer Unterschied von -7.88 am 30-10-2001\n",
    "Prozentualer Unterschied von 9.27 am 08-11-2001\n",
    "Prozentualer Unterschied von -7.96 am 09-11-2001\n",
    "Prozentualer Unterschied von 20.84 am 15-11-2001\n",
    "Prozentualer Unterschied von 10.45 am 26-11-2001\n",
    "Prozentualer Unterschied von 22.58 am 27-11-2001\n",
    "Prozentualer Unterschied von -6.72 am 28-11-2001\n",
    "Prozentualer Unterschied von 5.78 am 29-11-2001\n",
    "Prozentualer Unterschied von 13.45 am 05-12-2001\n",
    "Prozentualer Unterschied von -6.02 am 10-12-2001\n",
    "Prozentualer Unterschied von -7.16 am 13-12-2001\n",
    "Prozentualer Unterschied von 8.08 am 26-12-2001\n",
    "Prozentualer Unterschied von 8.0 am 04-01-2002\n",
    "Prozentualer Unterschied von -5.4 am 11-01-2002\n",
    "Prozentualer Unterschied von 32.71 am 22-01-2002\n",
    "Prozentualer Unterschied von 6.35 am 25-01-2002\n",
    "Prozentualer Unterschied von 9.59 am 28-01-2002\n",
    "Prozentualer Unterschied von -10.04 am 30-01-2002\n",
    "Prozentualer Unterschied von -8.24 am 04-02-2002\n",
    "Prozentualer Unterschied von -7.2 am 05-02-2002\n",
    "Prozentualer Unterschied von -5.46 am 07-02-2002\n",
    "Prozentualer Unterschied von 9.82 am 11-02-2002\n",
    "Prozentualer Unterschied von -6.9 am 19-02-2002\n",
    "Prozentualer Unterschied von 7.7 am 27-02-2002\n",
    "Prozentualer Unterschied von 9.13 am 04-03-2002\n",
    "Prozentualer Unterschied von -7.38 am 06-03-2002\n",
    "Prozentualer Unterschied von 10.73 am 07-03-2002\n",
    "Prozentualer Unterschied von -6.6 am 14-03-2002\n",
    "Prozentualer Unterschied von 7.07 am 19-03-2002\n",
    "Prozentualer Unterschied von -5.37 am 26-03-2002\n",
    "Prozentualer Unterschied von -5.05 am 27-03-2002\n",
    "Prozentualer Unterschied von -5.12 am 08-04-2002\n",
    "Prozentualer Unterschied von 8.48 am 09-04-2002\n",
    "Prozentualer Unterschied von 5.66 am 16-04-2002\n",
    "Prozentualer Unterschied von 6.13 am 24-04-2002\n",
    "Prozentualer Unterschied von 8.4 am 25-04-2002\n",
    "Prozentualer Unterschied von 5.07 am 14-05-2002\n",
    "Prozentualer Unterschied von -5.86 am 20-05-2002\n",
    "Prozentualer Unterschied von 6.96 am 18-06-2002\n",
    "Prozentualer Unterschied von -13.03 am 26-06-2002\n",
    "Prozentualer Unterschied von 9.67 am 27-06-2002\n",
    "Prozentualer Unterschied von -15.89 am 02-07-2002\n",
    "Prozentualer Unterschied von 7.55 am 05-07-2002\n",
    "Prozentualer Unterschied von -6.33 am 11-07-2002\n",
    "Prozentualer Unterschied von 7.44 am 12-07-2002\n",
    "Prozentualer Unterschied von 7.33 am 17-07-2002\n",
    "Prozentualer Unterschied von -5.46 am 18-07-2002\n",
    "Prozentualer Unterschied von -20.4 am 24-07-2002\n",
    "Prozentualer Unterschied von 10.83 am 25-07-2002\n",
    "Prozentualer Unterschied von -7.22 am 26-07-2002\n",
    "Prozentualer Unterschied von 7.09 am 30-07-2002\n",
    "Prozentualer Unterschied von 9.33 am 10-09-2002\n",
    "Prozentualer Unterschied von -10.6 am 23-09-2002\n",
    "Prozentualer Unterschied von 5.78 am 27-09-2002\n",
    "Prozentualer Unterschied von 5.94 am 11-10-2002\n",
    "Prozentualer Unterschied von 9.13 am 15-10-2002\n",
    "Prozentualer Unterschied von -7.91 am 16-10-2002\n",
    "Prozentualer Unterschied von 10.02 am 17-10-2002\n",
    "Prozentualer Unterschied von -8.06 am 18-10-2002\n",
    "Prozentualer Unterschied von -5.56 am 25-10-2002\n",
    "Prozentualer Unterschied von 7.04 am 14-11-2002\n",
    "Prozentualer Unterschied von 7.09 am 18-11-2002\n",
    "Prozentualer Unterschied von 9.27 am 21-11-2002\n",
    "Prozentualer Unterschied von -8.28 am 06-12-2002\n",
    "Prozentualer Unterschied von -7.5 am 27-12-2002\n",
    "Prozentualer Unterschied von -5.61 am 30-12-2002\n",
    "Prozentualer Unterschied von 5.2 am 13-03-2003\n",
    "Prozentualer Unterschied von 8.13 am 18-03-2003\n",
    "Prozentualer Unterschied von 5.2 am 21-03-2003\n",
    "Prozentualer Unterschied von 5.22 am 23-04-2003\n",
    "Prozentualer Unterschied von 10.24 am 25-04-2003\n",
    "Prozentualer Unterschied von 5.04 am 14-05-2003\n",
    "Prozentualer Unterschied von 7.16 am 28-05-2003\n",
    "Prozentualer Unterschied von 5.74 am 23-07-2003\n",
    "Prozentualer Unterschied von 8.74 am 24-07-2003\n",
    "Prozentualer Unterschied von 7.34 am 19-08-2003\n",
    "Prozentualer Unterschied von 6.2 am 24-09-2003\n",
    "Prozentualer Unterschied von -6.16 am 22-10-2003\n",
    "Prozentualer Unterschied von -5.48 am 23-10-2003\n",
    "Prozentualer Unterschied von -5.45 am 28-01-2004\n",
    "Prozentualer Unterschied von -7.01 am 04-02-2004\n",
    "Prozentualer Unterschied von 5.03 am 26-03-2004\n",
    "Prozentualer Unterschied von 5.87 am 02-04-2004\n",
    "Prozentualer Unterschied von 5.09 am 20-04-2004\n",
    "Prozentualer Unterschied von -5.16 am 21-04-2004\n",
    "Prozentualer Unterschied von -5.6 am 03-05-2004\n",
    "Prozentualer Unterschied von 5.05 am 26-05-2004\n",
    "Prozentualer Unterschied von 5.47 am 02-06-2004\n",
    "Prozentualer Unterschied von -7.63 am 22-07-2004\n",
    "Prozentualer Unterschied von -5.27 am 26-07-2004\n",
    "Prozentualer Unterschied von -5.77 am 06-08-2004\n",
    "Prozentualer Unterschied von 6.72 am 17-08-2004\n",
    "Prozentualer Unterschied von 6.17 am 19-08-2004\n",
    "Prozentualer Unterschied von -7.84 am 22-10-2004\n",
    "Prozentualer Unterschied von -6.13 am 25-10-2004\n",
    "Prozentualer Unterschied von 11.08 am 28-12-2004\n",
    "Prozentualer Unterschied von -5.07 am 04-01-2005\n",
    "Prozentualer Unterschied von -6.21 am 20-01-2005\n",
    "Prozentualer Unterschied von -18.93 am 03-02-2005\n",
    "Prozentualer Unterschied von -7.75 am 27-04-2005\n",
    "Prozentualer Unterschied von 9.92 am 27-07-2005\n",
    "Prozentualer Unterschied von -12.54 am 26-10-2005\n",
    "Prozentualer Unterschied von 6.91 am 15-11-2005\n",
    "Prozentualer Unterschied von -14.01 am 03-02-2006\n",
    "Prozentualer Unterschied von 5.84 am 25-05-2006\n",
    "Prozentualer Unterschied von -15.41 am 26-07-2006\n",
    "Prozentualer Unterschied von -8.03 am 27-07-2006\n",
    "Prozentualer Unterschied von -6.27 am 22-09-2006\n",
    "Prozentualer Unterschied von 13.48 am 25-10-2006\n",
    "Prozentualer Unterschied von 18.7 am 25-04-2007\n",
    "Prozentualer Unterschied von 6.36 am 26-04-2007\n",
    "Prozentualer Unterschied von 8.39 am 27-04-2007\n",
    "Prozentualer Unterschied von 7.71 am 22-05-2007\n",
    "Prozentualer Unterschied von 19.17 am 25-07-2007\n",
    "Prozentualer Unterschied von -6.69 am 01-08-2007\n",
    "Prozentualer Unterschied von 5.43 am 22-08-2007\n",
    "Prozentualer Unterschied von -6.2 am 12-10-2007\n",
    "Prozentualer Unterschied von 6.76 am 23-10-2007\n",
    "Prozentualer Unterschied von -5.05 am 09-11-2007\n",
    "Prozentualer Unterschied von -5.05 am 12-11-2007\n",
    "Prozentualer Unterschied von 5.58 am 28-11-2007\n",
    "Prozentualer Unterschied von 5.5 am 05-12-2007\n",
    "Prozentualer Unterschied von -7.94 am 22-01-2008\n",
    "Prozentualer Unterschied von 5.58 am 25-01-2008\n",
    "Prozentualer Unterschied von -6.3 am 31-01-2008\n",
    "Prozentualer Unterschied von 14.67 am 01-02-2008\n",
    "Prozentualer Unterschied von -5.72 am 04-02-2008\n",
    "Prozentualer Unterschied von -6.82 am 07-02-2008\n",
    "Prozentualer Unterschied von 8.95 am 08-02-2008\n",
    "Prozentualer Unterschied von -5.1 am 03-03-2008\n",
    "Prozentualer Unterschied von 6.47 am 05-03-2008\n",
    "Prozentualer Unterschied von 5.38 am 14-03-2008\n",
    "Prozentualer Unterschied von 5.2 am 24-03-2008\n",
    "Prozentualer Unterschied von 5.6 am 02-04-2008\n",
    "Prozentualer Unterschied von 6.03 am 17-06-2008\n",
    "Prozentualer Unterschied von -5.18 am 10-07-2008\n",
    "Prozentualer Unterschied von 6.36 am 17-07-2008\n",
    "Prozentualer Unterschied von 13.1 am 24-07-2008\n",
    "Prozentualer Unterschied von 8.9 am 12-08-2008\n",
    "Prozentualer Unterschied von 6.35 am 08-09-2008\n",
    "Prozentualer Unterschied von -5.92 am 11-09-2008\n",
    "Prozentualer Unterschied von -5.92 am 18-09-2008\n",
    "Prozentualer Unterschied von 9.63 am 19-09-2008\n",
    "Prozentualer Unterschied von -6.58 am 23-09-2008\n",
    "Prozentualer Unterschied von 9.02 am 01-10-2008\n",
    "Prozentualer Unterschied von -5.78 am 02-10-2008\n",
    "Prozentualer Unterschied von -7.72 am 06-10-2008\n",
    "Prozentualer Unterschied von -15.43 am 08-10-2008\n",
    "Prozentualer Unterschied von 11.38 am 09-10-2008\n",
    "Prozentualer Unterschied von -14.49 am 10-10-2008\n",
    "Prozentualer Unterschied von 11.27 am 13-10-2008\n",
    "Prozentualer Unterschied von 7.7 am 14-10-2008\n",
    "Prozentualer Unterschied von -14.24 am 15-10-2008\n",
    "Prozentualer Unterschied von -14.8 am 16-10-2008\n",
    "Prozentualer Unterschied von 5.24 am 17-10-2008\n",
    "Prozentualer Unterschied von 6.84 am 20-10-2008\n",
    "Prozentualer Unterschied von -13.35 am 23-10-2008\n",
    "Prozentualer Unterschied von 9.5 am 27-10-2008\n",
    "Prozentualer Unterschied von 5.1 am 28-10-2008\n",
    "Prozentualer Unterschied von 7.83 am 29-10-2008\n",
    "Prozentualer Unterschied von 5.82 am 30-10-2008\n",
    "Prozentualer Unterschied von -13.35 am 06-11-2008\n",
    "Prozentualer Unterschied von -5.76 am 11-11-2008\n",
    "Prozentualer Unterschied von -6.6 am 12-11-2008\n",
    "Prozentualer Unterschied von -5.89 am 13-11-2008\n",
    "Prozentualer Unterschied von 5.34 am 14-11-2008\n",
    "Prozentualer Unterschied von -8.48 am 17-11-2008\n",
    "Prozentualer Unterschied von -7.06 am 20-11-2008\n",
    "Prozentualer Unterschied von 6.6 am 24-11-2008\n",
    "Prozentualer Unterschied von 8.51 am 25-11-2008\n",
    "Prozentualer Unterschied von 7.73 am 28-11-2008\n",
    "Prozentualer Unterschied von 14.39 am 04-12-2008\n",
    "Prozentualer Unterschied von 7.1 am 08-12-2008\n",
    "Prozentualer Unterschied von 6.59 am 15-12-2008\n",
    "Prozentualer Unterschied von 5.32 am 17-12-2008\n",
    "Prozentualer Unterschied von 8.53 am 05-01-2009\n",
    "Prozentualer Unterschied von -5.84 am 13-01-2009\n",
    "Prozentualer Unterschied von 6.67 am 16-01-2009\n",
    "Prozentualer Unterschied von 14.81 am 30-01-2009\n",
    "Prozentualer Unterschied von 5.35 am 09-02-2009\n",
    "Prozentualer Unterschied von 5.06 am 23-02-2009\n",
    "Prozentualer Unterschied von 6.0 am 11-03-2009\n",
    "Prozentualer Unterschied von 5.34 am 18-03-2009\n",
    "Prozentualer Unterschied von 5.38 am 02-06-2009\n",
    "Prozentualer Unterschied von 5.63 am 17-09-2009\n",
    "Prozentualer Unterschied von 18.57 am 23-10-2009\n",
    "Prozentualer Unterschied von 7.35 am 26-10-2009\n",
    "Prozentualer Unterschied von -5.08 am 01-02-2010\n",
    "Prozentualer Unterschied von 5.32 am 02-03-2010\n",
    "Prozentualer Unterschied von -5.62 am 05-05-2010\n",
    "Prozentualer Unterschied von 5.49 am 26-05-2010\n",
    "Prozentualer Unterschied von -6.61 am 30-06-2010\n",
    "Prozentualer Unterschied von -10.77 am 23-07-2010\n",
    "Prozentualer Unterschied von 11.64 am 26-07-2010\n",
    "Prozentualer Unterschied von 5.61 am 25-10-2010\n",
    "Prozentualer Unterschied von 6.97 am 28-04-2011\n",
    "Prozentualer Unterschied von -5.71 am 19-08-2011\n",
    "Prozentualer Unterschied von 8.37 am 24-08-2011\n",
    "Prozentualer Unterschied von 6.06 am 29-08-2011\n",
    "Prozentualer Unterschied von 6.85 am 07-09-2011\n",
    "Prozentualer Unterschied von -6.82 am 30-09-2011\n",
    "Prozentualer Unterschied von -14.63 am 26-10-2011\n",
    "Prozentualer Unterschied von -5.86 am 21-11-2011\n",
    "Prozentualer Unterschied von -5.07 am 14-12-2011\n",
    "Prozentualer Unterschied von -10.41 am 01-02-2012\n",
    "Prozentualer Unterschied von -7.06 am 16-02-2012\n",
    "Prozentualer Unterschied von 16.15 am 27-04-2012\n",
    "Prozentualer Unterschied von 5.22 am 30-07-2012\n",
    "Prozentualer Unterschied von 5.06 am 02-01-2013\n",
    "Prozentualer Unterschied von -5.58 am 29-04-2013\n",
    "Prozentualer Unterschied von 8.79 am 25-10-2013\n",
    "Prozentualer Unterschied von -5.59 am 31-01-2014\n",
    "Prozentualer Unterschied von -5.02 am 11-04-2014\n",
    "Prozentualer Unterschied von 5.49 am 06-06-2014\n",
    "Prozentualer Unterschied von -11.86 am 25-07-2014\n",
    "Prozentualer Unterschied von -9.25 am 24-10-2014\n",
    "Prozentualer Unterschied von 13.65 am 30-01-2015\n",
    "Prozentualer Unterschied von 12.5 am 24-04-2015\n",
    "Prozentualer Unterschied von 17.76 am 24-07-2015\n",
    "Prozentualer Unterschied von -8.85 am 27-07-2015\n",
    "Prozentualer Unterschied von -8.63 am 24-08-2015\n",
    "Prozentualer Unterschied von 5.16 am 25-08-2015\n",
    "Prozentualer Unterschied von 6.13 am 27-08-2015\n",
    "Prozentualer Unterschied von 9.77 am 23-10-2015\n",
    "Prozentualer Unterschied von -6.54 am 14-01-2016\n",
    "Prozentualer Unterschied von -5.98 am 29-01-2016\n",
    "Prozentualer Unterschied von -5.15 am 04-02-2016\n",
    "Prozentualer Unterschied von -8.09 am 08-02-2016\n",
    "Prozentualer Unterschied von 8.2 am 29-04-2016\n",
    "Prozentualer Unterschied von -5.92 am 28-10-2016\n",
    "Prozentualer Unterschied von -5.53 am 11-11-2016\n",
    "Prozentualer Unterschied von -5.37 am 28-07-2017\n",
    "Prozentualer Unterschied von 7.94 am 27-10-2017\n",
    "Prozentualer Unterschied von -5.06 am 05-02-2018\n",
    "Prozentualer Unterschied von 6.43 am 07-02-2018\n",
    "Prozentualer Unterschied von -7.98 am 28-03-2018\n",
    "Prozentualer Unterschied von 6.17 am 05-04-2018\n",
    "Prozentualer Unterschied von -5.07 am 25-04-2018\n",
    "Prozentualer Unterschied von 10.03 am 27-04-2018\n",
    "Prozentualer Unterschied von -7.21 am 11-10-2018\n",
    "Prozentualer Unterschied von -10.47 am 30-10-2018\n",
    "Prozentualer Unterschied von 5.64 am 31-10-2018\n",
    "Prozentualer Unterschied von -8.85 am 20-11-2018\n",
    "Prozentualer Unterschied von 7.34 am 21-11-2018\n",
    "Prozentualer Unterschied von 5.36 am 03-12-2018\n",
    "Prozentualer Unterschied von -8.04 am 06-12-2018\n",
    "Prozentualer Unterschied von 5.59 am 07-12-2018\n",
    "Prozentualer Unterschied von -8.12 am 24-12-2018\n",
    "Prozentualer Unterschied von 6.23 am 27-12-2018\n",
    "Prozentualer Unterschied von 10.41 am 31-01-2020\n",
    "Prozentualer Unterschied von -6.49 am 24-02-2020\n",
    "Prozentualer Unterschied von -6.19 am 28-02-2020\n",
    "Prozentualer Unterschied von 5.06 am 02-03-2020\n",
    "Prozentualer Unterschied von -5.39 am 09-03-2020\n",
    "Prozentualer Unterschied von 5.47 am 10-03-2020\n",
    "Prozentualer Unterschied von -7.31 am 12-03-2020\n",
    "Prozentualer Unterschied von -6.47 am 16-03-2020\n",
    "Prozentualer Unterschied von 8.16 am 17-03-2020\n",
    "Prozentualer Unterschied von 6.29 am 19-03-2020\n",
    "Prozentualer Unterschied von -5.12 am 23-03-2020\n",
    "Prozentualer Unterschied von 6.77 am 24-03-2020\n",
    "Prozentualer Unterschied von 7.87 am 14-04-2020\n",
    "Prozentualer Unterschied von 5.58 am 02-07-2020\n",
    "Prozentualer Unterschied von 7.74 am 21-07-2020\n",
    "Prozentualer Unterschied von -5.43 am 24-07-2020\n",
    "Prozentualer Unterschied von 7.63 am 31-07-2020\n",
    "Prozentualer Unterschied von -5.24 am 08-09-2020\n",
    "Prozentualer Unterschied von -5.37 am 17-09-2020\n",
    "Prozentualer Unterschied von 5.06 am 05-11-2020\n",
    "Prozentualer Unterschied von 5.3 am 07-07-2021\n",
    "Prozentualer Unterschied von -7.71 am 30-07-2021\n",
    "Prozentualer Unterschied von -7.3 am 24-01-2022\n",
    "Prozentualer Unterschied von -8.59 am 03-02-2022\n",
    "Prozentualer Unterschied von 9.78 am 04-02-2022\n",
    "Prozentualer Unterschied von -7.79 am 24-02-2022\n",
    "Prozentualer Unterschied von 7.66 am 25-02-2022\n",
    "Prozentualer Unterschied von -6.02 am 08-03-2022\n",
    "Prozentualer Unterschied von -8.67 am 29-04-2022\n",
    "Prozentualer Unterschied von -5.74 am 02-05-2022\n",
    "Prozentualer Unterschied von -6.63 am 06-05-2022\n",
    "Prozentualer Unterschied von 6.15 am 13-05-2022\n",
    "Prozentualer Unterschied von 5.17 am 27-05-2022\n",
    "Prozentualer Unterschied von 5.14 am 01-06-2022\n",
    "Prozentualer Unterschied von -5.48 am 10-06-2022\n",
    "Prozentualer Unterschied von -8.14 am 13-06-2022\n",
    "Prozentualer Unterschied von 5.25 am 21-06-2022\n",
    "Prozentualer Unterschied von -5.39 am 29-06-2022\n",
    "Prozentualer Unterschied von 5.21 am 06-07-2022\n",
    "\n",
    "Entwicklung von 1995 bis 2022\n",
    "\n",
    "Werte für das Jahr: 1997\n",
    "Tage mit Anstieg: 81\n",
    "Durchschnittlicher Anstieg pro Tag: 5.11\n",
    "Tage mit Abfall: 79\n",
    "Durchschnittlicher Abfall pro Tag: 3.93\n",
    "\n",
    "Werte für das Jahr: 1998\n",
    "Tage mit Anstieg: 137\n",
    "Durchschnittlicher Anstieg pro Tag: 5.42\n",
    "Tage mit Abfall: 115\n",
    "Durchschnittlicher Abfall pro Tag: 3.92\n",
    "\n",
    "Werte für das Jahr: 1999\n",
    "Tage mit Anstieg: 120\n",
    "Durchschnittlicher Anstieg pro Tag: 6.19\n",
    "Tage mit Abfall: 132\n",
    "Durchschnittlicher Abfall pro Tag: 4.8\n",
    "\n",
    "Werte für das Jahr: 2000\n",
    "Tage mit Anstieg: 111\n",
    "Durchschnittlicher Anstieg pro Tag: 4.98\n",
    "Tage mit Abfall: 141\n",
    "Durchschnittlicher Abfall pro Tag: 4.64\n",
    "\n",
    "Werte für das Jahr: 2001\n",
    "Tage mit Anstieg: 114\n",
    "Durchschnittlicher Anstieg pro Tag: 5.65\n",
    "Tage mit Abfall: 134\n",
    "Durchschnittlicher Abfall pro Tag: 4.68\n",
    "\n",
    "Werte für das Jahr: 2002\n",
    "Tage mit Anstieg: 131\n",
    "Durchschnittlicher Anstieg pro Tag: 3.61\n",
    "Tage mit Abfall: 121\n",
    "Durchschnittlicher Abfall pro Tag: 3.21\n",
    "\n",
    "Werte für das Jahr: 2003\n",
    "Tage mit Anstieg: 148\n",
    "Durchschnittlicher Anstieg pro Tag: 2.15\n",
    "Tage mit Abfall: 104\n",
    "Durchschnittlicher Abfall pro Tag: 2.01\n",
    "\n",
    "Werte für das Jahr: 2004\n",
    "Tage mit Anstieg: 128\n",
    "Durchschnittlicher Anstieg pro Tag: 1.96\n",
    "Tage mit Abfall: 124\n",
    "Durchschnittlicher Abfall pro Tag: 2.08\n",
    "\n",
    "Werte für das Jahr: 2005\n",
    "Tage mit Anstieg: 135\n",
    "Durchschnittlicher Anstieg pro Tag: 1.35\n",
    "Tage mit Abfall: 117\n",
    "Durchschnittlicher Abfall pro Tag: 1.45\n",
    "\n",
    "Werte für das Jahr: 2006\n",
    "Tage mit Anstieg: 123\n",
    "Durchschnittlicher Anstieg pro Tag: 1.61\n",
    "Tage mit Abfall: 128\n",
    "Durchschnittlicher Abfall pro Tag: 1.62\n",
    "\n",
    "Werte für das Jahr: 2007\n",
    "Tage mit Anstieg: 139\n",
    "Durchschnittlicher Anstieg pro Tag: 2.0\n",
    "Tage mit Abfall: 112\n",
    "Durchschnittlicher Abfall pro Tag: 1.64\n",
    "\n",
    "Werte für das Jahr: 2008\n",
    "Tage mit Anstieg: 111\n",
    "Durchschnittlicher Anstieg pro Tag: 3.67\n",
    "Tage mit Abfall: 142\n",
    "Durchschnittlicher Abfall pro Tag: 3.11\n",
    "\n",
    "Werte für das Jahr: 2009\n",
    "Tage mit Anstieg: 140\n",
    "Durchschnittlicher Anstieg pro Tag: 2.21\n",
    "Tage mit Abfall: 112\n",
    "Durchschnittlicher Abfall pro Tag: 1.79\n",
    "\n",
    "Werte für das Jahr: 2010\n",
    "Tage mit Anstieg: 133\n",
    "Durchschnittlicher Anstieg pro Tag: 1.67\n",
    "Tage mit Abfall: 119\n",
    "Durchschnittlicher Abfall pro Tag: 1.57\n",
    "\n",
    "Werte für das Jahr: 2011\n",
    "Tage mit Anstieg: 130\n",
    "Durchschnittlicher Anstieg pro Tag: 1.65\n",
    "Tage mit Abfall: 122\n",
    "Durchschnittlicher Abfall pro Tag: 1.74\n",
    "\n",
    "Werte für das Jahr: 2012\n",
    "Tage mit Anstieg: 123\n",
    "Durchschnittlicher Anstieg pro Tag: 1.46\n",
    "Tage mit Abfall: 127\n",
    "Durchschnittlicher Abfall pro Tag: 1.11\n",
    "\n",
    "Werte für das Jahr: 2013\n",
    "Tage mit Anstieg: 140\n",
    "Durchschnittlicher Anstieg pro Tag: 1.18\n",
    "Tage mit Abfall: 112\n",
    "Durchschnittlicher Abfall pro Tag: 1.02\n",
    "\n",
    "Werte für das Jahr: 2014\n",
    "Tage mit Anstieg: 131\n",
    "Durchschnittlicher Anstieg pro Tag: 1.31\n",
    "Tage mit Abfall: 121\n",
    "Durchschnittlicher Abfall pro Tag: 1.57\n",
    "\n",
    "Werte für das Jahr: 2015\n",
    "Tage mit Anstieg: 129\n",
    "Durchschnittlicher Anstieg pro Tag: 1.68\n",
    "Tage mit Abfall: 123\n",
    "Durchschnittlicher Abfall pro Tag: 1.06\n",
    "\n",
    "Werte für das Jahr: 2016\n",
    "Tage mit Anstieg: 132\n",
    "Durchschnittlicher Anstieg pro Tag: 1.24\n",
    "Tage mit Abfall: 120\n",
    "Durchschnittlicher Abfall pro Tag: 1.24\n",
    "\n",
    "Werte für das Jahr: 2017\n",
    "Tage mit Anstieg: 157\n",
    "Durchschnittlicher Anstieg pro Tag: 0.85\n",
    "Tage mit Abfall: 94\n",
    "Durchschnittlicher Abfall pro Tag: 0.94\n",
    "\n",
    "Werte für das Jahr: 2018\n",
    "Tage mit Anstieg: 137\n",
    "Durchschnittlicher Anstieg pro Tag: 1.73\n",
    "Tage mit Abfall: 114\n",
    "Durchschnittlicher Abfall pro Tag: 1.79\n",
    "\n",
    "Werte für das Jahr: 2019\n",
    "Tage mit Anstieg: 133\n",
    "Durchschnittlicher Anstieg pro Tag: 1.15\n",
    "Tage mit Abfall: 119\n",
    "Durchschnittlicher Abfall pro Tag: 1.1\n",
    "\n",
    "Werte für das Jahr: 2020\n",
    "Tage mit Anstieg: 131\n",
    "Durchschnittlicher Anstieg pro Tag: 2.12\n",
    "Tage mit Abfall: 122\n",
    "Durchschnittlicher Abfall pro Tag: 1.73\n",
    "\n",
    "Werte für das Jahr: 2021\n",
    "Tage mit Anstieg: 137\n",
    "Durchschnittlicher Anstieg pro Tag: 1.06\n",
    "Tage mit Abfall: 115\n",
    "Durchschnittlicher Abfall pro Tag: 1.21\n",
    "\n",
    "Werte für das Jahr: 2022\n",
    "Tage mit Anstieg: 63\n",
    "Durchschnittlicher Anstieg pro Tag: 2.37\n",
    "Tage mit Abfall: 66\n",
    "Durchschnittlicher Abfall pro Tag: 2.74\n",
    "#Charts of Tesla\n",
    "\n",
    "tesla_waggle_list = get_daily_diff_list(tesla_open)\n",
    "title_tesla = f'Tesla daily difference chart from {tesla_dates[0]} to {tesla_dates[len(tesla_dates)-1]}'\n",
    "show_timerange(tesla_dates[0], tesla_dates[len(tesla_dates)-1], tesla_dates, tesla_waggle_list, \"Date\", \"Value\", title_tesla, 1500)\n",
    "\n",
    "start_date = \"01-01-1995\"\n",
    "end_date = \"01-03-2022\"\n",
    "tick_distance = (int(end_date[6:10])-int(start_date[6:10]))*24\n",
    "\n",
    "title_tesla = f'Tesla daily difference chart from {start_date} to {end_date}'\n",
    "show_timerange(start_date, end_date, tesla_dates, tesla_waggle_list, \"Date\", \"Value\", title_tesla, tick_distance)\n",
    "\n",
    "#daily\n",
    "min_percentage_diff = 20\n",
    "print_waggle_values(tesla_waggle_list, tesla_dates, min_percentage_diff)\n",
    "\n",
    "print_average_diff_per_year(tesla_waggle_list, tesla_dates, start_date[6:10], end_date[6:10])\n",
    "\n",
    "\n",
    "Prozentuale Unterschiede mit mindestens 20 zum Vortag:\n",
    "Prozentualer Unterschied von 35.74 am 30-06-2010\n",
    "Prozentualer Unterschied von 21.95 am 09-05-2013\n",
    "Prozentualer Unterschied von 31.06 am 04-02-2020\n",
    "Prozentualer Unterschied von -21.09 am 16-03-2020\n",
    "\n",
    "Entwicklung von 1995 bis 2022\n",
    "\n",
    "Werte für das Jahr: 2010\n",
    "Tage mit Anstieg: 67\n",
    "Durchschnittlicher Anstieg pro Tag: 3.63\n",
    "Tage mit Abfall: 63\n",
    "Durchschnittlicher Abfall pro Tag: 3.05\n",
    "\n",
    "Werte für das Jahr: 2011\n",
    "Tage mit Anstieg: 134\n",
    "Durchschnittlicher Anstieg pro Tag: 2.15\n",
    "Tage mit Abfall: 118\n",
    "Durchschnittlicher Abfall pro Tag: 2.3\n",
    "\n",
    "Werte für das Jahr: 2012\n",
    "Tage mit Anstieg: 129\n",
    "Durchschnittlicher Anstieg pro Tag: 2.12\n",
    "Tage mit Abfall: 121\n",
    "Durchschnittlicher Abfall pro Tag: 2.06\n",
    "\n",
    "Werte für das Jahr: 2013\n",
    "Tage mit Anstieg: 144\n",
    "Durchschnittlicher Anstieg pro Tag: 3.34\n",
    "Tage mit Abfall: 108\n",
    "Durchschnittlicher Abfall pro Tag: 2.8\n",
    "\n",
    "Werte für das Jahr: 2014\n",
    "Tage mit Anstieg: 127\n",
    "Durchschnittlicher Anstieg pro Tag: 2.43\n",
    "Tage mit Abfall: 125\n",
    "Durchschnittlicher Abfall pro Tag: 2.06\n",
    "\n",
    "Werte für das Jahr: 2015\n",
    "Tage mit Anstieg: 131\n",
    "Durchschnittlicher Anstieg pro Tag: 1.98\n",
    "Tage mit Abfall: 121\n",
    "Durchschnittlicher Abfall pro Tag: 2.01\n",
    "\n",
    "Werte für das Jahr: 2016\n",
    "Tage mit Anstieg: 128\n",
    "Durchschnittlicher Anstieg pro Tag: 1.84\n",
    "Tage mit Abfall: 124\n",
    "Durchschnittlicher Abfall pro Tag: 1.91\n",
    "\n",
    "Werte für das Jahr: 2017\n",
    "Tage mit Anstieg: 128\n",
    "Durchschnittlicher Anstieg pro Tag: 1.89\n",
    "Tage mit Abfall: 123\n",
    "Durchschnittlicher Abfall pro Tag: 1.61\n",
    "\n",
    "Werte für das Jahr: 2018\n",
    "Tage mit Anstieg: 130\n",
    "Durchschnittlicher Anstieg pro Tag: 2.53\n",
    "Tage mit Abfall: 121\n",
    "Durchschnittlicher Abfall pro Tag: 2.53\n",
    "\n",
    "Werte für das Jahr: 2019\n",
    "Tage mit Anstieg: 138\n",
    "Durchschnittlicher Anstieg pro Tag: 2.1\n",
    "Tage mit Abfall: 114\n",
    "Durchschnittlicher Abfall pro Tag: 2.28\n",
    "\n",
    "Werte für das Jahr: 2020\n",
    "Tage mit Anstieg: 137\n",
    "Durchschnittlicher Anstieg pro Tag: 5.13\n",
    "Tage mit Abfall: 116\n",
    "Durchschnittlicher Abfall pro Tag: 3.77\n",
    "\n",
    "Werte für das Jahr: 2021\n",
    "Tage mit Anstieg: 137\n",
    "Durchschnittlicher Anstieg pro Tag: 2.66\n",
    "Tage mit Abfall: 115\n",
    "Durchschnittlicher Abfall pro Tag: 2.66\n",
    "\n",
    "Werte für das Jahr: 2022\n",
    "Tage mit Anstieg: 32\n",
    "Durchschnittlicher Anstieg pro Tag: 3.46\n",
    "Tage mit Abfall: 24\n",
    "Durchschnittlicher Abfall pro Tag: 4.67\n",
    "#Charts of Johnson & Johnson\n",
    "\n",
    "jnj_waggle_list = get_daily_diff_list(jnj_open)\n",
    "title_jnj = f'Johnson & Johnson daily difference chart from {jnj_dates[0]} to {jnj_dates[len(jnj_dates)-1]}'\n",
    "show_timerange(jnj_dates[0], jnj_dates[len(jnj_dates)-1], jnj_dates, jnj_waggle_list, \"Date\", \"Value\", title_jnj, 1500)\n",
    "\n",
    "start_date = \"01-01-1995\"\n",
    "end_date = \"01-07-2022\"\n",
    "tick_distance = (int(end_date[6:10])-int(start_date[6:10]))*24\n",
    "\n",
    "\n",
    "title_jnj = f'Johnson & Johnson daily difference chart from {start_date} to {end_date}'\n",
    "show_timerange(start_date, end_date, jnj_dates, jnj_waggle_list, \"Date\", \"Value\", title_jnj, tick_distance)\n",
    "\n",
    "#daily\n",
    "min_percentage_diff = 10\n",
    "print_waggle_values(jnj_waggle_list, jnj_dates, min_percentage_diff)\n",
    "\n",
    "print_average_diff_per_year(jnj_waggle_list, jnj_dates, start_date[6:10], end_date[6:10])\n",
    "\n",
    "\n",
    "Prozentuale Unterschiede mit mindestens 10 zum Vortag:\n",
    "Prozentualer Unterschied von -10.98 am 19-10-1987\n",
    "Prozentualer Unterschied von -10.96 am 22-10-1987\n",
    "Prozentualer Unterschied von 10.55 am 16-03-2000\n",
    "Prozentualer Unterschied von -10.15 am 24-03-2000\n",
    "Prozentualer Unterschied von -18.34 am 19-07-2002\n",
    "Prozentualer Unterschied von -11.56 am 10-10-2008\n",
    "Prozentualer Unterschied von 13.75 am 14-10-2008\n",
    "Prozentualer Unterschied von -11.1 am 17-12-2018\n",
    "\n",
    "Entwicklung von 1995 bis 2022\n",
    "\n",
    "Werte für das Jahr: 1995\n",
    "Tage mit Anstieg: 157\n",
    "Durchschnittlicher Anstieg pro Tag: 0.88\n",
    "Tage mit Abfall: 95\n",
    "Durchschnittlicher Abfall pro Tag: 0.97\n",
    "\n",
    "Werte für das Jahr: 1996\n",
    "Tage mit Anstieg: 147\n",
    "Durchschnittlicher Anstieg pro Tag: 1.05\n",
    "Tage mit Abfall: 107\n",
    "Durchschnittlicher Abfall pro Tag: 1.25\n",
    "\n",
    "Werte für das Jahr: 1997\n",
    "Tage mit Anstieg: 135\n",
    "Durchschnittlicher Anstieg pro Tag: 1.51\n",
    "Tage mit Abfall: 118\n",
    "Durchschnittlicher Abfall pro Tag: 1.48\n",
    "\n",
    "Werte für das Jahr: 1998\n",
    "Tage mit Anstieg: 138\n",
    "Durchschnittlicher Anstieg pro Tag: 1.44\n",
    "Tage mit Abfall: 114\n",
    "Durchschnittlicher Abfall pro Tag: 1.49\n",
    "\n",
    "Werte für das Jahr: 1999\n",
    "Tage mit Anstieg: 126\n",
    "Durchschnittlicher Anstieg pro Tag: 1.33\n",
    "Tage mit Abfall: 126\n",
    "Durchschnittlicher Abfall pro Tag: 1.22\n",
    "\n",
    "Werte für das Jahr: 2000\n",
    "Tage mit Anstieg: 138\n",
    "Durchschnittlicher Anstieg pro Tag: 1.45\n",
    "Tage mit Abfall: 114\n",
    "Durchschnittlicher Abfall pro Tag: 1.6\n",
    "\n",
    "Werte für das Jahr: 2001\n",
    "Tage mit Anstieg: 133\n",
    "Durchschnittlicher Anstieg pro Tag: 1.19\n",
    "Tage mit Abfall: 115\n",
    "Durchschnittlicher Abfall pro Tag: 1.24\n",
    "\n",
    "Werte für das Jahr: 2002\n",
    "Tage mit Anstieg: 125\n",
    "Durchschnittlicher Anstieg pro Tag: 1.41\n",
    "Tage mit Abfall: 127\n",
    "Durchschnittlicher Abfall pro Tag: 1.42\n",
    "\n",
    "Werte für das Jahr: 2003\n",
    "Tage mit Anstieg: 127\n",
    "Durchschnittlicher Anstieg pro Tag: 1.08\n",
    "Tage mit Abfall: 125\n",
    "Durchschnittlicher Abfall pro Tag: 1.11\n",
    "\n",
    "Werte für das Jahr: 2004\n",
    "Tage mit Anstieg: 136\n",
    "Durchschnittlicher Anstieg pro Tag: 0.78\n",
    "Tage mit Abfall: 116\n",
    "Durchschnittlicher Abfall pro Tag: 0.72\n",
    "\n",
    "Werte für das Jahr: 2005\n",
    "Tage mit Anstieg: 116\n",
    "Durchschnittlicher Anstieg pro Tag: 0.69\n",
    "Tage mit Abfall: 136\n",
    "Durchschnittlicher Abfall pro Tag: 0.62\n",
    "\n",
    "Werte für das Jahr: 2006\n",
    "Tage mit Anstieg: 135\n",
    "Durchschnittlicher Anstieg pro Tag: 0.54\n",
    "Tage mit Abfall: 116\n",
    "Durchschnittlicher Abfall pro Tag: 0.53\n",
    "\n",
    "Werte für das Jahr: 2007\n",
    "Tage mit Anstieg: 124\n",
    "Durchschnittlicher Anstieg pro Tag: 0.61\n",
    "Tage mit Abfall: 127\n",
    "Durchschnittlicher Abfall pro Tag: 0.58\n",
    "\n",
    "Werte für das Jahr: 2008\n",
    "Tage mit Anstieg: 129\n",
    "Durchschnittlicher Anstieg pro Tag: 1.11\n",
    "Tage mit Abfall: 124\n",
    "Durchschnittlicher Abfall pro Tag: 1.22\n",
    "\n",
    "Werte für das Jahr: 2009\n",
    "Tage mit Anstieg: 130\n",
    "Durchschnittlicher Anstieg pro Tag: 0.89\n",
    "Tage mit Abfall: 122\n",
    "Durchschnittlicher Abfall pro Tag: 0.86\n",
    "\n",
    "Werte für das Jahr: 2010\n",
    "Tage mit Anstieg: 124\n",
    "Durchschnittlicher Anstieg pro Tag: 0.65\n",
    "Tage mit Abfall: 128\n",
    "Durchschnittlicher Abfall pro Tag: 0.66\n",
    "\n",
    "Werte für das Jahr: 2011\n",
    "Tage mit Anstieg: 132\n",
    "Durchschnittlicher Anstieg pro Tag: 0.77\n",
    "Tage mit Abfall: 120\n",
    "Durchschnittlicher Abfall pro Tag: 0.79\n",
    "\n",
    "Werte für das Jahr: 2012\n",
    "Tage mit Anstieg: 123\n",
    "Durchschnittlicher Anstieg pro Tag: 0.51\n",
    "Tage mit Abfall: 127\n",
    "Durchschnittlicher Abfall pro Tag: 0.45\n",
    "\n",
    "Werte für das Jahr: 2013\n",
    "Tage mit Anstieg: 145\n",
    "Durchschnittlicher Anstieg pro Tag: 0.64\n",
    "Tage mit Abfall: 107\n",
    "Durchschnittlicher Abfall pro Tag: 0.6\n",
    "\n",
    "Werte für das Jahr: 2014\n",
    "Tage mit Anstieg: 139\n",
    "Durchschnittlicher Anstieg pro Tag: 0.64\n",
    "Tage mit Abfall: 113\n",
    "Durchschnittlicher Abfall pro Tag: 0.66\n",
    "\n",
    "Werte für das Jahr: 2015\n",
    "Tage mit Anstieg: 126\n",
    "Durchschnittlicher Anstieg pro Tag: 0.73\n",
    "Tage mit Abfall: 126\n",
    "Durchschnittlicher Abfall pro Tag: 0.73\n",
    "\n",
    "Werte für das Jahr: 2016\n",
    "Tage mit Anstieg: 127\n",
    "Durchschnittlicher Anstieg pro Tag: 0.64\n",
    "Tage mit Abfall: 125\n",
    "Durchschnittlicher Abfall pro Tag: 0.56\n",
    "\n",
    "Werte für das Jahr: 2017\n",
    "Tage mit Anstieg: 136\n",
    "Durchschnittlicher Anstieg pro Tag: 0.56\n",
    "Tage mit Abfall: 115\n",
    "Durchschnittlicher Abfall pro Tag: 0.48\n",
    "\n",
    "Werte für das Jahr: 2018\n",
    "Tage mit Anstieg: 140\n",
    "Durchschnittlicher Anstieg pro Tag: 0.79\n",
    "Tage mit Abfall: 111\n",
    "Durchschnittlicher Abfall pro Tag: 1.06\n",
    "\n",
    "Werte für das Jahr: 2019\n",
    "Tage mit Anstieg: 135\n",
    "Durchschnittlicher Anstieg pro Tag: 0.7\n",
    "Tage mit Abfall: 117\n",
    "Durchschnittlicher Abfall pro Tag: 0.69\n",
    "\n",
    "Werte für das Jahr: 2020\n",
    "Tage mit Anstieg: 136\n",
    "Durchschnittlicher Anstieg pro Tag: 1.14\n",
    "Tage mit Abfall: 117\n",
    "Durchschnittlicher Abfall pro Tag: 1.23\n",
    "\n",
    "Werte für das Jahr: 2021\n",
    "Tage mit Anstieg: 128\n",
    "Durchschnittlicher Anstieg pro Tag: 0.76\n",
    "Tage mit Abfall: 124\n",
    "Durchschnittlicher Abfall pro Tag: 0.7\n",
    "\n",
    "Werte für das Jahr: 2022\n",
    "Tage mit Anstieg: 71\n",
    "Durchschnittlicher Anstieg pro Tag: 0.79\n",
    "Tage mit Abfall: 58\n",
    "Durchschnittlicher Abfall pro Tag: 0.9\n",
    "start_year = \"2007\"\n",
    "end_year = \"2010\"\n",
    "ticks = (int(end_year)-int(start_year))*24\n",
    "\n",
    "time_list = decrease_list_from_to(start_year,end_year, jnj_dates, [])\n",
    "apple_list = decrease_list_from_to(start_year,end_year, apple_dates, apple_waggle_list)\n",
    "jnj_list = decrease_list_from_to(start_year,end_year, jnj_dates, jnj_waggle_list)\n",
    "amazon_list = decrease_list_from_to(start_year,end_year, amazon_dates, amazon_waggle_list)\n",
    "tesla_list = decrease_list_from_to(start_year,end_year, tesla_dates, tesla_waggle_list)\n",
    "\n",
    "\n",
    "title = f'Chart from {start_year} to {end_year}'\n",
    "overlapping_chart(time_list, apple_list, jnj_list, amazon_list, tesla_list, \"Time\",\"Value\", title, ticks)\n",
    "\n",
    "#Holt den höchsten Wert im Zeitraum\n",
    "#Im Anschluss wird der Zeitpunkt ermittelt, wann der Wert wieder erreicht wird\n",
    "get_highest_value_in_intervall(\"01-06-2007\", \"03-01-2009\", apple_dates, apple_open)\n",
    "Der höchste Wert zwischen dem 01-06-2007 und dem 03-01-2009 ist 7.163928985595703 am 28-12-2007.\n",
    "Der Wert wurde am 20-10-2009 mit 7.164286136627197 übertroffen.\n",
    "#Vervielfachung des Aktienwerts\n",
    "print()\n",
    "print(f'Apple Vervielfachung um Faktor 10:')\n",
    "get_how_far_ago(apple_dates, apple_open, 10)\n",
    "print()\n",
    "print(f'Apple Vervielfachung um Faktor 100:')\n",
    "get_how_far_ago(apple_dates, apple_open, 100)\n",
    "\n",
    "print()\n",
    "print(f'Tesla Vervielfachung um Faktor 10:')\n",
    "get_how_far_ago(tesla_dates, tesla_open, 10)\n",
    "print()\n",
    "print(f'Tesla Vervielfachung um Faktor 100:')\n",
    "get_how_far_ago(tesla_dates, tesla_open, 100)\n",
    "\n",
    "print()\n",
    "print(f'Johnson & Johnson Vervielfachung um Faktor 10:')\n",
    "get_how_far_ago(jnj_dates, jnj_open, 10)\n",
    "print()\n",
    "print(f'Johnson & Johnson Vervielfachung um Faktor 100:')\n",
    "get_how_far_ago(jnj_dates, jnj_open, 100)\n",
    "\n",
    "print()\n",
    "print(f'Amazon Vervielfachung um Faktor 10:')\n",
    "get_how_far_ago(amazon_dates, amazon_open, 10)\n",
    "print()\n",
    "print(f'Amazon Vervielfachung um Faktor 100:')\n",
    "get_how_far_ago(amazon_dates, amazon_open, 100)\n",
    "Apple Vervielfachung um Faktor 10:\n",
    "Um den Wert seiner Aktie um den Faktor 10 zu erhöhen, müsste man die Aktie am 01-07-2013 zum Wert 14.381786346435547 kaufen. Nun liegt der Wert am 11-07-2022 beim Wert 145.6699981689453\n",
    "\n",
    "Apple Vervielfachung um Faktor 100:\n",
    "Um den Wert seiner Aktie um den Faktor 100 zu erhöhen, müsste man die Aktie am 13-07-2005 zum Wert 1.3674999475479126 kaufen. Nun liegt der Wert am 11-07-2022 beim Wert 145.6699981689453\n",
    "\n",
    "Tesla Vervielfachung um Faktor 10:\n",
    "Um den Wert seiner Aktie um den Faktor 10 zu erhöhen, müsste man die Aktie am 02-04-2020 zum Wert 96.206001 kaufen. Nun liegt der Wert am 24-03-2022 beim Wert 1009.72998\n",
    "\n",
    "Tesla Vervielfachung um Faktor 100:\n",
    "Um den Wert seiner Aktie um den Faktor 100 zu erhöhen, müsste man die Aktie am 22-04-2013 zum Wert 9.72 kaufen. Nun liegt der Wert am 24-03-2022 beim Wert 1009.72998\n",
    "\n",
    "Johnson & Johnson Vervielfachung um Faktor 10:\n",
    "Um den Wert seiner Aktie um den Faktor 10 zu erhöhen, müsste man die Aktie am 14-09-1995 zum Wert 17.625 kaufen. Nun liegt der Wert am 11-07-2022 beim Wert 177.6999969482422\n",
    "\n",
    "Johnson & Johnson Vervielfachung um Faktor 100:\n",
    "Um den Wert seiner Aktie um den Faktor 100 zu erhöhen, müsste man die Aktie am 30-07-1984 zum Wert 1.7734379768371582 kaufen. Nun liegt der Wert am 11-07-2022 beim Wert 177.6999969482422\n",
    "\n",
    "Amazon Vervielfachung um Faktor 10:\n",
    "Um den Wert seiner Aktie um den Faktor 10 zu erhöhen, müsste man die Aktie am 16-11-2012 zum Wert 11.065500259399414 kaufen. Nun liegt der Wert am 11-07-2022 beim Wert 114.08000183105469\n",
    "\n",
    "Amazon Vervielfachung um Faktor 100:\n",
    "Um den Wert seiner Aktie um den Faktor 100 zu erhöhen, müsste man die Aktie am 12-03-2003 zum Wert 1.125499963760376 kaufen. Nun liegt der Wert am 11-07-2022 beim Wert 114.08000183105469\n",
    "#Entwicklung von.. bis\n",
    "start_date = \"01-06-2019\"\n",
    "end_date = \"01-06-2022\"\n",
    "\n",
    "print()\n",
    "print(f'Apple Entwicklung von {start_date} bis {end_date}:')\n",
    "procentual_diff_from_to(start_date, end_date, apple_dates, apple_open)\n",
    "\n",
    "print()\n",
    "print(f'Tesla Entwicklung von {start_date} bis {end_date}:')\n",
    "procentual_diff_from_to(start_date, end_date, tesla_dates, tesla_open)\n",
    "\n",
    "print()\n",
    "print(f'Amazon Entwicklung von {start_date} bis {end_date}:')\n",
    "procentual_diff_from_to(start_date, end_date, amazon_dates, amazon_open)\n",
    "\n",
    "print()\n",
    "print(f'Johnson & Johnson Entwicklung von {start_date} bis {end_date}:')\n",
    "procentual_diff_from_to(start_date, end_date, jnj_dates, jnj_open)\n",
    "Apple Entwicklung von 01-06-2019 bis 01-06-2022:\n",
    "Preis am 01-06-2019: 43.900001525878906\n",
    "Preis am 01-06-2022: 145.6699981689453\n",
    "Preisentwicklung von 332%.\n",
    "\n",
    "Tesla Entwicklung von 01-06-2019 bis 01-06-2022:\n",
    "Preis am 01-06-2019: 37.102001\n",
    "Preis am 01-06-2022: 1009.72998\n",
    "Preisentwicklung von 2721%.\n",
    "\n",
    "Amazon Entwicklung von 01-06-2019 bis 01-06-2022:\n",
    "Preis am 01-06-2019: 88.00050354003906\n",
    "Preis am 01-06-2022: 114.08000183105469\n",
    "Preisentwicklung von 130%.\n",
    "\n",
    "Johnson & Johnson Entwicklung von 01-06-2019 bis 01-06-2022:\n",
    "Preis am 01-06-2019: 131.5\n",
    "Preis am 01-06-2022: 177.6999969482422\n",
    "Preisentwicklung von 135%.\n",
    "Alwins Teil\n",
    "\n",
    "def max_diff(list):\n",
    "    returned_list = []\n",
    "    if(len(list)<2):\n",
    "        return list\n",
    "    for i in range(0, len(list)-1):\n",
    "        returned_list.append(list[i+1] - list[i])\n",
    "    return returned_list\n",
    "\n",
    "def diff_list_perc(list):\n",
    "    returned_list = []\n",
    "    if(len(list)<2):\n",
    "        return list\n",
    "    for i in range(0, len(list)-1):\n",
    "        returned_list.append(((list[i+1] - list[i])/list[i])*100)\n",
    "    return returned_list\n",
    "\n",
    "def get_chart(datelist, name, y_value):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    ax = plt.gca()\n",
    "    ticks = 150\n",
    "    if(ticks != 1):\n",
    "\n",
    "        tick_list = []\n",
    "        for i in range(len(datelist)-1):\n",
    "            if(i%ticks == 0):\n",
    "                tick_list.append(i)\n",
    "\n",
    "        ax.set_xticks(tick_list)\n",
    "        minor_ticks = np.arange(0, len(datelist), (ticks/5))\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "    ax.plot(datelist[:-1], y_value)\n",
    "    ax.tick_params(direction='out', length=10, width=2)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(30)\n",
    "    plt.xticks(fontsize= 15)\n",
    "    plt.yticks(fontsize= 15)\n",
    "    plt.title(name, fontsize = 25)\n",
    "    ax.set_ylabel(\"Value\", fontsize=22)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def get_sorted_diff_perc(list):\n",
    "    sorted_list = sorted(list)\n",
    "    return sorted_list\n",
    "        \n",
    "\n",
    "def max_diff_sorted(list):\n",
    "    returned_list = sorted(list)\n",
    "    return returned_list\n",
    "\n",
    "def get_date_max_diff_list(date, value, value2):\n",
    "    returned_index = []\n",
    "    returned_date = []\n",
    "    for i in range(0,5):\n",
    "        returned_index.append(value.index(value2[i]))\n",
    "    for i in range(len(value)-5, len(value)):\n",
    "        returned_index.append(value.index(value2[i]))\n",
    "    for i in range(0, len(returned_index)):\n",
    "        returned_date.append(date[returned_index[i]])\n",
    "    return returned_date\n",
    "\n",
    "def get_date_of_value(date, value, value2):\n",
    "    index = value.index(value2[-1])\n",
    "    return date[index]\n",
    "\n",
    "def get_chart_around_date(datelist, date, index1, index2, name, y_value):\n",
    "    index = datelist.index(date)\n",
    "    dates = []\n",
    "    values = []\n",
    "    index_start = index-index1\n",
    "    index_end = index+index2\n",
    "    ticks = 40\n",
    "\n",
    "    for i in range(index_start, index_end):\n",
    "        dates.append(datelist[i])\n",
    "    for i in range(index_start, index_end):\n",
    "        values.append(y_value[i])  \n",
    "    plt.figure(figsize=(20,8))\n",
    "    ax = plt.gca()\n",
    "    if(ticks != 1):\n",
    "\n",
    "        tick_list = []\n",
    "        for i in range(len(dates)-1):\n",
    "            if(i%ticks == 0):\n",
    "                tick_list.append(i)\n",
    "\n",
    "        ax.set_xticks(tick_list)\n",
    "        minor_ticks = np.arange(0, len(dates), (ticks/5))\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "\n",
    "    ax.plot(dates, values)\n",
    "    ax.tick_params(direction='out', length=10, width=2)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(30)\n",
    "    plt.xticks(fontsize= 15)\n",
    "    plt.yticks(fontsize= 15)\n",
    "    plt.title(name, fontsize = 25)\n",
    "    ax.set_ylabel(\"Value\", fontsize=22)\n",
    "    plt.show()\n",
    "    \n",
    "def get_value_date(datelist, valuelist, value):\n",
    "    index = valuelist.index(value)\n",
    "    date = datelist[index]\n",
    "    return date\n",
    "\n",
    "def overlapping_percentage_chart(date_list, list_one, list_two, list_three, desc_x, desc_y, title, ticks):\n",
    "    float_list_one = list(map(float, list_one))\n",
    "    float_list_two = list(map(float, list_two))\n",
    "    float_list_three = list(map(float, list_three))\n",
    "    plt.figure(figsize=(30,8))\n",
    "    \n",
    "    ax = plt.gca()  \n",
    "    if(ticks != 1):\n",
    "\n",
    "        tick_list = []\n",
    "        for i in range(len(date_list)-1):\n",
    "            if(i%ticks == 0):\n",
    "                tick_list.append(i)\n",
    "        \n",
    "        ax.set_xticks(tick_list)\n",
    "        minor_ticks = np.arange(0, len(date_list), (ticks/5))\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "        \n",
    "    plt.xticks(fontsize= 18)\n",
    "    plt.yticks(fontsize= 20)\n",
    "    \n",
    "    ax.set_xlabel(desc_x, fontsize=30)\n",
    "    ax.set_ylabel(desc_y, fontsize=30)\n",
    "    \n",
    "    if len(date_list[:-1]) == len(list_one):\n",
    "        plt.plot(date_list[:-1],list_one, color = \"red\", label = \"Nasdaq\") \n",
    "    if len(date_list) == len(list_two):\n",
    "        plt.plot(date_list,list_two, color = \"blue\", label = \"S&P500\")\n",
    "    if len(date_list[:-2]) == len(list_three):\n",
    "        plt.plot(date_list[:-2],list_three, color = \"green\", label = \"DowJones\")\n",
    "    ax.legend()\n",
    "    plt.title(title, fontsize = 35)\n",
    "    plt.show()\n",
    "\n",
    "def get_max_value_timeline(datelist, date, index1, index2, y_value):\n",
    "    index = datelist.index(date)\n",
    "    start_index = index-index1\n",
    "    end_index = index + index2\n",
    "    newlist = []\n",
    "    for i in range(start_index, end_index):\n",
    "        newlist.append(y_value[i])\n",
    "    max_value = max(newlist)\n",
    "    print(max_value)\n",
    "    \n",
    "def diff_between_values(datelist, date, index1, index2, y_value):\n",
    "    index = datelist.index(date)\n",
    "    start_index = index - index1\n",
    "    end_index = index + index2\n",
    "    result = []\n",
    "    newlist = []\n",
    "    for i in range(start_index, end_index):\n",
    "        newlist.append(y_value[i])\n",
    "    result.append(min(newlist))\n",
    "    result.append(max(newlist))\n",
    "    return result\n",
    "# S&P500 Data\n",
    "print(\"\\n\\nS&P500 Data     note: it's weekly\")\n",
    "filename_S500 = '../input/stock-prices-over-a-30-year-period/SP500.csv'\n",
    "print()\n",
    "s500_date, s500_value = [], []\n",
    "with open(filename_S500) as f:\n",
    "\tdf = csv.reader(f)\n",
    "\theader_row = next(df)\n",
    "\tprint(header_row)\n",
    "    \n",
    "\tfor row in df:\n",
    "\t\tdate = row[0]\n",
    "\t\ts500_date.append(date)\n",
    "        \n",
    "\t\tvalue = row[1]\n",
    "\t\ts500_value.append(value)\n",
    "\n",
    "print(s500_date[:5])\n",
    "print(s500_date[0])\n",
    "print(s500_date[-1])\n",
    "print()\n",
    "s500_value_float = list(map(float, s500_value))\n",
    "print('Minimaler Wert: ', min(s500_value_float))\n",
    "print(get_value_date(s500_date, s500_value_float, min(s500_value_float)))\n",
    "print('Maximaler Wert: ', max(s500_value_float))\n",
    "print(get_value_date(s500_date, s500_value_float, max(s500_value_float)))\n",
    "print()\n",
    "#Liste der Differenzen\n",
    "max_diff_list = max_diff(s500_value_float)\n",
    "#Sortierte Liste der Differenzen\n",
    "max_diff_sorted_list = max_diff_sorted(max_diff_list)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "ax = plt.gca()\n",
    "ticks = 150\n",
    "if(ticks != 1):\n",
    "\n",
    "    tick_list = []\n",
    "    for i in range(len(s500_date)-1):\n",
    "        if(i%ticks == 0):\n",
    "            tick_list.append(i)\n",
    "\n",
    "    ax.set_xticks(tick_list)\n",
    "    minor_ticks = np.arange(0, len(s500_date), (ticks/5))\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    \n",
    "print('Maximaler Anstieg: ', max_diff_sorted_list[-5:])\n",
    "\n",
    "print('Maximaler Abstieg: ', max_diff_sorted_list[0:5])\n",
    "print()\n",
    "ax.plot(s500_date, s500_value_float)\n",
    "ax.tick_params(direction='out', length=10, width=2)\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(30)\n",
    "plt.xticks(fontsize= 15)\n",
    "plt.yticks(fontsize= 15)\n",
    "plt.title(\"S&P500 Data from 1977-2017\", fontsize = 25)\n",
    "ax.set_ylabel(\"Value\", fontsize=22)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Liste für die 5 maximalen und minimalen Differenzen als Datum\n",
    "date_test = get_date_max_diff_list(s500_date, max_diff_list, max_diff_sorted_list)\n",
    "\n",
    "print(\"Daten der 10 maximalen Differenzen:\")\n",
    "print()\n",
    "for x in range(len(date_test)):\n",
    "    print(\"   \", date_test[x])\n",
    "    print()\n",
    "\n",
    "print(get_value_date(s500_date, max_diff_list, max_diff_sorted_list[-5]))\n",
    "max_diff_date = get_date_of_value(s500_date, max_diff_list, max_diff_sorted_list)\n",
    "print(\"Wert der maximalen positiven Differenz:\",max_diff_sorted_list[-1] , \" und das Datum:\", max_diff_date)\n",
    "print()\n",
    "\n",
    "S&P500 Data     note: it's weekly\n",
    "\n",
    "['Date', 'Value']\n",
    "['1977-09-02', '1977-09-09', '1977-09-16', '1977-09-23', '1977-09-30']\n",
    "1977-09-02\n",
    "2017-08-29\n",
    "\n",
    "Minimaler Wert:  87.45\n",
    "1978-03-03\n",
    "Maximaler Wert:  2476.83\n",
    "2017-08-04\n",
    "\n",
    "Maximaler Anstieg:  [79.26999999999998, 85.6099999999999, 91.98000000000002, 96.21000000000004, 99.24000000000001]\n",
    "Maximaler Abstieg:  [-200.01, -159.03999999999996, -126.74000000000001, -121.91000000000008, -120.64999999999986]\n",
    "\n",
    "\n",
    "Daten der 10 maximalen Differenzen:\n",
    "\n",
    "    2008-10-03\n",
    "\n",
    "    2000-04-07\n",
    "\n",
    "    2001-09-11\n",
    "\n",
    "    2015-12-31\n",
    "\n",
    "    2015-08-14\n",
    "\n",
    "    2016-11-04\n",
    "\n",
    "    2011-11-25\n",
    "\n",
    "    2008-10-24\n",
    "\n",
    "    2008-11-21\n",
    "\n",
    "    2000-05-26\n",
    "\n",
    "2016-11-04\n",
    "Wert der maximalen positiven Differenz: 99.24000000000001  und das Datum: 2000-05-26\n",
    "\n",
    "Betrachtung der Werte um 2000\n",
    "\n",
    "get_chart_around_date(s500_date, max_diff_date, 200, 200, \"S&P500 around 2000\", s500_value_float)\n",
    "\n",
    "date = \"2008-10-24\"\n",
    "get_chart_around_date(s500_date, date, 100, 100, \"S&P500 around 2008\", s500_value_float)\n",
    "\n",
    "list_perc_s500 = diff_list_perc(s500_value_float)\n",
    "sorted_list = get_sorted_diff_perc(list_perc_s500)\n",
    "for i in range(0, 5):\n",
    "    print(sorted_list[i])\n",
    "print()\n",
    "\n",
    "for i in range(len(list_perc_s500)-5, len(list_perc_s500)):\n",
    "    print(sorted_list[i])\n",
    "\n",
    "print()\n",
    "print(sorted_list[0])\n",
    "print(sorted_list[-1])\n",
    "print()\n",
    "\n",
    "get_date_max_diff_list(s500_date, list_perc_s500, sorted_list)\n",
    "-18.195464097595586\n",
    "-12.196674920410326\n",
    "-11.600490599886504\n",
    "-10.488343720117385\n",
    "-9.399391726491215\n",
    "\n",
    "7.780078691240433\n",
    "8.830043331728458\n",
    "10.490778653466704\n",
    "10.707073663262015\n",
    "12.025799032536284\n",
    "\n",
    "-18.195464097595586\n",
    "12.025799032536284\n",
    "\n",
    "['2008-10-03',\n",
    " '1987-10-16',\n",
    " '2001-09-11',\n",
    " '2000-04-07',\n",
    " '2008-09-26',\n",
    " '2001-09-21',\n",
    " '1982-08-13',\n",
    " '2008-10-24',\n",
    " '2009-03-06',\n",
    " '2008-11-21']\n",
    "get_chart(s500_date, \"S&P500 percentage comparison\", list_perc_s500)\n",
    "\n",
    "date = \"2008-10-24\"\n",
    "get_max_value_timeline(s500_date, date, 200, 200, s500_value_float)\n",
    "1561.8\n",
    "# Nasdaq Data\n",
    "print(\"\\n\\nNasdaq Data     note: it's weekly\")\n",
    "filename_Nasdaq = '../input/stock-prices-over-a-30-year-period/Nasdaq.csv'\n",
    "print()\n",
    "\n",
    "nasdaq_date, nasdaq_value = [], []\n",
    "with open(filename_Nasdaq) as f:\n",
    "\tdf = csv.reader(f)\n",
    "\theader_row = next(df)\n",
    "\tprint(header_row)\n",
    "    \n",
    "\tfor row in df:\n",
    "\t\tdate = row[0]\n",
    "\t\tnasdaq_date.append(date)\n",
    "        \n",
    "\t\tvalue = row[1]\n",
    "\t\tnasdaq_value.append(value)\n",
    "\n",
    "print(nasdaq_date[:5])\n",
    "print(nasdaq_date[0])\n",
    "print(nasdaq_date[-1])\n",
    "print()\n",
    "\n",
    "nasdaq_value_float = list(map(float, nasdaq_value))\n",
    "print('Minimaler Wert: ', min(nasdaq_value_float))\n",
    "print(get_value_date(nasdaq_date, nasdaq_value_float, min(nasdaq_value_float)))\n",
    "print('Maximaler Wert: ', max(nasdaq_value_float))\n",
    "print(get_value_date(nasdaq_date, nasdaq_value_float, max(nasdaq_value_float)))\n",
    "\n",
    "print()\n",
    "\n",
    "#Liste der Differenzen\n",
    "max_diff_list = max_diff(nasdaq_value_float)\n",
    "#Sortierte Liste der Differenzen\n",
    "max_diff_sorted_list = max_diff_sorted(max_diff_list)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "ax = plt.gca()\n",
    "ticks = 150\n",
    "if(ticks != 1):\n",
    "\n",
    "    tick_list = []\n",
    "    for i in range(len(nasdaq_date)-1):\n",
    "        if(i%ticks == 0):\n",
    "            tick_list.append(i)\n",
    "\n",
    "    ax.set_xticks(tick_list)\n",
    "    minor_ticks = np.arange(0, len(nasdaq_date), (ticks/5))\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "        \n",
    "print('Maximaler Anstieg: ', max_diff_sorted_list[-5:])\n",
    "\n",
    "print('Maximaler Abstieg: ', max_diff_sorted_list[0:5])\n",
    "print()\n",
    "\n",
    "ax.plot(nasdaq_date, nasdaq_value_float)\n",
    "ax.tick_params(direction='out', length=10, width=2)\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(30)\n",
    "plt.xticks(fontsize= 15)\n",
    "plt.yticks(fontsize= 15)\n",
    "plt.title(\"Nasdaq Data from 1977-2017\", fontsize = 25)\n",
    "ax.set_ylabel(\"Value\", fontsize=22)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Liste für die 5 maximalen und minimalen Differenzen als Datum\n",
    "date_test = get_date_max_diff_list(nasdaq_date, max_diff_list, max_diff_sorted_list)\n",
    "\n",
    "print(\"Daten der 10 maximalen Differenzen:\")\n",
    "print()\n",
    "for x in range(len(date_test)):\n",
    "    \n",
    "    print(\"   \", date_test[x])\n",
    "    print()\n",
    "\n",
    "max_diff_date = get_date_of_value(nasdaq_date, max_diff_list, max_diff_sorted_list)\n",
    "print(\"Wert der maximalen positiven Differenz:\",max_diff_sorted_list[-1], \" und das Datum:\", max_diff_date)\n",
    "\n",
    "Nasdaq Data     note: it's weekly\n",
    "\n",
    "['Date', 'Value']\n",
    "['1977-09-02', '1977-09-09', '1977-09-16', '1977-09-23', '1977-09-30']\n",
    "1977-09-02\n",
    "2017-08-29\n",
    "\n",
    "Minimaler Wert:  97.21\n",
    "1977-11-04\n",
    "Maximaler Wert:  6387.75\n",
    "2017-07-21\n",
    "\n",
    "Maximaler Anstieg:  [272.1399999999999, 322.59000000000015, 324.28999999999996, 357.07000000000016, 608.27]\n",
    "Maximaler Abstieg:  [-1125.1599999999999, -431.4499999999998, -422.59000000000015, -390.1999999999998, -363.77999999999975]\n",
    "\n",
    "\n",
    "Daten der 10 maximalen Differenzen:\n",
    "\n",
    "    2000-04-07\n",
    "\n",
    "    2000-07-21\n",
    "\n",
    "    2000-11-03\n",
    "\n",
    "    2000-03-24\n",
    "\n",
    "    2015-12-31\n",
    "\n",
    "    2000-12-01\n",
    "\n",
    "    2000-04-14\n",
    "\n",
    "    2000-02-25\n",
    "\n",
    "    2000-01-28\n",
    "\n",
    "    2000-05-26\n",
    "\n",
    "Wert der maximalen positiven Differenz: 608.27  und das Datum: 2000-05-26\n",
    "Betrachtung der Wrte um 2000\n",
    "\n",
    "get_chart_around_date(nasdaq_date, max_diff_date, 200, 200, \"Nasdaq around 2000\", nasdaq_value_float)\n",
    "\n",
    "date = \"2008-10-24\"\n",
    "get_chart_around_date(nasdaq_date, date, 100, 100, \"Nasdaq around 2008\", nasdaq_value_float)\n",
    "\n",
    "list_perc_nas = diff_list_perc(nasdaq_value_float)\n",
    "sorted_list = get_sorted_diff_perc(list_perc_nas)\n",
    "for i in range(0, 5):\n",
    "    print(sorted_list[i])\n",
    "print()\n",
    "\n",
    "for i in range(len(list_perc_nas)-5, len(list_perc_nas)):\n",
    "    print(sorted_list[i])\n",
    "\n",
    "print()\n",
    "print(sorted_list[0])\n",
    "print(sorted_list[-1])\n",
    "print()\n",
    "\n",
    "get_date_max_diff_list(nasdaq_date, list_perc_nas, sorted_list)\n",
    "-25.30468126258026\n",
    "-19.148412503076546\n",
    "-16.05431262792192\n",
    "-15.296371040212803\n",
    "-12.243378394822086\n",
    "\n",
    "10.638791204544585\n",
    "10.883810235626894\n",
    "10.92353812258461\n",
    "14.012764770164393\n",
    "18.9781317957886\n",
    "\n",
    "-25.30468126258026\n",
    "18.9781317957886\n",
    "\n",
    "['2000-04-07',\n",
    " '1987-10-16',\n",
    " '2001-09-11',\n",
    " '2008-10-03',\n",
    " '2000-11-03',\n",
    " '2009-03-06',\n",
    " '2008-10-24',\n",
    " '2008-11-21',\n",
    " '2001-04-06',\n",
    " '2000-05-26']\n",
    "get_chart(nasdaq_date, \"Nasdaq percentage comparison\", list_perc_nas)\n",
    "\n",
    "# DowJones Data\n",
    "print(\"\\n\\nDowJones Data     note: it's weekly\")\n",
    "filename_DowJones = '../input/stock-prices-over-a-30-year-period/DowJones.csv'\n",
    "print()\n",
    "\n",
    "dowJones_date, dowJones_value = [], []\n",
    "with open(filename_DowJones) as f:\n",
    "\tdf = csv.reader(f)\n",
    "\theader_row = next(df)\n",
    "\tprint(header_row)\n",
    "    \n",
    "\tfor row in df:\n",
    "\t\tdate = row[0]\n",
    "\t\tdowJones_date.append(date)\n",
    "        \n",
    "\t\tvalue = row[1]\n",
    "\t\tdowJones_value.append(value)\n",
    "\n",
    "print(dowJones_date[:5])\n",
    "print(dowJones_date[0])\n",
    "print(dowJones_date[-1])\n",
    "print()\n",
    "\n",
    "#Liste als floats\n",
    "dowJones_value_float = list(map(float, dowJones_value))\n",
    "print('Minimaler Wert: ', min(dowJones_value_float))\n",
    "print(get_value_date(dowJones_date, dowJones_value_float, min(dowJones_value_float)))\n",
    "\n",
    "print('Maximaler Wert: ', max(dowJones_value_float))\n",
    "print(get_value_date(dowJones_date, dowJones_value_float, max(dowJones_value_float)))\n",
    "\n",
    "print()\n",
    "#Liste der Differenzen\n",
    "max_diff_list = max_diff(dowJones_value_float)\n",
    "#Sortierte Liste der Differenzen\n",
    "max_diff_sorted_list = max_diff_sorted(max_diff_list)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "ax = plt.gca()\n",
    "ticks = 150\n",
    "if(ticks != 1):\n",
    "\n",
    "    tick_list = []\n",
    "    for i in range(len(dowJones_date)-1):\n",
    "        if(i%ticks == 0):\n",
    "            tick_list.append(i)\n",
    "\n",
    "    ax.set_xticks(tick_list)\n",
    "    minor_ticks = np.arange(0, len(dowJones_date), (ticks/5))\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "    \n",
    "print('Maximaler Anstieg: ', max_diff_sorted_list[-5:])\n",
    "\n",
    "print('Maximaler Abstieg: ', max_diff_sorted_list[0:5])\n",
    "print()\n",
    "\n",
    "#Diagramm\n",
    "ax.plot(dowJones_date, dowJones_value_float)\n",
    "ax.tick_params(direction='out', length=10, width=2)\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(30)\n",
    "plt.xticks(fontsize= 15)\n",
    "plt.yticks(fontsize= 15)\n",
    "plt.title(\"DowJones Data from 1977-2017\", fontsize = 25)\n",
    "ax.set_ylabel(\"Value\", fontsize=22)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Liste für die 5 maximalen und minimalen Differenzen als Datum\n",
    "date_test = get_date_max_diff_list(dowJones_date, max_diff_list, max_diff_sorted_list)\n",
    "\n",
    "print(\"Daten der 10 maximalen Differenzen:\")\n",
    "print()\n",
    "for x in range(len(date_test)):\n",
    "    \n",
    "    print(\"   \", date_test[x])\n",
    "    print()\n",
    "\n",
    "max_diff_date = get_date_of_value(dowJones_date, max_diff_list, max_diff_sorted_list)\n",
    "print(\"Wert der maximalen positiven Differenz:\",max_diff_sorted_list[-1] , \" und das Datum:\", max_diff_date)\n",
    "\n",
    "DowJones Data     note: it's weekly\n",
    "\n",
    "['Date', 'Value']\n",
    "['1977-09-02', '1977-09-09', '1977-09-16', '1977-09-23', '1977-09-30']\n",
    "1977-09-02\n",
    "2017-08-29\n",
    "\n",
    "Minimaler Wert:  747.31\n",
    "1978-03-03\n",
    "Maximaler Wert:  22092.81\n",
    "2017-08-04\n",
    "\n",
    "Maximaler Anstieg:  [666.4099999999999, 782.6200000000008, 787.6399999999994, 946.0599999999995, 959.380000000001]\n",
    "Maximaler Abstieg:  [-1874.1899999999987, -1369.7000000000007, -1078.579999999998, -1017.6500000000015, -821.210000000001]\n",
    "\n",
    "\n",
    "Daten der 10 maximalen Differenzen:\n",
    "\n",
    "    2008-10-03\n",
    "\n",
    "    2001-09-10\n",
    "\n",
    "    2015-12-31\n",
    "\n",
    "    2015-08-14\n",
    "\n",
    "    2001-03-09\n",
    "\n",
    "    2000-03-10\n",
    "\n",
    "    2008-11-21\n",
    "\n",
    "    2011-11-25\n",
    "\n",
    "    2008-10-24\n",
    "\n",
    "    2016-11-04\n",
    "\n",
    "Wert der maximalen positiven Differenz: 959.380000000001  und das Datum: 2016-11-04\n",
    "DowJones um 2000 herum\n",
    "\n",
    "date = \"2000-05-26\"\n",
    "get_chart_around_date(dowJones_date, date, 200, 200, \"DowJones around 2000\", dowJones_value_float)\n",
    "\n",
    "date = \"1987-10-16\"\n",
    "get_chart_around_date(dowJones_date, date, 200, 200, \"DowJones around 1987\", dowJones_value_float)\n",
    "\n",
    "get_chart_around_date(dowJones_date, max_diff_date, 200, 30, \"DowJones around 2016\", dowJones_value_float)\n",
    "\n",
    "date = \"2008-10-24\"\n",
    "get_chart_around_date(dowJones_date, date, 100, 100, \"DowJones around 2008\", dowJones_value_float)\n",
    "\n",
    "list_perc_dj = diff_list_perc(dowJones_value_float)\n",
    "sorted_list = get_sorted_diff_perc(list_perc_dj)\n",
    "for i in range(0, 5):\n",
    "    print(sorted_list[i])\n",
    "print()\n",
    "\n",
    "for i in range(len(list_perc_dj)-5, len(list_perc_dj)):\n",
    "    print(sorted_list[i])\n",
    "\n",
    "print()\n",
    "print(sorted_list[0])\n",
    "print(sorted_list[-1])\n",
    "print()\n",
    "\n",
    "get_date_max_diff_list(dowJones_date, list_perc_dj, sorted_list)\n",
    "-18.151293221169574\n",
    "-14.259523960726714\n",
    "-13.17336751634598\n",
    "-9.486707409929055\n",
    "-7.763720956948784\n",
    "\n",
    "8.7150505651398\n",
    "9.009286337283875\n",
    "9.7263130684205\n",
    "10.308990546285136\n",
    "11.290913539285942\n",
    "\n",
    "-18.151293221169574\n",
    "11.290913539285942\n",
    "\n",
    "['2008-10-03',\n",
    " '2001-09-10',\n",
    " '1987-10-16',\n",
    " '1987-10-09',\n",
    " '1989-10-06',\n",
    " '1982-10-01',\n",
    " '2009-03-06',\n",
    " '2008-11-21',\n",
    " '1982-08-13',\n",
    " '2008-10-24']\n",
    "get_chart(dowJones_date, \"DowJones percentage comparison\", list_perc_dj)\n",
    "\n",
    "overlapping_percentage_chart(nasdaq_date, list_perc_nas, list_perc_s500, list_perc_dj, \"Time\", \"Value\", \"Overlapping percentage chart\", 200)\n",
    "\n",
    "date = \"2008-10-24\"\n",
    "list_s500 = diff_between_values(s500_date, date, 200, 200, s500_value_float)\n",
    "print(list_s500[0], list_s500[1])\n",
    "date1 = get_value_date(s500_date, s500_value_float, list_s500[0])\n",
    "print(date1)\n",
    "date2 = get_value_date(s500_date, s500_value_float, list_s500[1])\n",
    "print(date2)\n",
    "print(((list_s500[0]-list_s500[1])/list_s500[1])*100)\n",
    "683.38 1561.8\n",
    "2009-03-06\n",
    "2007-10-12\n",
    "-56.2440773466513\n",
    "date = \"2000-05-26\"\n",
    "list_s500 = diff_between_values(s500_date, date, 200, 200, s500_value_float)\n",
    "print(list_s500[0], list_s500[1])\n",
    "date1 = get_value_date(s500_date, s500_value_float, list_s500[0])\n",
    "print(date1)\n",
    "date2 = get_value_date(s500_date, s500_value_float, list_s500[1])\n",
    "print(date2)\n",
    "print(((list_s500[1]-list_s500[0])/list_s500[0])*100)\n",
    "635.9 1527.46\n",
    "1996-07-26\n",
    "2000-03-24\n",
    "140.20443465953767\n",
    "date = \"2008-10-24\"\n",
    "list_nasdaq = diff_between_values(nasdaq_date, date, 200, 200, nasdaq_value_float)\n",
    "print(list_nasdaq[0], list_nasdaq[1])\n",
    "date1 = get_value_date(nasdaq_date, nasdaq_value_float, list_nasdaq[0])\n",
    "print(date1)\n",
    "date2 = get_value_date(nasdaq_date, nasdaq_value_float, list_nasdaq[1])\n",
    "print(date2)\n",
    "print(((list_nasdaq[0]-list_nasdaq[1])/list_nasdaq[1])*100)\n",
    "1293.85 3183.95\n",
    "2009-03-06\n",
    "2012-09-14\n",
    "-59.363369399645094\n",
    "date = \"2000-05-26\"\n",
    "list_nasdaq = diff_between_values(nasdaq_date, date, 0, 200, nasdaq_value_float)\n",
    "print(list_nasdaq[0], list_nasdaq[1])\n",
    "date1 = get_value_date(nasdaq_date, nasdaq_value_float, list_nasdaq[0])\n",
    "print(date1)\n",
    "date2 = get_value_date(nasdaq_date, nasdaq_value_float, list_nasdaq[1])\n",
    "print(date2)\n",
    "print(((list_nasdaq[0]-list_nasdaq[1])/list_nasdaq[1])*100)\n",
    "1139.9 4246.18\n",
    "2002-10-04\n",
    "2000-07-14\n",
    "-73.15469433702764\n",
    "date = \"2008-10-24\"\n",
    "list_dowJones = diff_between_values(dowJones_date, date, 200, 200, dowJones_value_float)\n",
    "print(list_dowJones[0], list_dowJones[1])\n",
    "date1 = get_value_date(dowJones_date, dowJones_value_float, list_dowJones[0])\n",
    "print(date1)\n",
    "date2 = get_value_date(dowJones_date, dowJones_value_float, list_dowJones[1])\n",
    "print(date2)\n",
    "print(((list_dowJones[0]-list_dowJones[1])/list_dowJones[1])*100)\n",
    "6626.94 14093.08\n",
    "2009-03-06\n",
    "2007-10-12\n",
    "-52.97734774797277\n",
    "date = \"2000-05-26\"\n",
    "list_dowJones = diff_between_values(dowJones_date, date, 200, 200, dowJones_value_float)\n",
    "print(list_dowJones[0], list_dowJones[1])\n",
    "date1 = get_value_date(dowJones_date, dowJones_value_float, list_dowJones[0])\n",
    "print(date1)\n",
    "date2 = get_value_date(dowJones_date, dowJones_value_float, list_dowJones[1])\n",
    "print(date2)\n",
    "print(((list_dowJones[1]-list_dowJones[0])/list_dowJones[0])*100)\n",
    "5473.06 11722.98\n",
    "1996-07-26\n",
    "2000-01-14\n",
    "114.19425330619433\n",
    "# MACROECONOMIC DATA\n",
    "\n",
    "filename = '../input/interest-rates/index.csv'\n",
    "\n",
    "#importing data & creating lists\n",
    "with open(filename) as f:\n",
    "    reader = csv.reader(f)\n",
    "    header_row = next(reader)\n",
    "    dates, years, fed_target_rates, effective_fed_rates, real_gdps, unemployment_rates, inflation_rates, weird_dates = [], [], [], [], [], [], [], []\n",
    "#\tprint(header_row)\n",
    "\n",
    "    for row in reader:\n",
    "        if row[2] == '01':\n",
    "            #simplify data to one data point per month (0.1) (AND CLEAN JUNK ENTRIES)\n",
    "\n",
    "            # when exactly?\n",
    "            date = f\"{row[0]}-{row[1]}\"\n",
    "            dates.append(date)\n",
    "            year = row[0]\n",
    "            years.append(year)\n",
    "            #month = row[1]\n",
    "            #months.append(month)\n",
    "\n",
    "            # interest rates\n",
    "            fed_target_rate = row[3]\n",
    "            effective_fed_rate = row[6]\n",
    "            fed_target_rates.append(fed_target_rate)\n",
    "            effective_fed_rates.append(effective_fed_rate) \n",
    "            \n",
    "            # real_gdp\n",
    "            real_gdp = row[7]\n",
    "            real_gdps.append(real_gdp)        \n",
    "\n",
    "            # unemployment\n",
    "            unemployment_rate = row[8]\n",
    "            unemployment_rates.append(unemployment_rate)        \n",
    "\n",
    "            # inflation NOTE: it lacks entries in the beginning\n",
    "            inflation_rate = row[9]\n",
    "            inflation_rates.append(inflation_rate)\t\n",
    "#Helping methods\n",
    "\n",
    "def clean_up_data(data_set):\n",
    "    \"\"\"Remove empty entries and replace them with those from the previous year.\"\"\"\n",
    "    clean_data = []\n",
    "    for i in range(len(data_set)):\n",
    "        if data_set[i] != '':\n",
    "            last_data_point = data_set[i]\n",
    "            clean_data.append(float(data_set[i]))\n",
    "        else:\n",
    "            clean_data.append(float(last_data_point))\n",
    "    return clean_data\n",
    "\n",
    "def average_per_timeframe(data_set, timeframe):\n",
    "    \"\"\"\n",
    "    Calculate the average of the amount of pace someone enters.\n",
    "    In a dataset with 1 month intervals, enter 12 in timeframe to get the yearly average.\n",
    "    \"\"\"\n",
    "    name_of_new_list = []\n",
    "    for i in range(len(data_set)):\n",
    "        if i>(timeframe-2): #-2, weil 12 monat noch inklusive + 0-index\n",
    "            cum_data = 0\n",
    "            for n in range(timeframe):\n",
    "                cum_data += data_set[i-n]\n",
    "                \n",
    "            average_data = cum_data / timeframe\n",
    "            name_of_new_list.append(round(average_data, 2))       \n",
    "    return name_of_new_list\n",
    "\n",
    "def hochpunkt(data_set):\n",
    "    max_value = data_set[0]\n",
    "    #print(max_value)\n",
    "    for value in data_set:\n",
    "        #print(value)\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "            #print(\"DER WURDE ERKANNT\")\n",
    "    return max_value\n",
    "\n",
    "def tiefpunkt(data_set):\n",
    "    min_value = data_set[0]\n",
    "    for i in range(len(data_set)):\n",
    "        if data_set[i] < min_value:\n",
    "            min_value = data_set[i]\n",
    "    return min_value\n",
    "\n",
    "def tiefpunkt_timeframe(data_set, start_year, end_year):\n",
    "    start_index = what_time_is_it(start_year)[0]\n",
    "    end_index = what_time_is_it(end_year)[11]\n",
    "    \n",
    "    min_value = data_set[start_index]\n",
    "    for value in data_set[start_index:end_index]:\n",
    "        if value < min_value:\n",
    "            min_value = value\n",
    "    return min_value\n",
    "\n",
    "def hochpunkt_timeframe(data_set, start_year, end_year):\n",
    "    start_index = what_time_is_it(start_year)[0]\n",
    "    end_index = what_time_is_it(end_year)[11]\n",
    "    \n",
    "    max_value = data_set[start_index]\n",
    "    for value in data_set[start_index:end_index]:\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "    return max_value\n",
    "\n",
    "def average_value(data_set):\n",
    "    cumulated_values, counter = 0, 0\n",
    "    for value in data_set:\n",
    "        if value != '':\n",
    "            cumulated_values += value\n",
    "            counter += 1\n",
    "    average_value = round((cumulated_values / counter), 2)\n",
    "    return average_value\n",
    "\n",
    "#Analysis of Specific Timeperiods\n",
    "\n",
    "def what_time_is_it(year):\n",
    "    \"\"\"input the year, output the index i\"\"\"\n",
    "    i = -1\n",
    "    index = []\n",
    "    for yr in years:\n",
    "        i += 1\n",
    "        if int(yr) == year:\n",
    "            index.append(i)\n",
    "    return index\n",
    "\n",
    "def convert_index_to_date(index):\n",
    "    date = dates[index]\n",
    "    return date\n",
    "\n",
    "def convert_value_from_data_set_to_date(data_set, value):\n",
    "    index_of_value = data_set.index(value)\n",
    "    date_of_value = convert_index_to_date(index_of_value)\n",
    "    return date_of_value\n",
    "\n",
    "\n",
    "#####notfinished\n",
    "#def get_index_from_data_dataset(date_data_set, year):\n",
    "#    for date in date_data_set:\n",
    "#        if year in date:\n",
    "\n",
    "\n",
    "def difference_in_timeframe(data_set, start_year, end_year):\n",
    "    \"\"\"asdasdasd\"\"\"\n",
    "    start_index = what_time_is_it(start_year)[0]\n",
    "    end_index = what_time_is_it(end_year)[11]\n",
    "    difference = float(data_set[end_index]) - float(data_set[start_index])\n",
    "    return round(difference, 2)\n",
    "\n",
    "def average_in_timeframe(data_set, start_year, end_year):\n",
    "    \"\"\"input a dataset, the start-year and end-year. Output the average value during that period.\"\"\"\n",
    "    start_index = what_time_is_it(start_year)[0]\n",
    "    end_index = what_time_is_it(end_year)[11]\n",
    "    values_cum, counter = 0,0\n",
    "    for value in data_set[start_index:end_index]:\n",
    "        values_cum += value\n",
    "        counter += 1\n",
    "    average_value = values_cum / counter\n",
    "    return average_value\n",
    "\n",
    "def max_change_in_timeframe(data_set, start_year, end_year):\n",
    "    \"\"\"Input a dataset, a start- and endpoint. Output the biggest drawdown during that period.\"\"\"\n",
    "    start_index = what_time_is_it(start_year)[0]\n",
    "    end_index = what_time_is_it(end_year)[11]\n",
    "    \n",
    "    max_value = data_set[start_index]\n",
    "    min_value = data_set[start_index]\n",
    "\n",
    "    for value in data_set[start_index:end_index]:\n",
    "        if value > max_value:\n",
    "            max_value = value\n",
    "        if value < min_value:\n",
    "            min_value = value\n",
    "\n",
    "    #Was the max_value before or after the min value - appreciation or loss?\n",
    "    index_max = data_set.index(max_value)\n",
    "    index_min = data_set.index(min_value)\n",
    "    \n",
    "    if index_max < index_min:\n",
    "        max_drawdown = max_value - min_value\n",
    "        type = \"drawdown\"\n",
    "        return max_drawdown, type\n",
    "        \n",
    "    elif index_max > index_min:\n",
    "        max_appreciation = max_value - min_value\n",
    "        type = \"appreciation\"\n",
    "        return max_appreciation, type\n",
    "\n",
    "    return max_value, min_value\n",
    "\n",
    "def daten_ableiten(data_set):\n",
    "    abgeleitete_daten = []\n",
    "    last_value = data_set[0]\n",
    "    for value in data_set:\n",
    "        steigung = value - last_value\n",
    "        last_value = value\n",
    "        abgeleitete_daten.append(steigung)\n",
    "    return abgeleitete_daten\n",
    "\n",
    "def time_to_break_even(monthly_data_set, data_set, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Enter a start and an end of a time period.\n",
    "    Calculate what the peak of that time period was.\n",
    "    Calculate when the level was reached/surpassed again.\n",
    "    Get the index of those two points, calculate the difference and convert that to months.\n",
    "    \"\"\"\n",
    "    start_index = what_time_is_it(start_year)[0]\n",
    "    end_index = what_time_is_it(end_year)[11]\n",
    "    \n",
    "    peak_value = hochpunkt(data_set[start_index:end_index])\n",
    "    peak_index = data_set[start_index:end_index].index(peak_value) + start_index\n",
    "    print(f\"peak index: {peak_index}\")\n",
    "    print(f\"peak value: {peak_value}\")\n",
    "    print(f\"value of peak index: {data_set[peak_index]}\")\n",
    "    \n",
    "    month_until_break_even = 0\n",
    "    for value in data_set[peak_index:]:\n",
    "        month_until_break_even += 1\n",
    "        if value > peak_value:\n",
    "            break\n",
    "    return month_until_break_even\n",
    "    \n",
    "def plot_a_graph_multiple(x_values, y_values_1, y_values_2, title, y_label, set_n,x_label=''):\n",
    "    \"\"\"Enter the y-data and time-data and output a correctly formatted plot.\n",
    "    optionally, enter a start- and endyear in which the graph should be shown.\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x_values, y_values_1, c='blue', alpha=0.5)\n",
    "    ax.plot(x_values, y_values_2, c='red', alpha=0.5)\n",
    "    \n",
    "    #Format plot\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(x_label ,fontsize=16)\n",
    "    fig.autofmt_xdate()\n",
    "    ax.set_ylabel(y_label, fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)    \n",
    "    \n",
    "    every_nth = set_n\n",
    "    for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "        if n % every_nth != 0:\n",
    "            label.set_visible(False)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_a_graph_multiple_timeframe(x_values, y_values_1, y_values_2, start_year, end_year, title, y_label, set_n, x_label=''):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    index_start = what_time_is_it(start_year)[0]\n",
    "    index_end = what_time_is_it(end_year)[11]\n",
    "    ax.plot(x_values[index_start:index_end], y_values_1[index_start:index_end], c='blue', alpha=0.5)\n",
    "    ax.plot(x_values[index_start:index_end], y_values_2[index_start:index_end], c='blue', alpha=0.5)\n",
    "\n",
    "    #Format plot\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(x_label ,fontsize=16)\n",
    "    fig.autofmt_xdate()\n",
    "    ax.set_ylabel(y_label, fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    every_nth = set_n\n",
    "    for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "        if n % every_nth != 0:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def plot_a_graph_3_timeframe(x_values, y_values_1, y_values_2, y_values_3, start_year, end_year, title, y_label, set_n, x_label=''):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    index_start = what_time_is_it(start_year)[0]\n",
    "    index_end = what_time_is_it(end_year)[11]\n",
    "    ax.plot(x_values[index_start:index_end], y_values_1[index_start:index_end], c='blue', alpha=0.5)\n",
    "    ax.plot(x_values[index_start:index_end], y_values_2[index_start:index_end], c='red', alpha=0.5)\n",
    "    ax.plot(x_values[index_start:index_end], y_values_3[index_start:index_end], c='green', alpha=0.5)\n",
    "    \n",
    "    #Format plot\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(x_label ,fontsize=16)\n",
    "    fig.autofmt_xdate()\n",
    "    ax.set_ylabel(y_label, fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "    every_nth = set_n\n",
    "    for n, label in enumerate(ax.xaxis.get_ticklabels()):\n",
    "        if n % every_nth != 0:\n",
    "            label.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "def plot_a_graph_timeframe(x_values, y_values, start_year, end_year, title, y_label, ticks, referenzlinie = 0.1, x_label=''):\n",
    "    \"\"\"Enter the y-data and time-data and output a correctly formatted plot.\n",
    "    optionally, enter a start- and endyear in which the graph should be shown.\"\"\"\n",
    "    index_start = what_time_is_it(start_year)[0]\n",
    "    index_end = what_time_is_it(end_year)[11]\n",
    "    \n",
    "    plt.figure(figsize=(20,8))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(x_values[index_start:index_end], y_values[index_start:index_end], c='blue', alpha=0.5, linewidth=3.0)\n",
    "    #Format plot\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel(x_label ,fontsize=10)\n",
    "    ax.set_ylabel(y_label, fontsize=10)\n",
    "    ax = plt.gca()\n",
    "    if(ticks != 1):\n",
    "        tick_list = []\n",
    "        for i in range(len(x_values[index_start:index_end])-1):\n",
    "            if(i%ticks == 0):\n",
    "                tick_list.append(i)\n",
    "\n",
    "        ax.set_xticks(tick_list, rotation = 45)\n",
    "        ax.tick_params(direction='out', length=10, width=2)\n",
    "        minor_ticks = np.arange(0, len(x_values[index_start:index_end]), (ticks/5))\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(30)\n",
    "    plt.xticks(fontsize= 14)\n",
    "    plt.yticks(fontsize= 16)\n",
    "    plt.title(title, fontsize = 25)\n",
    "    ax.set_xlabel(x_label, fontsize=22)\n",
    "    ax.set_ylabel(y_label, fontsize=22)\n",
    "    if referenzlinie != 0.1:\n",
    "        plt.axhline(y=referenzlinie, xmin=0, xmax=10000, linewidth=1.0)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_a_graph(x_values, y_values, title, y_label, ticks, referenzlinie=0.1, x_label=''):\n",
    "    \"\"\"Enter the y-data and time-data and output a correctly formatted plot.\n",
    "    optionally, enter a start- and endyear in which the graph should be shown.\"\"\"\n",
    "    plt.figure(figsize=(20,8))\n",
    "    ax = plt.gca()\n",
    "    ax.plot(x_values, y_values, c='blue', alpha=0.5, linewidth=3.0)\n",
    "    #Format plot\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.set_xlabel(x_label ,fontsize=10)\n",
    "    ax.set_ylabel(y_label, fontsize=10)\n",
    "    ax = plt.gca()\n",
    "    if(ticks != 1):\n",
    "        tick_list = []\n",
    "        for i in range(len(x_values)-1):\n",
    "            if(i%ticks == 0):\n",
    "                tick_list.append(i)\n",
    "\n",
    "        ax.set_xticks(tick_list, rotation = 45)\n",
    "        ax.tick_params(direction='out', length=10, width=2)\n",
    "        minor_ticks = np.arange(0, len(x_values), (ticks/5))\n",
    "        ax.set_xticks(minor_ticks, minor=True)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(30)\n",
    "    plt.xticks(fontsize= 14)\n",
    "    plt.yticks(fontsize= 16)\n",
    "    plt.title(title, fontsize = 25)\n",
    "    ax.set_xlabel(x_label, fontsize=22)\n",
    "    ax.set_ylabel(y_label, fontsize=22)\n",
    "    if referenzlinie != 0.1:\n",
    "        plt.axhline(y=referenzlinie, xmin=0, xmax=10000, linewidth=1.0)\n",
    "    plt.show()\n",
    "# Real GDP\n",
    "\n",
    "#Data set is quarterly, every 3 month.  real_gdps[::3]\n",
    "\n",
    "real_gdps_clean = clean_up_data(real_gdps)\n",
    "#print(real_gdps_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Durchschnittlicher GDP\n",
    "average_gdp = average_value(real_gdps_clean)\n",
    "print(f\"Average GDP: {round(average_gdp, 2)}\")\n",
    "\n",
    "#hochpunkt gdp\n",
    "print(\"\\n\\n\")\n",
    "print(f\"Hochpunkt am {dates[285]}\")\n",
    "hochpunkt_real_gdps = hochpunkt(real_gdps[::3])\n",
    "print(hochpunkt_real_gdps)\n",
    "\n",
    "#tiefpunkt gdp\n",
    "print(f\"Tiefpunkt am {dates[42]}\")\n",
    "tiefpunkt_real_gdps = tiefpunkt(real_gdps_clean)\n",
    "print(tiefpunkt_real_gdps)\n",
    "\n",
    "\n",
    "# 3 Extremwerte im Graphen:\n",
    "tiefpunkt_1st_crash = tiefpunkt_timeframe(real_gdps_clean, 1955, 1964)\n",
    "date_first_crash = convert_index_to_date(real_gdps_clean.index(tiefpunkt_1st_crash))\n",
    "print(f\"\\n{date_first_crash}: GDP fällt auf {tiefpunkt_1st_crash}%.\")\n",
    "\n",
    "tiefpunkt_2nd_crash = tiefpunkt_timeframe(real_gdps_clean, 1975, 1990)\n",
    "date_second_crash = convert_index_to_date(real_gdps_clean.index(tiefpunkt_2nd_crash))\n",
    "print(f\"\\n{date_second_crash}: GDP fällt auf {tiefpunkt_2nd_crash}%.\")\n",
    "\n",
    "tiefpunkt_3rd_crash = tiefpunkt_timeframe(real_gdps_clean, 2007, 2011)\n",
    "date_third_crash = convert_index_to_date(real_gdps_clean.index(tiefpunkt_3rd_crash))\n",
    "print(f\"\\n{date_third_crash}: GDP fällt auf {tiefpunkt_3rd_crash}%.\")\n",
    "\n",
    "\n",
    "#Visualize the data\n",
    "plot_a_graph(dates, real_gdps_clean, \"Real GDP values from 1954 - 2017\", \"GDP\", 60, 2)\n",
    "\n",
    "\n",
    "\n",
    "#max_drawdown_1960 = change_in_timeframe = max_change_in_timeframe(real_gdps_clean, 1959, 1964)\n",
    "#date_first_crash = convert_index_to_date(real_gdps_clean.index(max_drawdown_1960[0]))\n",
    "#print(f\"{date_first_crash} ging der GDP um {max_drawdown_1960[0]} zurück.\")\n",
    "#max_drawdown_1984 = change_in_timeframe = max_change_in_timeframe(real_gdps_clean, 1982, 1989)\n",
    "#date_second_crash = convert_index_to_date(real_gdps_clean.index(max_drawdown_1984[0]))\n",
    "#print(f\"{date_first_crash} ging der GDP um {max_drawdown_1960[0]} zurück.\")\n",
    "Average GDP: 3.13\n",
    "\n",
    "\n",
    "\n",
    "Hochpunkt am 1978-04\n",
    "9.8\n",
    "Tiefpunkt am 1958-01\n",
    "-10.0\n",
    "\n",
    "1958-01: GDP fällt auf -10.0%.\n",
    "\n",
    "1980-04: GDP fällt auf -7.9%.\n",
    "\n",
    "2008-10: GDP fällt auf -8.2%.\n",
    "\n",
    "plot_a_graph_timeframe(dates, real_gdps_clean, 1984, 2004, \"Real GDP values from 1984 - 2004\", \"GDP\", 60, 2)\n",
    "\n",
    "real_gdp_two_year_average = average_per_timeframe(real_gdps_clean ,24)\n",
    "\n",
    "plot_a_graph(dates[23:], real_gdp_two_year_average, \"Average GDP values over 2 years\", \"GDP\", 60, 2)\n",
    "\n",
    "print(\"\\nMan kann sehen, wie die Finanzkrise 2008 sich auf das Wirtschaftswachstum ausgewirkt hat. Der maximale drawdown ist ähnlich wie bei\"\n",
    "      \"den Finanzkrisen zuvor, allerdings fällt der Zwei-Jahres-Durchschnitt tiefer. Die Ursache liegt darin, dass das Durchschnittliche Niveau\"\n",
    "     \"in dieser Zeitperiode niedriger ist als sonst. Dies wird deutlich am 10-year-average-gdp Chart.\")\n",
    "\n",
    "Man kann sehen, wie die Finanzkrise 2008 sich auf das Wirtschaftswachstum ausgewirkt hat. Der maximale drawdown ist ähnlich wie beiden Finanzkrisen zuvor, allerdings fällt der Zwei-Jahres-Durchschnitt tiefer. Die Ursache liegt darin, dass das Durchschnittliche Niveauin dieser Zeitperiode niedriger ist als sonst. Dies wird deutlich am 10-year-average-gdp Chart.\n",
    "real_gdp_one_year_average = average_per_timeframe(real_gdps_clean ,60)\n",
    "\n",
    "plot_a_graph(dates[59:], real_gdp_one_year_average, \"Average GDP values over 5 years\", \"GDP\", 60, 2)\n",
    "\n",
    "real_gdp_one_year_average = average_per_timeframe(real_gdps_clean ,120)\n",
    "\n",
    "plot_a_graph(dates[119:], real_gdp_one_year_average, \"Average GDP values over 10 years\", \"GDP\", 60)\n",
    "\n",
    "#Analysis of specific time periods:\n",
    "\n",
    "year_1 = what_time_is_it(2007)\n",
    "year_2 = what_time_is_it(2009)\n",
    "print(\"\\nindex of 2007:\")\n",
    "print(year_1)\n",
    "print(\"index of 2009:\")\n",
    "print(year_2)\n",
    "\n",
    "#gdp\n",
    "gdp_2007 = real_gdps_clean[630]\n",
    "print(\"\\nGDP 2007:\")\n",
    "print(gdp_2007)\n",
    "\n",
    "gdp_2009 = real_gdps_clean[665]\n",
    "print(\"GDP 2009:\")\n",
    "print(gdp_2009)\n",
    "\n",
    "print(\"GDP progression 2007 - 2009\")\n",
    "print(real_gdps_clean[630:665])\n",
    "\n",
    "difference_2007_2009 = difference_in_timeframe(real_gdps_clean, 2007, 2009)\n",
    "print(\"\\nDifference 2007 - 2009\")\n",
    "print(difference_2007_2009)\n",
    "\n",
    "average_2007_2009 = average_in_timeframe(real_gdps_clean, 2007, 2009)\n",
    "print(\"\\nAverage 2007 - 2009:\")\n",
    "print(average_2007_2009)\n",
    "\n",
    "change_in_timeframe = max_change_in_timeframe(real_gdps_clean, 2007, 2009)\n",
    "print(\"\\nBiggest Change during 2007 - 2009\")\n",
    "print(change_in_timeframe)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "months_until_gdp_breaks_even = time_to_break_even(dates, real_gdps_clean, 2007, 2008)\n",
    "print(f\"It took {months_until_gdp_breaks_even} month to get back to the gdp-levels pre-crisis\")\n",
    "print(convert_index_to_date(633))\n",
    "print(convert_index_to_date(664))\n",
    "\n",
    "#print(real_gdps_clean[630:665])\n",
    "#print(dates[630:665])\n",
    "\n",
    "#for i in range(36):\n",
    "#    print(real_gdps_clean[636+i])\n",
    "#    print(dates[636+i])\n",
    "#    print(\"\")\n",
    "\n",
    "\n",
    "plot_a_graph_timeframe(dates, real_gdps_clean, 1995, 2013, \"GDP from 1995 until 2003\", \"GDP\", 12, 2)\n",
    "index of 2007:\n",
    "[630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641]\n",
    "index of 2009:\n",
    "[654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665]\n",
    "\n",
    "GDP 2007:\n",
    "0.2\n",
    "GDP 2009:\n",
    "3.9\n",
    "GDP progression 2007 - 2009\n",
    "[0.2, 0.2, 0.2, 3.1, 3.1, 3.1, 2.7, 2.7, 2.7, 1.4, 1.4, 1.4, -2.7, -2.7, -2.7, 2.0, 2.0, 2.0, -1.9, -1.9, -1.9, -8.2, -8.2, -8.2, -5.4, -5.4, -5.4, -0.5, -0.5, -0.5, 1.3, 1.3, 1.3, 3.9, 3.9]\n",
    "\n",
    "Difference 2007 - 2009\n",
    "3.7\n",
    "\n",
    "Average 2007 - 2009:\n",
    "-0.46285714285714286\n",
    "\n",
    "Biggest Change during 2007 - 2009\n",
    "(12.1, 'drawdown')\n",
    "peak index: 633\n",
    "peak value: 3.1\n",
    "value of peak index: 3.1\n",
    "It took 31 month to get back to the gdp-levels pre-crisis\n",
    "2007-04\n",
    "2009-11\n",
    "\n",
    "#Abgeleitete Daten\n",
    "\n",
    "gdps_steigung = daten_ableiten(real_gdps_clean)\n",
    "\n",
    "plot_a_graph(dates, gdps_steigung, \"Increments of Real GDP\", \"Increments GDP\", 60)\n",
    "\n",
    "plot_a_graph_timeframe(dates, real_gdp_two_year_average, 1995, 2013, \"Average GDP values over 2 years, from 1995 - 2013\", \"Average GDP\", 12)\n",
    "\n",
    "plot_a_graph_timeframe(dates, real_gdps_clean, 1984, 2004, \"Average GDP values over 2 years, from 1995 - 2013\", \"Average GDP\", 12, 0)\n",
    "\n",
    "plot_a_graph_timeframe(dates, real_gdp_two_year_average, 1997, 2013, \"Average GDP values over 2 years, from 2000 - 2013\", \"Average GDP\", 12)\n",
    "\n",
    "# Arbeitslosigkeit    \n",
    "\n",
    "#print(unemployment_rates)\n",
    "\n",
    "#cleaning up the data, replace missing entries with data from year before\n",
    "unemployment_clean = clean_up_data(unemployment_rates)\n",
    "#print(unemployment_clean)\n",
    "\n",
    "#Arbeitslosigkeit 1Jahres Durchschnitt\n",
    "unemployment_1year_average = average_per_timeframe(unemployment_clean, 12)\n",
    "#print(unemployment_1year_average)\n",
    "#print(len(unemployment_1year_average[::12]))\n",
    "\n",
    "#Arbeitslosigkeit Tiefpunkt (wenig Arbeitslose)\n",
    "unemployment_low = tiefpunkt(unemployment_clean)\n",
    "print(f\"Unemployment_low = {unemployment_low}\")\n",
    "\n",
    "#Arbeitslosigkeit Hochpunkt (viele Arbeitslose)\n",
    "unemployment_high = hochpunkt(unemployment_clean)\n",
    "print(f\"Unemployment_high = {unemployment_high}\")\n",
    "\n",
    "#Arbeitslosigkeit Durchschnitt\n",
    "unemployment_average = average_value(unemployment_clean)\n",
    "print(f\"\\nDie durchschnittliche Arbeitslosigkeit = {round(unemployment_average, 2)}\")\n",
    "\n",
    "plot_a_graph(dates, unemployment_clean, \"Unemploymentrate from 1954 - 2017\", \"Unemploymentrate\", 60, unemployment_average)\n",
    "Unemployment_low = 3.4\n",
    "Unemployment_high = 10.8\n",
    "\n",
    "Die durchschnittliche Arbeitslosigkeit = 5.98\n",
    "\n",
    "plot_a_graph_timeframe(dates, unemployment_clean, 1995, 2013, \"Unemploymentrate from 1995 - 2013\", \"Unemploymentrate in %\", 24, unemployment_average)\n",
    "\n",
    "#calculate and show the employmentrate\n",
    "unemployment_inverse = [100-value for value in unemployment_clean]\n",
    "average_employment = 100-unemployment_average\n",
    "plot_a_graph_timeframe(dates, unemployment_inverse, 1995, 2013, \"Employmentrate from 1995 - 2013\", \"Employmentrate in %\", 24, average_employment)\n",
    "\n",
    "# Analyse Finanzcrash 2008\n",
    "\n",
    "print(\"\\nHochpunkt 2008 Krise:\")\n",
    "hochpunkt_2008_krise = hochpunkt(unemployment_clean[630-24:665+12+12+12])\n",
    "print(hochpunkt_2008_krise)\n",
    "print(\"\\nTiefpunkt 2008 Krise:\")\n",
    "tiefpunkt_2008_krise = tiefpunkt(unemployment_clean[630-24:665+12+12+12])\n",
    "print(tiefpunkt_2008_krise)\n",
    "\n",
    "unemployment_difference = hochpunkt_2008_krise - tiefpunkt_2008_krise\n",
    "print(f\"\\nDie Arbeitslosigkeit ist um {unemployment_difference} Prozent gestiegen.\")\n",
    "\n",
    "#plot_a_graph_timeframe(dates,unemployment_clean,2003, 2013, \"Arbeitslosigkeit während der Finanzkrise 2008\", \"Arbeitslosenquote\", 12)\n",
    "Hochpunkt 2008 Krise:\n",
    "10.0\n",
    "\n",
    "Tiefpunkt 2008 Krise:\n",
    "4.4\n",
    "\n",
    "Die Arbeitslosigkeit ist um 5.6 Prozent gestiegen.\n",
    "#Arbeitslosigkeit abgeleitet\n",
    "\n",
    "arbeitslosigkeit_steigung = daten_ableiten(unemployment_clean)\n",
    "#print(arbeitslosigkeit_steigung)\n",
    "\n",
    "#plot_a_graph(dates, arbeitslosigkeit_steigung, \"Steigung Arbeitslosenquote\", \"Arbeitslosenquote\", 60)\n",
    "#Abgeleitete Arbeitslosenquote während der Finanzkrise 2008\n",
    "\n",
    "plot_a_graph_timeframe(dates, arbeitslosigkeit_steigung, 1995, 2013, \"Incremental Unemploymentrate from 1995 - 2013\", \"Increase in Unemploymentrate\", 12)\n",
    "\n",
    "steigung_arbeitslosenquote_one_year_average = average_per_timeframe(arbeitslosigkeit_steigung, 12)\n",
    "\n",
    "plot_a_graph_timeframe(dates, steigung_arbeitslosenquote_one_year_average, 1995, 2013, \"2 year average increases in Unemploymentrate from 1995 - 2013\", \"Increase in Unemploymentrate\", 12, 0)\n",
    "print(\"\")\n",
    "\n",
    "        # Zinssätze\n",
    "        \n",
    "        \n",
    "interest_rates_clean = clean_up_data(effective_fed_rates)\n",
    "        \n",
    "#Hochpunkt  \n",
    "hochpunkt_zinssatz = hochpunkt(interest_rates_clean)\n",
    "hochpunkt_zinssatz_date = convert_value_from_data_set_to_date(interest_rates_clean, hochpunkt_zinssatz)\n",
    "print(f\"Hochpunkt Zinssatz: {hochpunkt_zinssatz}%, am {hochpunkt_zinssatz_date}\")\n",
    "\n",
    "#Tiefpunkt\n",
    "tiefpunkt_zinssatz = tiefpunkt(interest_rates_clean)\n",
    "tiefpunkt_zinssatz_date = convert_value_from_data_set_to_date(interest_rates_clean, tiefpunkt_zinssatz)\n",
    "print(f\"Tiefpunkt Zinssatz: {tiefpunkt_zinssatz}%, am {tiefpunkt_zinssatz_date}\")\n",
    "\n",
    "#Durchschnitt\n",
    "zinssatz_durchschnitt = average_value(interest_rates_clean)\n",
    "print(f\"Der durchschnittliche Zinssatz: {zinssatz_durchschnitt}%\")\n",
    "\n",
    "\n",
    "#Jahresdurchschnitte\n",
    "one_year_interest_rate_avrg = average_per_timeframe(interest_rates_clean, 12)\n",
    "three_year_interest_rate_avrg = average_per_timeframe(interest_rates_clean, 12*3)\n",
    "five_year_interest_rate_avrg = average_per_timeframe(interest_rates_clean, 12*5)\n",
    "Hochpunkt Zinssatz: 19.1%, am 1981-06\n",
    "Tiefpunkt Zinssatz: 0.07%, am 2011-07\n",
    "Der durchschnittliche Zinssatz: 4.91%\n",
    "plot_a_graph(dates, interest_rates_clean, \"Effective Fed interest rates from 1954 - 2017\", \"Interest rates\", 60, 1)\n",
    "\n",
    "plot_a_graph_timeframe(dates[12*5-1:], five_year_interest_rate_avrg, 1980, 2001, \"5 year average interest rates from 1984 - 2010\", \"Interest rates average\", 60)\n",
    "\n",
    "plot_a_graph(dates[59:], five_year_interest_rate_avrg, \"5-Jahres Durchschnitt Interest Rates\", \"avrg interest rates\", 60)\n",
    "\n",
    "#Zinssatz um 2008 (von 2003 bis 2013)\n",
    "\n",
    "index_2003 = what_time_is_it(2003)\n",
    "index_2013 = what_time_is_it(2013)\n",
    "\n",
    "\n",
    "\n",
    "index_2003 = what_time_is_it(2003)[0]\n",
    "index_2013 = what_time_is_it(2013)[11]\n",
    "\n",
    "hochpunkt_zinsen = hochpunkt(interest_rates_clean[index_2003:index_2013])\n",
    "zins_hochpunkt_index = interest_rates_clean.index(hochpunkt_zinsen)\n",
    "print(f\"Das Datum an dem der Zinssatz am höchsten war: {dates[zins_hochpunkt_index]}\")\n",
    "print()\n",
    "\n",
    "print(\"Konstanter Anstieg der Zinsen, nach Crash -> starkes Absenken des Zinssatzes.\")\n",
    "\n",
    "\n",
    "plot_a_graph_timeframe(dates, interest_rates_clean, 2002, 2013, \"Effective FED interest rates from 2002 - 2013\", \"Interest rates\", 12)\n",
    "Das Datum an dem der Zinssatz am höchsten war: 2007-02\n",
    "\n",
    "Konstanter Anstieg der Zinsen, nach Crash -> starkes Absenken des Zinssatzes.\n",
    "\n",
    "#Abgeleitete Daten\n",
    "\n",
    "zinssätze_abgeleitet = daten_ableiten(real_gdps_clean)\n",
    "\n",
    "plot_a_graph(dates, zinssätze_abgeleitet, \"Zinssätze Abgeleitet\", \"Steigung Zinssätze\", 60)\n",
    "\n",
    "#Abgeleitete Daten während der Finanzkrise 2008\n",
    "\n",
    "plot_a_graph_timeframe(dates, zinssätze_abgeleitet, 2003, 2013, \"Zinssätze Abgeleitet während der Finanzkrise 2008\", \"Steigung Zinssätze\", 12)\n",
    "\n",
    "zinssätze_one_year_average_steigung = average_per_timeframe(zinssätze_abgeleitet, 12)\n",
    "\n",
    "plot_a_graph_timeframe(dates, zinssätze_one_year_average_steigung, 2003, 2013, \"Durchschnittliche Steigung der Zinssätze 2003-2013\", \"Zinssätze Steigung\", 12)\n",
    "print(\"\")\n",
    "\n",
    "# M2 Money Supply\n",
    "print(\"\\n\\nM2 Money Supply\")\n",
    "    \n",
    "filename = '../input/real-m2-money-stock/M2REAL.csv'\n",
    "m2_money_supply_list, m2_dates = [], []\n",
    "\n",
    "with open(filename) as f:\n",
    "\treader = csv.reader(f)\n",
    "\theader_row = next(reader)\n",
    "\tprint(header_row)\n",
    "    \n",
    "\tfor row in reader:\n",
    "\t\tm2_money_supply = row[3]\n",
    "\t\tm2_money_supply_list.append(m2_money_supply)\n",
    "\t\tdate = row[2]\n",
    "\t\tm2_dates.append(date)\n",
    "        \n",
    "\n",
    "\n",
    "#print(m2_money_supply_list)\n",
    "\n",
    "m2_money_supply_list_float = [float(x) for x in m2_money_supply_list]\n",
    "#print(m2_money_supply_list_float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#maximaler abstieg\n",
    "max_value = m2_money_supply_list_float[0]\n",
    "max_drawdown = 0\n",
    "for i in m2_money_supply_list_float:\n",
    "    if i > max_value:\n",
    "        max_value = i\n",
    "    if i < max_value:\n",
    "        drawdown = 1 - (i / max_value)\n",
    "        if drawdown > max_drawdown:\n",
    "            max_drawdown = drawdown\n",
    "            #print(max_drawdown)\n",
    "            #print(i)\n",
    "            \n",
    "\n",
    "#print(max_value)\n",
    "print(\"max drawdown:\")\n",
    "print(max_drawdown)\n",
    "index_mdw = m2_money_supply_list_float.index(1832.4)\n",
    "print(m2_dates[index_mdw])\n",
    "\n",
    "\n",
    "plot_a_graph(m2_dates, m2_money_supply_list_float, \"M2 Money supply\", \"M2\", 60)\n",
    "\n",
    "M2 Money Supply\n",
    "['realtime_start', 'realtime_end', 'date', 'value']\n",
    "max drawdown:\n",
    "0.10220480156785883\n",
    "1981-09-01\n",
    "\n",
    "#Steigung M2\n",
    "\n",
    "\n",
    "m2_abgeleitet = daten_ableiten(m2_money_supply_list_float)\n",
    "\n",
    "zero = [0 for x in range(len(m2_dates))]\n",
    "plot_a_graph_multiple(m2_dates, m2_abgeleitet, zero, \"Steigung Geldumlaufmenge M2\", \"M2\", 60)\n",
    "\n",
    "avrg_m2_incr = average_value(m2_abgeleitet)\n",
    "print(f\"Durchschnittliche Steigung: {avrg_m2_incr}\")\n",
    "\n",
    "Durchschnittliche Steigung: 6.74\n",
    "steigung_m2_in_prozent = []\n",
    "wert_zuvor = 0\n",
    "\n",
    "for wert in m2_money_supply_list_float:\n",
    "    if wert_zuvor != 0:\n",
    "        steigung = ( (wert / wert_zuvor) - 1) * 100\n",
    "        steigung_m2_in_prozent.append(steigung)\n",
    "    wert_zuvor = wert\n",
    "    \n",
    "m2_stg_avrg = average_value(steigung_m2_in_prozent)\n",
    "    \n",
    "plot_a_graph_multiple(m2_dates[1:], steigung_m2_in_prozent, zero[1:], \"Steigung Geldumlaufmenge M2 in %\", \"M2\", 60)\n",
    "\n",
    "print(f\"Durchschnittliche Steigung: {round(m2_stg_avrg, 3)}%\")\n",
    "\n",
    "null_bis_eins = 0\n",
    "for wert in steigung_m2_in_prozent:\n",
    "    if wert > 0 and wert < 1:\n",
    "        null_bis_eins += 1\n",
    "        \n",
    "#print(null_bis_eins)\n",
    "#print(len(steigung_m2_in_prozent))\n",
    "\n",
    "przt_zw_null_eins = round ( ( null_bis_eins / len(steigung_m2_in_prozent) )* 100 , 2)\n",
    "print(f\"Werte zwischen 0% und 1% = {przt_zw_null_eins}%\")\n",
    "\n",
    "positiv, negativ = 0, 0\n",
    "for i in m2_abgeleitet:\n",
    "    if i > 0:\n",
    "        positiv += 1\n",
    "    elif i < 0:\n",
    "        negativ += 1\n",
    "print(f\"Positive Werte: {positiv}\")\n",
    "print(f\"Negative Werte: {negativ}\")\n",
    "\n",
    "gesamt = positiv + negativ\n",
    "positiv_prozent = (512 / gesamt) * 100\n",
    "\n",
    "print(f\"Anzahl positiver Werte: = {round(positiv_prozent, 2)}%\")\n",
    "\n",
    "Durchschnittliche Steigung: 0.25%\n",
    "Werte zwischen 0% und 1% = 66.12%\n",
    "Positive Werte: 512\n",
    "Negative Werte: 214\n",
    "Anzahl positiver Werte: = 70.52%\n",
    "m2_steigung_durchschnitt_2yrs = average_per_timeframe(m2_abgeleitet,12)\n",
    "\n",
    "\n",
    "plot_a_graph_multiple(m2_dates[11:], m2_steigung_durchschnitt_2yrs, zero[11:], \"Steigung Geldumlaufmenge 2 Jahre\", \"M2\", 60)\n",
    "\n",
    "m2_steigung_durchschnitt_2yrs = average_per_timeframe(m2_abgeleitet,36)\n",
    "\n",
    "\n",
    "plot_a_graph_multiple(m2_dates[35:], m2_steigung_durchschnitt_2yrs, zero[35:], \"Steigung Geldumlaufmenge 3 Jahre\", \"M2\", 60)\n",
    "\n",
    "m2_steigung_durchschnitt_2yrs = average_per_timeframe(m2_abgeleitet,60)\n",
    "\n",
    "\n",
    "plot_a_graph_multiple(m2_dates[59:], m2_steigung_durchschnitt_2yrs, zero[59:], \"Steigung Geldumlaufmenge M2\", \"M2\", 60)\n",
    "\n",
    "print(dates[582])\n",
    "print(dates[700])\n",
    "avrg_m2 = [avrg_m2_incr for i in range(0, len(dates))]\n",
    "#plot_a_graph_multiple(m2_dates[582:700], m2_money_supply_list_float[582:700], avrg_m2[582:700], \"Geldumlaufmenge um 2008\", \"M2\", 36)\n",
    "#plot_a_graph_timeframe(m2_dates, m2_money_supply_list_float, 1995, 2007, \"M2 Money supply from \", \"M2\", 12)\n",
    "\n",
    "\n",
    "index_start = 470\n",
    "index_end = 630\n",
    "title = \"M2 Money Supply\"\n",
    "x_label = \"\"\n",
    "y_label = \"M2\"\n",
    "ticks = 12\n",
    "x_values = m2_dates\n",
    "y_values = m2_money_supply_list_float\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "ax = plt.gca()\n",
    "ax.plot(x_values[index_start:index_end], y_values[index_start:index_end], c='blue', alpha=0.5, linewidth=3.0)\n",
    "#Format plot\n",
    "ax.set_title(title, fontsize=14)\n",
    "ax.set_xlabel(x_label ,fontsize=10)\n",
    "ax.set_ylabel(y_label, fontsize=10)\n",
    "ax = plt.gca()\n",
    "if(ticks != 1):\n",
    "    tick_list = []\n",
    "    for i in range(len(x_values[index_start:index_end])-1):\n",
    "        if(i%ticks == 0):\n",
    "            tick_list.append(i)\n",
    "\n",
    "    ax.set_xticks(tick_list, rotation = 45)\n",
    "    ax.tick_params(direction='out', length=10, width=2)\n",
    "    minor_ticks = np.arange(0, len(m2_dates[index_start:index_end]), (ticks/5))\n",
    "    ax.set_xticks(minor_ticks, minor=True)\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_rotation(30)\n",
    "plt.xticks(fontsize= 14)\n",
    "plt.yticks(fontsize= 16)\n",
    "plt.title(title, fontsize = 25)\n",
    "ax.set_xlabel(x_label, fontsize=22)\n",
    "ax.set_ylabel(y_label, fontsize=22)\n",
    "\n",
    "plt.axhline(y=3250, xmin=0, xmax=10000, linewidth=1.0)\n",
    "plt.axhline(y=3600, xmin=0, xmax=10000, linewidth=1.0)\n",
    "#plt.axhline(y=0, xmin=550, xmax=10000, linewidth=1.0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "########################################################################\n",
    "2003-01\n",
    "2012-11\n",
    "\n",
    "plot_a_graph_timeframe(m2_dates, m2_abgeleitet, 2000, 2007, \"Steigung Geldumlaufmenge\", \"M2\", 12)\n",
    "\n",
    "plot_a_graph_multiple(m2_dates[450:], m2_abgeleitet[450:], zero[450:], \"Steigung Geldumlaufmenge in %\", \"M2\", 36)\n",
    "\n",
    "positiv, negativ = 0, 0\n",
    "for i in m2_abgeleitet:\n",
    "    if i > 0:\n",
    "        positiv += 1\n",
    "    elif i < 0:\n",
    "        negativ += 1\n",
    "print(f\"Positive Werte: {positiv}\")\n",
    "print(f\"Negative Werte: {negativ}\")\n",
    "\n",
    "gesamt = positiv + negativ\n",
    "positiv_prozent = 512 / gesamt\n",
    "\n",
    "print(f\"Anzahl positiver Werte: = {round(positiv_prozent, 2)}%\")\n",
    "Positive Werte: 512\n",
    "Negative Werte: 214\n",
    "Anzahl positiver Werte: = 0.71%\n",
    "#Inflation\n",
    "print(\"\\nInflationsrate\")\n",
    "\n",
    "#convert string to float\n",
    "inflation_rates_float = []\n",
    "for value in inflation_rates:\n",
    "    if value != '':\n",
    "        inflation_rates_float.append(float(value))\n",
    "    else:\n",
    "        inflation_rates_float.append(value)\n",
    "\n",
    "\n",
    "for i in range(len(inflation_rates_float)):\n",
    "    if inflation_rates_float[i] != '':\n",
    "        print(f\"Ab Index {i} beginnen die Werte\")\n",
    "        start_inflation_data = convert_index_to_date(42)\n",
    "        print(start_inflation_data)\n",
    "        break\n",
    "\n",
    "\n",
    "average_inflation = average_value(inflation_rates_float[42:])\n",
    "print(f\"\\nDurchschnittliche Inflationsrate: {average_inflation}\")\n",
    "\n",
    "min_inflation = tiefpunkt(inflation_rates_float[42:-1])\n",
    "print(f\"\\nDie niedrigste Inflationsrate beträgt: {min_inflation}\")\n",
    "min_inflation_year_index = inflation_rates_float.index(0.6)\n",
    "min_inflation_year = convert_index_to_date(min_inflation_year_index)\n",
    "print(min_inflation_year)\n",
    "\n",
    "max_inflation = hochpunkt(inflation_rates_float[42:-1])\n",
    "print(f\"\\nDie höchste Inflationsrate beträgt: {max_inflation}\")\n",
    "max_inflation_year_index = inflation_rates_float.index(13.6)\n",
    "max_inflation_year = convert_index_to_date(max_inflation_year_index)\n",
    "print(max_inflation_year)\n",
    "\n",
    "\n",
    "plot_a_graph(dates[42:-1], inflation_rates_float[42:-1], \"Inflationrate from 1958 - 2017\", \"Inflationrate\", 60, 2)\n",
    "\n",
    "\n",
    "\n",
    "#print(inflation_rates_float[42:])\n",
    "Inflationsrate\n",
    "Ab Index 42 beginnen die Werte\n",
    "1958-01\n",
    "\n",
    "Durchschnittliche Inflationsrate: 3.73\n",
    "\n",
    "Die niedrigste Inflationsrate beträgt: 0.6\n",
    "2010-10\n",
    "\n",
    "Die höchste Inflationsrate beträgt: 13.6\n",
    "1980-06\n",
    "\n",
    "plot_a_graph_timeframe(dates[:-1], inflation_rates_float[:-1], 1984, 2003, \"Inflationrate from 1984 - 2003\", \"Inflationrate\", 60, 2)\n",
    "\n",
    "plot_a_graph_timeframe(dates, inflation_rates_float, 2003, 2009, \"Inflationrate from 2003 - 2009\", \"Inflationrate\", 12, 2)\n",
    "\n",
    "#plot_a_graph_multiple(x_values, y_values_1, y_values_2 title, y_label, set_n,x_label=''):\n",
    "    \n",
    "plot_a_graph_multiple(dates[42:-1], inflation_rates_float[42:-1], interest_rates_clean[42:-1], \"Inflation & Interestrates\", \"Inflation\\nInterest\", 60)\n",
    "\n",
    "#plot_a_graph_3_timeframe(x_values, y_values_1, y_values_2, y_values_3, start_year, end_year, title, y_label, set_n, x_label=''):\n",
    "    \n",
    "\n",
    "plot_a_graph_3_timeframe(dates, real_gdps_clean, interest_rates_clean, unemployment_clean, 1995, 2015, \"BIP, Zinsen, Arbeitslosigkeit\", \"BIP\\nZinsen\\nArbeitslosigkeit\", 36)\n",
    "\n",
    "two = [2 for x in range(len(dates[42:-1]))]\n",
    "plot_a_graph_multiple(dates[42:-1], inflation_rates_float[42:-1], two, \"Inflation\", \"Inflation\", 60)\n",
    "\n",
    "plot_a_graph_multiple(dates[42:-1], interest_rates_clean[42:-1], unemployment_clean[42:-1], \"Zinsen & Arbeitslosigkeit\", \"Inflation\\nArbeitslosigkeit\", 60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "48dc65c8-d1c2-4005-9aba-1e485ab2fff6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/2724557819.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'date'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data=data).T\n",
    "\n",
    "\n",
    "\n",
    "#data.to_csv('TSLA.csv') \n",
    "\n",
    "df.head()\n",
    "df.isnull()\n",
    "# df.describe()\n",
    "\n",
    "#df   = df.rename(columns={ \"1. open\": \"Open\", \"2. high\": \"High\", \"3. low\": \"Low\" , \"4. close\": \"Close\", \"5. volume\": \"Volume\" } ) \n",
    "#df[\"date\"] = pd.to_datetime(df.date)\n",
    "\n",
    "df[\"date\"] = pd.to_datetime(df.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4821c99d-b3fb-421c-9d85-f17ab4969884",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/758352923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# df   = df.set_index( 'Open' )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/envs/tensorflow_env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Date'"
     ]
    }
   ],
   "source": [
    "# df   = df.set_index( 'Open' ) \n",
    "df[\"date\"] = pd.to_datetime(df.Date)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81f494db-8e28-49da-a45e-a7649865680b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Response' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/z7/f3scrkt52xl98f7q0pcz9vy80000gn/T/ipykernel_65505/25806328.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOCK_ENDPOINT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstock_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Response' object is not callable"
     ]
    }
   ],
   "source": [
    "STOCK_NAME = 'TSLA' # this is the stock name \n",
    "STOCK_ENDPOINT = 'https://www.alphavantage.co/query' # this is where we pull the information from \n",
    "\n",
    "STOCK_API_KEY = 'J578B5KP1C3ZG1LE' \n",
    "\n",
    "stock_params = {\n",
    "    \"function\": \"TIME_SERIES_DAILY\",\n",
    "    \"symbol\": STOCK_NAME,\n",
    "    \"apikey\": STOCK_API_KEY,\n",
    "}\n",
    "\n",
    "response = requests.get(STOCK_ENDPOINT, params=stock_params)\n",
    "print(response(json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f02ae6-99bb-49a7-9b16-6a27cd256beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
